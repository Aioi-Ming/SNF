{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4e4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdf3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4570ff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7696fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The model of the Decoder\n",
    "class GenerativeModel(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=50):\n",
    "        super(GenerativeModel, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.net = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(latent_dim, 1024),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(1024, 1024),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(1024, 784),\n",
    "                    torch.nn.Sigmoid()\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def sample(self, M, N=None):\n",
    "        device = next(self.parameters()).device\n",
    "        if N is None:\n",
    "            x = torch.randn(M, self.latent_dim).to(device)\n",
    "        else:\n",
    "            x = torch.randn(M, N, self.latent_dim).to(device)\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def conditional_log_likelihood(self, x, y):\n",
    "        recon_x = torch.clamp(self.forward(x), 1e-6, 1.-1e-6)\n",
    "        return torch.log(recon_x) * y + torch.log(1 - recon_x) * (1 - y)\n",
    "        \n",
    "class SimpleVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=50):\n",
    "        super(SimpleVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.G = GenerativeModel(latent_dim)\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "                    torch.nn.Linear(784, 1024),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(1024, 1024),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(1024, latent_dim * 2)\n",
    "                    )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        device = next(self.parameters()).device\n",
    "        M = x.shape[0]\n",
    "        N = y.shape[0]\n",
    "        dW = torch.zeros((M, N, 1)).to(device)\n",
    "        mean_std = self.encoder(y)\n",
    "        mean = mean_std[:, :self.latent_dim]\n",
    "        std = torch.abs(mean_std[:, self.latent_dim:]) + 1e-6\n",
    "        x1 = x * std + mean\n",
    "        dW = dW + (x**2).sum(axis=2, keepdims=True) / 2\n",
    "        dW = dW - (x1**2).sum(axis=2, keepdims=True) / 2\n",
    "        dW = dW + self.G.conditional_log_likelihood(x1, y).sum(axis=2, keepdims=True)\n",
    "        dW = dW + torch.log(std).sum(axis=1, keepdims=True)\n",
    "        return x1, dW\n",
    "\n",
    "    def log_likelihood(self, y, M):\n",
    "        device = next(self.parameters()).device\n",
    "        x0 = torch.randn(M, y.shape[0], self.latent_dim).to(device)\n",
    "        x, dW = self.forward(x0, y.view(-1, 784))\n",
    "        return torch.mean(dW, axis=0, keepdims=False)\n",
    "\n",
    "class LangevinVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=50, nsteps=30, stepsize=0.01):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.G = GenerativeModel(latent_dim)\n",
    "        self.nsteps = nsteps\n",
    "        stepsize_list = torch.FloatTensor([stepsize,] * nsteps)\n",
    "        lambda_list = (np.array(range(1,nsteps + 1))/nsteps).tolist()\n",
    "        lambda_list = torch.FloatTensor(lambda_list)\n",
    "        self.stepsize_para_list, self.lambda_para_list = self.stepsize_lambda_2_para(stepsize_list, lambda_list)\n",
    "        self.stepsize_para_list = nn.Parameter(torch.FloatTensor(self.stepsize_para_list), requires_grad=True)\n",
    "        self.lambda_para_list = nn.Parameter(torch.FloatTensor(self.lambda_para_list), requires_grad=True)\n",
    "        \n",
    "    def stepsize_lambda_2_para(self, stepsize_list, lambda_list):\n",
    "        stepsize_para_list = torch.clamp(torch.abs(stepsize_list), min=1e-6)\n",
    "        lambda_para_list = lambda_list\n",
    "        return stepsize_para_list, lambda_para_list\n",
    "    \n",
    "    def para_2_stepsize_lambda(self, stepsize_para_list, lambda_para_list):\n",
    "        stepsize_list = torch.abs(stepsize_para_list) + 1e-6\n",
    "        lambda_list = lambda_para_list\n",
    "        return stepsize_list, lambda_list\n",
    "\n",
    "    def energy_0(self, x, y):\n",
    "        return (x**2).sum(axis=2, keepdims=True) / 2\n",
    "\n",
    "    def force_0(self, x, y):\n",
    "        return -x\n",
    "    \n",
    "    def sample_energy_0(self, y, M):\n",
    "        device = next(self.parameters()).device\n",
    "        x = torch.randn(M, y.shape[0], self.latent_dim).to(device)\n",
    "        return x\n",
    "        \n",
    "    def energy_1(self, x, y):\n",
    "        return (x**2).sum(axis=2, keepdims=True) / 2 - self.G.conditional_log_likelihood(x, y).sum(axis=2, keepdims=True)\n",
    "\n",
    "    def force_1(self, x, y):\n",
    "        x0 = x.clone().detach().requires_grad_(True)\n",
    "        e = self.energy_1(x0, y)\n",
    "        return -torch.autograd.grad(e.sum(), x0, create_graph=True)[0]\n",
    "\n",
    "    def interpolated_energy(self, x, y, lambda_=1.):\n",
    "        return self.energy_0(x, y) * (1 - lambda_) + self.energy_1(x, y) * lambda_\n",
    "\n",
    "    def interpolated_force(self, x, y, lambda_=1.):\n",
    "        return self.force_0(x, y) * (1 - lambda_) + self.force_1(x, y) * lambda_\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        stepsize_list, lambda_list = self.para_2_stepsize_lambda(self.stepsize_para_list, self.lambda_para_list)\n",
    "        dW = self.energy_0(x, y)\n",
    "        for i in range(self.nsteps):\n",
    "            lambda_ = lambda_list[i]\n",
    "            stepsize = stepsize_list[i]\n",
    "            # forward step\n",
    "            x1 = x + stepsize * self.interpolated_force(x, lambda_) + torch.sqrt(2*stepsize) * torch.randn_like(x)\n",
    "            tmp_dW = self.interpolated_energy(x1, y, lambda_) - self.interpolated_energy(x, y, lambda_)\n",
    "            A = torch.exp(torch.clamp(-tmp_dW, - math.inf, 0.))\n",
    "            u = torch.rand_like(A)\n",
    "            acc = (u <= A).float()\n",
    "            x = (1 - acc) * x + acc * x1\n",
    "            dW += acc * tmp_dW\n",
    "        dW = dW - self.energy_1(x, y)\n",
    "        return x, dW\n",
    "\n",
    "    def log_likelihood(self, y, M):\n",
    "        x0 = self.sample_energy_0(y.view(-1, 784), M)\n",
    "        x, dW = self.forward(x0, y.view(-1, 784))\n",
    "        return torch.mean(dW, axis=0, keepdims=False)\n",
    "\n",
    "\n",
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim, mask, cond_dim=None, s_tanh_activation=True, smooth_activation=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        if cond_dim is not None:\n",
    "            total_input_dim = input_dim + cond_dim\n",
    "        else:\n",
    "            total_input_dim = input_dim\n",
    "\n",
    "        self.s_fc1 = nn.Linear(total_input_dim, hid_dim)\n",
    "        self.s_fc2 = nn.Linear(hid_dim, hid_dim)\n",
    "        self.s_fc3 = nn.Linear(hid_dim, input_dim)\n",
    "        self.t_fc1 = nn.Linear(total_input_dim, hid_dim)\n",
    "        self.t_fc2 = nn.Linear(hid_dim, hid_dim)\n",
    "        self.t_fc3 = nn.Linear(hid_dim, input_dim)\n",
    "        self.mask = nn.Parameter(mask, requires_grad=False)\n",
    "        self.s_tanh_activation = s_tanh_activation\n",
    "        self.smooth_activation = smooth_activation\n",
    "\n",
    "    def forward(self, x, cond_x=None, mode='direct'):\n",
    "        x_m = x * self.mask\n",
    "        if cond_x is not None:\n",
    "            x_m = torch.cat([x_m, cond_x.expand(x_m.shape[0], -1, -1)], -1)\n",
    "        if self.smooth_activation:\n",
    "            if self.s_tanh_activation:\n",
    "                s_out = torch.tanh(self.s_fc3(F.elu(self.s_fc2(F.elu(self.s_fc1(x_m)))))) * (1-self.mask)\n",
    "            else:\n",
    "                s_out = self.s_fc3(F.elu(self.s_fc2(F.elu(self.s_fc1(x_m))))) * (1-self.mask)\n",
    "            t_out = self.t_fc3(F.elu(self.t_fc2(F.elu(self.t_fc1(x_m))))) * (1-self.mask)\n",
    "        else:\n",
    "            if self.s_tanh_activation:\n",
    "                s_out = torch.tanh(self.s_fc3(F.relu(self.s_fc2(F.relu(self.s_fc1(x_m)))))) * (1-self.mask)\n",
    "            else:\n",
    "                s_out = self.s_fc3(F.relu(self.s_fc2(F.relu(self.s_fc1(x_m))))) * (1-self.mask)\n",
    "            t_out = self.t_fc3(F.relu(self.t_fc2(F.relu(self.t_fc1(x_m))))) * (1-self.mask)\n",
    "        if mode == 'direct':\n",
    "            y = x * torch.exp(s_out) + t_out\n",
    "            log_det_jacobian = s_out.sum(-1, keepdim=True)\n",
    "        else:\n",
    "            y = (x - t_out) * torch.exp(-s_out)\n",
    "            log_det_jacobian = -s_out.sum(-1, keepdim=True)\n",
    "        return y, log_det_jacobian\n",
    "\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim = 256, n_layers = 2, cond_dim = None, s_tanh_activation = True, smooth_activation=False):\n",
    "        super().__init__()\n",
    "        assert n_layers >= 2, 'num of coupling layers should be greater or equal to 2'\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        mask = (torch.arange(0, input_dim) % 2).float()\n",
    "        self.modules = []\n",
    "        self.modules.append(CouplingLayer(input_dim, hid_dim, mask, cond_dim, s_tanh_activation, smooth_activation))\n",
    "        for _ in range(n_layers - 2):\n",
    "            mask = 1 - mask\n",
    "            self.modules.append(CouplingLayer(input_dim, hid_dim, mask, cond_dim, s_tanh_activation, smooth_activation))\n",
    "        self.modules.append(CouplingLayer(input_dim, hid_dim, 1 - mask, cond_dim, s_tanh_activation, smooth_activation))\n",
    "        self.module_list = nn.ModuleList(self.modules)\n",
    "        \n",
    "    def forward(self, x, cond_x=None, mode='direct'):\n",
    "        \"\"\" Performs a forward or backward pass for flow modules.\n",
    "        Args:\n",
    "            x: a tuple of inputs and logdets\n",
    "            mode: to run direct computation or inverse\n",
    "        \"\"\"\n",
    "        logdets = torch.zeros(x.size(), device=x.device).sum(-1, keepdim=True)\n",
    "\n",
    "        assert mode in ['direct', 'inverse']\n",
    "        if mode == 'direct':\n",
    "            for module in self.module_list:\n",
    "                x, logdet = module(x, cond_x, mode)\n",
    "                logdets += logdet\n",
    "        else:\n",
    "            for module in reversed(self.module_list):\n",
    "                x, logdet = module(x, cond_x, mode)\n",
    "                logdets += logdet\n",
    "\n",
    "        return x, logdets\n",
    "\n",
    "    def log_probs(self, x, cond_x = None):\n",
    "        u, log_jacob = self(x, cond_x)\n",
    "        log_probs = (-0.5 * u.pow(2) - 0.5 * math.log(2 * math.pi)).sum(\n",
    "            -1, keepdim=True)\n",
    "        return (log_probs + log_jacob).sum(-1, keepdim=True)\n",
    "\n",
    "    def sample(self, num_samples, noise=None, cond_x=None):\n",
    "        if noise is None:\n",
    "            noise = torch.Tensor(num_samples, self.input_dim).normal_()\n",
    "        device = next(self.parameters()).device\n",
    "        noise = noise.to(device)\n",
    "        if cond_x is not None:\n",
    "            cond_x = cond_x.to(device)\n",
    "        samples = self.forward(noise, cond_x, mode='inverse')[0]\n",
    "        return samples\n",
    "    \n",
    "class RealNVPVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=50):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.G = GenerativeModel(latent_dim)\n",
    "        self.F = RealNVP(latent_dim, hid_dim=64, n_layers=6, cond_dim=784)\n",
    "\n",
    "    def energy_0(self, x, y):\n",
    "        return (x**2).sum(axis=2, keepdims=True) / 2\n",
    "    \n",
    "    def sample_energy_0(self, y, M):\n",
    "        device = next(self.parameters()).device\n",
    "        x = torch.randn(M, y.shape[0], self.latent_dim).to(device)\n",
    "        return x\n",
    "        \n",
    "    def energy_1(self, x, y):\n",
    "        return (x**2).sum(axis=2, keepdims=True) / 2 - self.G.conditional_log_likelihood(x, y).sum(axis=2, keepdims=True)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        dW = self.energy_0(x, y)\n",
    "        x, tmp_dW = self.F(x, y)\n",
    "        dW += tmp_dW\n",
    "        dW = dW - self.energy_1(x, y)\n",
    "        return x, dW\n",
    "\n",
    "    def log_likelihood(self, y, M):\n",
    "        x0 = self.sample_energy_0(y.view(-1, 784), M)\n",
    "        x, dW = self.forward(x0, y.view(-1, 784))\n",
    "        return torch.mean(dW, axis=0, keepdims=False)\n",
    "\n",
    "class RealNVPVAE_eval(nn.Module):\n",
    "\n",
    "    def __init__(self, G):\n",
    "        super().__init__()\n",
    "        latent_dim = G.latent_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.G = G\n",
    "        self.F = RealNVP(latent_dim, hid_dim=256, n_layers=12, cond_dim=784)\n",
    "\n",
    "    def energy_0(self, x, y):\n",
    "        return (x**2).sum(axis=2, keepdims=True) / 2\n",
    "    \n",
    "    def sample_energy_0(self, y, M):\n",
    "        device = next(self.parameters()).device\n",
    "        x = torch.randn(M, y.shape[0], self.latent_dim).to(device)\n",
    "        return x\n",
    "        \n",
    "    def energy_1(self, x, y):\n",
    "        return (x**2).sum(axis=2, keepdims=True) / 2 - self.G.conditional_log_likelihood(x, y).sum(axis=2, keepdims=True)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        dW = self.energy_0(x, y)\n",
    "        x, tmp_dW = self.F(x, y)\n",
    "        dW += tmp_dW\n",
    "        dW = dW - self.energy_1(x, y)\n",
    "        return x, dW\n",
    "\n",
    "    def log_likelihood(self, y, M):\n",
    "        x0 = self.sample_energy_0(y.view(-1, 784), M)\n",
    "        x, dW = self.forward(x0, y.view(-1, 784))\n",
    "        return torch.logsumexp(dW, axis=0, keepdims=False) - math.log(M)\n",
    "\n",
    "def ModelEval(G, sample_size, data_file):\n",
    "    start = time.process_time()\n",
    "    \n",
    "#    device = torch.device(\"cuda\")\n",
    "    latent_dim = 50\n",
    "    batch_size = 128\n",
    "    n_epochs = 40\n",
    "    log_interval = 10\n",
    "\n",
    "    if data_file == 'mnist_data':\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(data_file, train=True, download=False,\n",
    "                           transform=transforms.ToTensor()),\n",
    "                            batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(data_file, train=False, transform=transforms.ToTensor()),\n",
    "            batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST(data_file, train=True, download=False,\n",
    "                           transform=transforms.ToTensor()),\n",
    "                            batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST(data_file, train=False, transform=transforms.ToTensor()),\n",
    "            batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "    flow = RealNVPVAE_eval(G).to(device)\n",
    "    optim = torch.optim.Adam(flow.F.parameters(), lr=1e-3)\n",
    "\n",
    "    M = 1\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(test_loader):\n",
    "            data = ((torch.rand_like(data) <= data) + 0.).float()\n",
    "            data = data.to(device)\n",
    "            loss = -flow.log_likelihood(data, M).mean()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()*len(data)\n",
    "            optim.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(test_loader.dataset),\n",
    "                    100. * batch_idx / len(test_loader),\n",
    "                    loss.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        M = sample_size\n",
    "        K = 10\n",
    "        for kk in range(K):\n",
    "            for batch_idx, (data, _) in enumerate(test_loader):\n",
    "                data = ((torch.rand_like(data) <= data) + 0.).float()\n",
    "                data = data.to(device)\n",
    "                loss = -flow.log_likelihood(data, M).mean()\n",
    "                test_loss += loss.item()*len(data)\n",
    "                if batch_idx % log_interval == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        kk, batch_idx * len(data), len(test_loader.dataset),\n",
    "                        100. * batch_idx / len(test_loader),\n",
    "                        loss.item()))\n",
    "        test_loss /= len(test_loader.dataset)*K\n",
    "    print('====> Test set NLL: {:.4f}'.format(test_loss))\n",
    "\n",
    "    return test_loss\n",
    "    \n",
    "\n",
    "class SNFVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=50, unit_num=3, nsteps=10, stepsize=0.1):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.unit_num = unit_num\n",
    "        self.G = GenerativeModel(latent_dim)\n",
    "        self.F_list = []\n",
    "        for _ in range(unit_num):\n",
    "            self.F_list.append(RealNVP(latent_dim, hid_dim=64, n_layers=2, cond_dim=784))\n",
    "        self.F_list = nn.ModuleList(self.F_list)\n",
    "        self.nsteps = nsteps\n",
    "        stepsize_list = torch.FloatTensor([stepsize,] * nsteps * unit_num)\n",
    "        lambda_list = (np.array(range(1,nsteps * unit_num + 1))/nsteps / unit_num).tolist()\n",
    "        lambda_list = torch.FloatTensor(lambda_list)\n",
    "        self.stepsize_para_list, self.lambda_para_list = self.stepsize_lambda_2_para(stepsize_list, lambda_list)\n",
    "        self.stepsize_para_list = nn.Parameter(torch.FloatTensor(self.stepsize_para_list), requires_grad=True)\n",
    "        self.lambda_para_list = nn.Parameter(torch.FloatTensor(self.lambda_para_list))\n",
    "        \n",
    "    def stepsize_lambda_2_para(self, stepsize_list, lambda_list):\n",
    "        stepsize_para_list = torch.clamp(torch.abs(stepsize_list), min=1e-6)\n",
    "        lambda_para_list = lambda_list\n",
    "        return stepsize_para_list, lambda_para_list\n",
    "    \n",
    "    def para_2_stepsize_lambda(self, stepsize_para_list, lambda_para_list):\n",
    "        stepsize_list = torch.abs(stepsize_para_list) + 1e-6\n",
    "        lambda_list = lambda_para_list\n",
    "        return stepsize_list, lambda_list\n",
    "\n",
    "    def energy_0(self, x, y):\n",
    "        return (x**2).sum(axis=2, keepdims=True) / 2\n",
    "\n",
    "    def force_0(self, x, y):\n",
    "        return -x\n",
    "    \n",
    "    def sample_energy_0(self, y, M):\n",
    "        device = next(self.parameters()).device\n",
    "        x = torch.randn(M, y.shape[0], self.latent_dim).to(device)\n",
    "        return x\n",
    "        \n",
    "    def energy_1(self, x, y):\n",
    "        return (x**2).sum(axis=2, keepdims=True) / 2 - self.G.conditional_log_likelihood(x, y).sum(axis=2, keepdims=True)\n",
    "\n",
    "    def force_1(self, x, y):\n",
    "        x0 = x.clone().detach().requires_grad_(True)\n",
    "        e = self.energy_1(x0, y)\n",
    "        return -torch.autograd.grad(e.sum(), x0, create_graph=True)[0]\n",
    "\n",
    "    def interpolated_energy(self, x, y, lambda_=1.):\n",
    "        return self.energy_0(x, y) * (1 - lambda_) + self.energy_1(x, y) * lambda_\n",
    "\n",
    "    def interpolated_force(self, x, y, lambda_=1.):\n",
    "        return self.force_0(x, y) * (1 - lambda_) + self.force_1(x, y) * lambda_\n",
    "\n",
    "    def forward(self, x, y, flow_disable=False):\n",
    "        stepsize_list, lambda_list = self.para_2_stepsize_lambda(self.stepsize_para_list, self.lambda_para_list)\n",
    "        dW = self.energy_0(x, y)\n",
    "        for i in range(self.nsteps * self.unit_num):\n",
    "            if i % self.nsteps == 0:\n",
    "                x, tmp_dW = self.F_list[int(i/self.nsteps)](x, y)\n",
    "                dW += tmp_dW                \n",
    "            if flow_disable:\n",
    "                continue\n",
    "            lambda_ = lambda_list[i]\n",
    "            stepsize = stepsize_list[i]\n",
    "            # forward step\n",
    "            x1 = x + stepsize * self.interpolated_force(x, lambda_) + torch.sqrt(2*stepsize) * torch.randn_like(x)\n",
    "            tmp_dW = self.interpolated_energy(x1, y, lambda_) - self.interpolated_energy(x, y, lambda_)\n",
    "            A = torch.exp(torch.clamp(-tmp_dW, - math.inf, 0.))\n",
    "            u = torch.rand_like(A)\n",
    "            acc = (u <= A).float()\n",
    "            x = (1 - acc) * x + acc * x1\n",
    "            dW += acc * tmp_dW\n",
    "        dW = dW - self.energy_1(x, y)\n",
    "        return x, dW\n",
    "\n",
    "    def log_likelihood(self, y, M, flow_disable=False):\n",
    "        x0 = self.sample_energy_0(y.view(-1, 784), M)\n",
    "        x, dW = self.forward(x0, y.view(-1, 784), flow_disable)\n",
    "        return torch.mean(dW, axis=0, keepdims=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf82f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, data_file, M):\n",
    "    start = time.process_time()\n",
    "    \n",
    "    latent_dim = 50\n",
    "    batch_size = 128\n",
    "    log_interval = 100\n",
    "\n",
    "    if data_file == 'mnist_data':\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('mnist_data', train=True, download=True,\n",
    "                           transform=transforms.ToTensor()),\n",
    "                            batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST('mnist_data', train=False, transform=transforms.ToTensor()),\n",
    "            batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST('fashionmnist_data', train=True, download=True,\n",
    "                           transform=transforms.ToTensor()),\n",
    "                            batch_size=batch_size, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.FashionMNIST('fashionmnist_data', train=False, transform=transforms.ToTensor()),\n",
    "            batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    if model_name in ['SimpleVAE','RealNVPVAE','LangevinVAE']:\n",
    "        n_epochs = 40\n",
    "        if model_name == 'SimpleVAE':\n",
    "            flow = SimpleVAE(latent_dim).to(device)\n",
    "        if model_name == 'RealNVPVAE':\n",
    "            flow = RealNVPVAE(latent_dim).to(device)\n",
    "        if model_name == 'LangevinVAE':\n",
    "            flow = LangevinVAE(latent_dim).to(device)\n",
    "        optim = torch.optim.Adam(flow.parameters(), lr=1e-3)\n",
    "        #perform training\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            train_loss = 0\n",
    "            for batch_idx, (data, _) in enumerate(train_loader):\n",
    "                data = ((torch.rand_like(data) <= data) + 0.).float()\n",
    "                data = data.to(device)\n",
    "                loss = -flow.log_likelihood(data, M).mean()\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                train_loss += loss.item() * len(data)\n",
    "                optim.step()\n",
    "                if batch_idx % log_interval == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item() * len(data) / len(data)))\n",
    "\n",
    "            test_loss = 0\n",
    "            for i, (data, _) in enumerate(test_loader):\n",
    "                data = ((torch.rand_like(data) <= data) + 0.).float()\n",
    "                data = data.to(device)\n",
    "                loss = -flow.log_likelihood(data, M).sum()\n",
    "                test_loss += loss.item()\n",
    "\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    else:\n",
    "        flow = SNFVAE(latent_dim, nsteps=10, stepsize=1e-2).to(device)\n",
    "        optim = torch.optim.Adam(flow.parameters(), lr=1e-3)\n",
    "        n_epochs = 20\n",
    "        flow_disable = True\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            train_loss = 0\n",
    "            for batch_idx, (data, _) in enumerate(train_loader):\n",
    "                data = ((torch.rand_like(data) <= data) + 0.).float()\n",
    "                data = data.to(device)\n",
    "                loss = -flow.log_likelihood(data, M, flow_disable).mean()\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                train_loss += loss.item()\n",
    "                optim.step()\n",
    "                if batch_idx % log_interval == 0:\n",
    "                    print(flow.stepsize_para_list.mean())\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item()))\n",
    "\n",
    "            test_loss = 0\n",
    "            for i, (data, _) in enumerate(test_loader):\n",
    "                data = ((torch.rand_like(data) <= data) + 0.).float()\n",
    "                data = data.to(device)\n",
    "                loss = -flow.log_likelihood(data, M, flow_disable).sum()\n",
    "                test_loss += loss.item()\n",
    "\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "        optim = torch.optim.Adam(flow.parameters(), lr=1e-3)\n",
    "        flow_disable = False\n",
    "        n_epochs = 20\n",
    "        flow_disable = True\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            train_loss = 0\n",
    "            for batch_idx, (data, _) in enumerate(train_loader):\n",
    "                data = ((torch.rand_like(data) <= data) + 0.).float()\n",
    "                data = data.to(device)\n",
    "                loss = -flow.log_likelihood(data, M, flow_disable).mean()\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                train_loss += loss.item()\n",
    "                optim.step()\n",
    "                if batch_idx % log_interval == 0:\n",
    "                    print(flow.stepsize_para_list.mean())\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch+20, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item()))\n",
    "\n",
    "            test_loss = 0\n",
    "            for i, (data, _) in enumerate(test_loader):\n",
    "                data = ((torch.rand_like(data) <= data) + 0.).float()\n",
    "                data = data.to(device)\n",
    "                loss = -flow.log_likelihood(data, M, flow_disable).sum()\n",
    "                test_loss += loss.item()\n",
    "\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "\n",
    "    #calculate the marginal log-likelihood\n",
    "    loss = ModelEval(flow.G, 2000, data_file)\n",
    "\n",
    "    print('Running time: %s Seconds'%(time.process_time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dae4d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 713.730347\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 203.225449\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 185.080200\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 150.746216\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 142.993958\n",
      "====> Test set loss: 137.8264\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 145.235306\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 131.734619\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 122.637726\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 122.470139\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 119.651093\n",
      "====> Test set loss: 115.8454\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 118.039597\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 116.292404\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 109.655807\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 111.365166\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 111.805542\n",
      "====> Test set loss: 108.8558\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 107.257217\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 105.680923\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 108.807648\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 103.438126\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 102.753250\n",
      "====> Test set loss: 105.4472\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 111.938431\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 105.948654\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 103.798752\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 102.191597\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 99.084763\n",
      "====> Test set loss: 103.1052\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 103.980942\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 105.389709\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 105.646454\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 103.337296\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 99.024719\n",
      "====> Test set loss: 101.7620\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 99.549011\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 101.389038\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 105.248459\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 100.809052\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 99.617889\n",
      "====> Test set loss: 100.5393\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 101.698898\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 98.547409\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 94.022057\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 95.671608\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 96.677094\n",
      "====> Test set loss: 99.0912\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 99.304924\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 99.293854\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 97.873680\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 99.699677\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 105.139038\n",
      "====> Test set loss: 98.3424\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 102.786751\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 98.296295\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 93.131470\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 94.947906\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 101.075806\n",
      "====> Test set loss: 98.2897\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 97.177452\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 100.130615\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 95.322601\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 101.708191\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 99.325928\n",
      "====> Test set loss: 97.4921\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 92.934593\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 98.779411\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 92.710091\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 94.548294\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 99.294106\n",
      "====> Test set loss: 97.1838\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 96.412857\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 93.992859\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 94.145996\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 97.281525\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 98.396057\n",
      "====> Test set loss: 97.0271\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 94.095322\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 96.851631\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 94.044533\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 97.892929\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 95.175735\n",
      "====> Test set loss: 96.5876\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 92.686569\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 94.401390\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 95.771393\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 98.083183\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 97.891823\n",
      "====> Test set loss: 96.6738\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 99.268936\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 95.824051\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 96.848236\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 96.368073\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 94.001877\n",
      "====> Test set loss: 96.0730\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 97.031738\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 98.035400\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 94.993744\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 96.290237\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 95.314484\n",
      "====> Test set loss: 96.0118\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 93.584435\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 95.276436\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 94.846130\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 94.726318\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 93.015579\n",
      "====> Test set loss: 95.9934\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 95.934097\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 91.947540\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 95.832230\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 96.170761\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 96.423386\n",
      "====> Test set loss: 95.7344\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 92.252831\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 97.279633\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 92.411667\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 94.323761\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 93.728256\n",
      "====> Test set loss: 95.3972\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 91.287750\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 97.864929\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 93.831024\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 96.790710\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 92.934929\n",
      "====> Test set loss: 95.3941\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 93.513351\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 93.230942\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 94.173325\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 93.762009\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 95.224220\n",
      "====> Test set loss: 95.2695\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 97.438438\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 95.395683\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 87.768829\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 96.564224\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 93.870125\n",
      "====> Test set loss: 95.1676\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 96.779449\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 93.818169\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 91.916496\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 93.667236\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 95.814072\n",
      "====> Test set loss: 95.1743\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 95.136581\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 94.693604\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 94.090500\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 94.612854\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 94.638931\n",
      "====> Test set loss: 95.0058\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 94.581200\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 89.990097\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 96.778130\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 96.296524\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 94.993896\n",
      "====> Test set loss: 95.0852\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 96.586029\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 96.805527\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 93.215012\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 90.584702\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 90.433441\n",
      "====> Test set loss: 95.1467\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 94.618446\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 94.803375\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 92.381042\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 92.728256\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 92.734222\n",
      "====> Test set loss: 94.7399\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 93.941818\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 91.150101\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 96.149445\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 91.923309\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 90.559944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 94.6370\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 93.710716\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 92.866791\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 94.809052\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 94.842438\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 93.337463\n",
      "====> Test set loss: 94.6565\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 91.859718\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 93.317459\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 93.098419\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 91.463608\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 96.035759\n",
      "====> Test set loss: 94.7044\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 89.144806\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 94.392471\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 94.211243\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 92.439774\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 91.715797\n",
      "====> Test set loss: 94.5726\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 95.077194\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 87.850372\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 98.199646\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 91.433060\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 95.916702\n",
      "====> Test set loss: 94.5309\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 95.089561\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 93.008041\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 90.668564\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 97.463867\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 89.749290\n",
      "====> Test set loss: 94.2874\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 90.796761\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 90.590675\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 92.497269\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 91.070877\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 89.188644\n",
      "====> Test set loss: 94.2958\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 91.914856\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 92.662689\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 94.239861\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 99.105499\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 90.371071\n",
      "====> Test set loss: 106.8035\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 107.554749\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 104.978027\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 102.924644\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 101.490631\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 114.459175\n",
      "====> Test set loss: 104.5031\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 101.014374\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 107.914825\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 111.187485\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 111.177170\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 111.840263\n",
      "====> Test set loss: 113.2632\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 113.553940\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 105.216721\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 106.473595\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 109.253342\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 123.379807\n",
      "====> Test set loss: 109.6053\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 112.262115\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 119.377975\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 110.320541\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 130.714111\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 111.392746\n",
      "====> Test set loss: 113.9040\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 382.124084\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 185.104797\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 145.782837\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 135.896271\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 129.402283\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 122.178558\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 121.428574\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 128.414932\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 116.206894\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 119.236557\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 115.021385\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 118.783607\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 112.328629\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 112.398193\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 114.518768\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 118.654358\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 109.722427\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 111.726898\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 109.955429\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 115.596619\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 110.088364\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 110.452637\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 110.980972\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 116.095291\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 106.229614\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 110.630814\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 108.325058\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 112.682320\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 108.459305\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 109.364014\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 109.293236\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 114.585495\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 107.247543\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 108.762489\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 106.636894\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 112.798843\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 106.538216\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 108.521820\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 108.682816\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 113.005424\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 105.989960\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 108.832947\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 107.564499\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 110.300095\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 105.107361\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 106.404877\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 108.196091\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 112.248978\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 104.255699\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 106.036583\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 105.095894\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 110.039772\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 105.877502\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 105.226852\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 105.411140\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 111.621315\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 105.291336\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 107.837242\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 106.098869\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 109.748993\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 105.053925\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 104.866440\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 105.384964\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 111.439705\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 104.064644\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 105.588310\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 104.407585\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 109.453835\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 105.430550\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 105.654251\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 105.649155\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 112.002014\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 102.353409\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 106.395432\n",
      "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 104.941986\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 109.877991\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 104.207382\n",
      "Train Epoch: 10 [6400/10000 (63%)]\tLoss: 105.291191\n",
      "Train Epoch: 10 [7680/10000 (76%)]\tLoss: 105.242378\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 111.007462\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 103.678650\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 105.424820\n",
      "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 104.481377\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 107.429520\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 104.601440\n",
      "Train Epoch: 11 [6400/10000 (63%)]\tLoss: 104.940826\n",
      "Train Epoch: 11 [7680/10000 (76%)]\tLoss: 106.842331\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 111.506927\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 103.390182\n",
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 103.929382\n",
      "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 103.989395\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 109.362740\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 104.902954\n",
      "Train Epoch: 12 [6400/10000 (63%)]\tLoss: 105.348732\n",
      "Train Epoch: 12 [7680/10000 (76%)]\tLoss: 104.759003\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 109.436646\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 102.283188\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 105.821411\n",
      "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 104.198441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 108.169350\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 103.717850\n",
      "Train Epoch: 13 [6400/10000 (63%)]\tLoss: 104.303154\n",
      "Train Epoch: 13 [7680/10000 (76%)]\tLoss: 105.359558\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 111.423729\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 103.145050\n",
      "Train Epoch: 14 [1280/10000 (13%)]\tLoss: 104.264183\n",
      "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 103.002045\n",
      "Train Epoch: 14 [3840/10000 (38%)]\tLoss: 107.406998\n",
      "Train Epoch: 14 [5120/10000 (51%)]\tLoss: 103.547882\n",
      "Train Epoch: 14 [6400/10000 (63%)]\tLoss: 104.756653\n",
      "Train Epoch: 14 [7680/10000 (76%)]\tLoss: 104.949280\n",
      "Train Epoch: 14 [8960/10000 (89%)]\tLoss: 109.239250\n",
      "Train Epoch: 15 [0/10000 (0%)]\tLoss: 100.561607\n",
      "Train Epoch: 15 [1280/10000 (13%)]\tLoss: 104.629578\n",
      "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 103.101044\n",
      "Train Epoch: 15 [3840/10000 (38%)]\tLoss: 107.216583\n",
      "Train Epoch: 15 [5120/10000 (51%)]\tLoss: 103.726311\n",
      "Train Epoch: 15 [6400/10000 (63%)]\tLoss: 103.576431\n",
      "Train Epoch: 15 [7680/10000 (76%)]\tLoss: 103.376831\n",
      "Train Epoch: 15 [8960/10000 (89%)]\tLoss: 109.608940\n",
      "Train Epoch: 16 [0/10000 (0%)]\tLoss: 101.228195\n",
      "Train Epoch: 16 [1280/10000 (13%)]\tLoss: 103.952820\n",
      "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 103.656601\n",
      "Train Epoch: 16 [3840/10000 (38%)]\tLoss: 106.673111\n",
      "Train Epoch: 16 [5120/10000 (51%)]\tLoss: 102.629532\n",
      "Train Epoch: 16 [6400/10000 (63%)]\tLoss: 103.642990\n",
      "Train Epoch: 16 [7680/10000 (76%)]\tLoss: 105.499908\n",
      "Train Epoch: 16 [8960/10000 (89%)]\tLoss: 109.519981\n",
      "Train Epoch: 17 [0/10000 (0%)]\tLoss: 100.877151\n",
      "Train Epoch: 17 [1280/10000 (13%)]\tLoss: 103.285797\n",
      "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 103.122086\n",
      "Train Epoch: 17 [3840/10000 (38%)]\tLoss: 107.987228\n",
      "Train Epoch: 17 [5120/10000 (51%)]\tLoss: 103.822525\n",
      "Train Epoch: 17 [6400/10000 (63%)]\tLoss: 103.999680\n",
      "Train Epoch: 17 [7680/10000 (76%)]\tLoss: 104.892250\n",
      "Train Epoch: 17 [8960/10000 (89%)]\tLoss: 109.006424\n",
      "Train Epoch: 18 [0/10000 (0%)]\tLoss: 100.405006\n",
      "Train Epoch: 18 [1280/10000 (13%)]\tLoss: 104.537704\n",
      "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 102.880173\n",
      "Train Epoch: 18 [3840/10000 (38%)]\tLoss: 107.800873\n",
      "Train Epoch: 18 [5120/10000 (51%)]\tLoss: 103.526215\n",
      "Train Epoch: 18 [6400/10000 (63%)]\tLoss: 104.251617\n",
      "Train Epoch: 18 [7680/10000 (76%)]\tLoss: 104.313095\n",
      "Train Epoch: 18 [8960/10000 (89%)]\tLoss: 108.991089\n",
      "Train Epoch: 19 [0/10000 (0%)]\tLoss: 101.508072\n",
      "Train Epoch: 19 [1280/10000 (13%)]\tLoss: 103.485001\n",
      "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 103.039169\n",
      "Train Epoch: 19 [3840/10000 (38%)]\tLoss: 107.350243\n",
      "Train Epoch: 19 [5120/10000 (51%)]\tLoss: 103.113068\n",
      "Train Epoch: 19 [6400/10000 (63%)]\tLoss: 104.548462\n",
      "Train Epoch: 19 [7680/10000 (76%)]\tLoss: 104.159904\n",
      "Train Epoch: 19 [8960/10000 (89%)]\tLoss: 107.619728\n",
      "Train Epoch: 20 [0/10000 (0%)]\tLoss: 99.461777\n",
      "Train Epoch: 20 [1280/10000 (13%)]\tLoss: 104.016663\n",
      "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 102.773193\n",
      "Train Epoch: 20 [3840/10000 (38%)]\tLoss: 106.485779\n",
      "Train Epoch: 20 [5120/10000 (51%)]\tLoss: 103.463173\n",
      "Train Epoch: 20 [6400/10000 (63%)]\tLoss: 103.698456\n",
      "Train Epoch: 20 [7680/10000 (76%)]\tLoss: 104.584122\n",
      "Train Epoch: 20 [8960/10000 (89%)]\tLoss: 108.103142\n",
      "Train Epoch: 21 [0/10000 (0%)]\tLoss: 102.130455\n",
      "Train Epoch: 21 [1280/10000 (13%)]\tLoss: 104.819870\n",
      "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 102.639816\n",
      "Train Epoch: 21 [3840/10000 (38%)]\tLoss: 107.141685\n",
      "Train Epoch: 21 [5120/10000 (51%)]\tLoss: 102.853348\n",
      "Train Epoch: 21 [6400/10000 (63%)]\tLoss: 103.289963\n",
      "Train Epoch: 21 [7680/10000 (76%)]\tLoss: 103.048012\n",
      "Train Epoch: 21 [8960/10000 (89%)]\tLoss: 108.192253\n",
      "Train Epoch: 22 [0/10000 (0%)]\tLoss: 101.354813\n",
      "Train Epoch: 22 [1280/10000 (13%)]\tLoss: 103.741646\n",
      "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 103.612564\n",
      "Train Epoch: 22 [3840/10000 (38%)]\tLoss: 105.193237\n",
      "Train Epoch: 22 [5120/10000 (51%)]\tLoss: 102.649384\n",
      "Train Epoch: 22 [6400/10000 (63%)]\tLoss: 104.320770\n",
      "Train Epoch: 22 [7680/10000 (76%)]\tLoss: 103.982681\n",
      "Train Epoch: 22 [8960/10000 (89%)]\tLoss: 108.274582\n",
      "Train Epoch: 23 [0/10000 (0%)]\tLoss: 100.264107\n",
      "Train Epoch: 23 [1280/10000 (13%)]\tLoss: 102.671677\n",
      "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 102.243950\n",
      "Train Epoch: 23 [3840/10000 (38%)]\tLoss: 106.632492\n",
      "Train Epoch: 23 [5120/10000 (51%)]\tLoss: 103.344803\n",
      "Train Epoch: 23 [6400/10000 (63%)]\tLoss: 104.107605\n",
      "Train Epoch: 23 [7680/10000 (76%)]\tLoss: 103.683159\n",
      "Train Epoch: 23 [8960/10000 (89%)]\tLoss: 107.432335\n",
      "Train Epoch: 24 [0/10000 (0%)]\tLoss: 99.289780\n",
      "Train Epoch: 24 [1280/10000 (13%)]\tLoss: 103.262474\n",
      "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 103.484985\n",
      "Train Epoch: 24 [3840/10000 (38%)]\tLoss: 106.564278\n",
      "Train Epoch: 24 [5120/10000 (51%)]\tLoss: 103.626183\n",
      "Train Epoch: 24 [6400/10000 (63%)]\tLoss: 103.625389\n",
      "Train Epoch: 24 [7680/10000 (76%)]\tLoss: 105.260849\n",
      "Train Epoch: 24 [8960/10000 (89%)]\tLoss: 109.179764\n",
      "Train Epoch: 25 [0/10000 (0%)]\tLoss: 100.886559\n",
      "Train Epoch: 25 [1280/10000 (13%)]\tLoss: 104.670235\n",
      "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 103.255325\n",
      "Train Epoch: 25 [3840/10000 (38%)]\tLoss: 106.874649\n",
      "Train Epoch: 25 [5120/10000 (51%)]\tLoss: 102.174370\n",
      "Train Epoch: 25 [6400/10000 (63%)]\tLoss: 102.517090\n",
      "Train Epoch: 25 [7680/10000 (76%)]\tLoss: 105.492722\n",
      "Train Epoch: 25 [8960/10000 (89%)]\tLoss: 107.480438\n",
      "Train Epoch: 26 [0/10000 (0%)]\tLoss: 100.831230\n",
      "Train Epoch: 26 [1280/10000 (13%)]\tLoss: 103.683754\n",
      "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 102.664665\n",
      "Train Epoch: 26 [3840/10000 (38%)]\tLoss: 106.250153\n",
      "Train Epoch: 26 [5120/10000 (51%)]\tLoss: 103.780380\n",
      "Train Epoch: 26 [6400/10000 (63%)]\tLoss: 102.985512\n",
      "Train Epoch: 26 [7680/10000 (76%)]\tLoss: 103.926491\n",
      "Train Epoch: 26 [8960/10000 (89%)]\tLoss: 108.619331\n",
      "Train Epoch: 27 [0/10000 (0%)]\tLoss: 100.614182\n",
      "Train Epoch: 27 [1280/10000 (13%)]\tLoss: 104.057442\n",
      "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 103.187309\n",
      "Train Epoch: 27 [3840/10000 (38%)]\tLoss: 106.280075\n",
      "Train Epoch: 27 [5120/10000 (51%)]\tLoss: 102.902130\n",
      "Train Epoch: 27 [6400/10000 (63%)]\tLoss: 102.027496\n",
      "Train Epoch: 27 [7680/10000 (76%)]\tLoss: 103.779945\n",
      "Train Epoch: 27 [8960/10000 (89%)]\tLoss: 107.297363\n",
      "Train Epoch: 28 [0/10000 (0%)]\tLoss: 100.915405\n",
      "Train Epoch: 28 [1280/10000 (13%)]\tLoss: 102.611549\n",
      "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 101.972305\n",
      "Train Epoch: 28 [3840/10000 (38%)]\tLoss: 106.384857\n",
      "Train Epoch: 28 [5120/10000 (51%)]\tLoss: 102.149300\n",
      "Train Epoch: 28 [6400/10000 (63%)]\tLoss: 103.151024\n",
      "Train Epoch: 28 [7680/10000 (76%)]\tLoss: 103.195961\n",
      "Train Epoch: 28 [8960/10000 (89%)]\tLoss: 107.837265\n",
      "Train Epoch: 29 [0/10000 (0%)]\tLoss: 100.673965\n",
      "Train Epoch: 29 [1280/10000 (13%)]\tLoss: 101.538261\n",
      "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 103.680634\n",
      "Train Epoch: 29 [3840/10000 (38%)]\tLoss: 106.535507\n",
      "Train Epoch: 29 [5120/10000 (51%)]\tLoss: 102.706085\n",
      "Train Epoch: 29 [6400/10000 (63%)]\tLoss: 102.947266\n",
      "Train Epoch: 29 [7680/10000 (76%)]\tLoss: 104.371643\n",
      "Train Epoch: 29 [8960/10000 (89%)]\tLoss: 108.650993\n",
      "Train Epoch: 30 [0/10000 (0%)]\tLoss: 101.122162\n",
      "Train Epoch: 30 [1280/10000 (13%)]\tLoss: 102.818459\n",
      "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 103.394623\n",
      "Train Epoch: 30 [3840/10000 (38%)]\tLoss: 106.997696\n",
      "Train Epoch: 30 [5120/10000 (51%)]\tLoss: 102.406006\n",
      "Train Epoch: 30 [6400/10000 (63%)]\tLoss: 104.005005\n",
      "Train Epoch: 30 [7680/10000 (76%)]\tLoss: 103.597031\n",
      "Train Epoch: 30 [8960/10000 (89%)]\tLoss: 107.215645\n",
      "Train Epoch: 31 [0/10000 (0%)]\tLoss: 99.417068\n",
      "Train Epoch: 31 [1280/10000 (13%)]\tLoss: 102.981598\n",
      "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 102.588554\n",
      "Train Epoch: 31 [3840/10000 (38%)]\tLoss: 107.069992\n",
      "Train Epoch: 31 [5120/10000 (51%)]\tLoss: 101.829361\n",
      "Train Epoch: 31 [6400/10000 (63%)]\tLoss: 102.627014\n",
      "Train Epoch: 31 [7680/10000 (76%)]\tLoss: 104.084076\n",
      "Train Epoch: 31 [8960/10000 (89%)]\tLoss: 107.406410\n",
      "Train Epoch: 32 [0/10000 (0%)]\tLoss: 99.135696\n",
      "Train Epoch: 32 [1280/10000 (13%)]\tLoss: 101.893204\n",
      "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 103.659584\n",
      "Train Epoch: 32 [3840/10000 (38%)]\tLoss: 106.304359\n",
      "Train Epoch: 32 [5120/10000 (51%)]\tLoss: 102.832672\n",
      "Train Epoch: 32 [6400/10000 (63%)]\tLoss: 103.423782\n",
      "Train Epoch: 32 [7680/10000 (76%)]\tLoss: 103.065140\n",
      "Train Epoch: 32 [8960/10000 (89%)]\tLoss: 108.228157\n",
      "Train Epoch: 33 [0/10000 (0%)]\tLoss: 100.765091\n",
      "Train Epoch: 33 [1280/10000 (13%)]\tLoss: 102.354324\n",
      "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 102.527374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [3840/10000 (38%)]\tLoss: 106.979538\n",
      "Train Epoch: 33 [5120/10000 (51%)]\tLoss: 102.294876\n",
      "Train Epoch: 33 [6400/10000 (63%)]\tLoss: 103.182457\n",
      "Train Epoch: 33 [7680/10000 (76%)]\tLoss: 104.700455\n",
      "Train Epoch: 33 [8960/10000 (89%)]\tLoss: 107.076859\n",
      "Train Epoch: 34 [0/10000 (0%)]\tLoss: 99.414047\n",
      "Train Epoch: 34 [1280/10000 (13%)]\tLoss: 102.691185\n",
      "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 102.520622\n",
      "Train Epoch: 34 [3840/10000 (38%)]\tLoss: 105.914490\n",
      "Train Epoch: 34 [5120/10000 (51%)]\tLoss: 102.460892\n",
      "Train Epoch: 34 [6400/10000 (63%)]\tLoss: 103.530167\n",
      "Train Epoch: 34 [7680/10000 (76%)]\tLoss: 103.832413\n",
      "Train Epoch: 34 [8960/10000 (89%)]\tLoss: 107.510376\n",
      "Train Epoch: 35 [0/10000 (0%)]\tLoss: 99.264885\n",
      "Train Epoch: 35 [1280/10000 (13%)]\tLoss: 102.136963\n",
      "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 102.543320\n",
      "Train Epoch: 35 [3840/10000 (38%)]\tLoss: 106.843147\n",
      "Train Epoch: 35 [5120/10000 (51%)]\tLoss: 102.710907\n",
      "Train Epoch: 35 [6400/10000 (63%)]\tLoss: 103.118172\n",
      "Train Epoch: 35 [7680/10000 (76%)]\tLoss: 102.829239\n",
      "Train Epoch: 35 [8960/10000 (89%)]\tLoss: 107.044464\n",
      "Train Epoch: 36 [0/10000 (0%)]\tLoss: 100.182190\n",
      "Train Epoch: 36 [1280/10000 (13%)]\tLoss: 102.630592\n",
      "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 102.522873\n",
      "Train Epoch: 36 [3840/10000 (38%)]\tLoss: 106.813560\n",
      "Train Epoch: 36 [5120/10000 (51%)]\tLoss: 102.306999\n",
      "Train Epoch: 36 [6400/10000 (63%)]\tLoss: 102.835144\n",
      "Train Epoch: 36 [7680/10000 (76%)]\tLoss: 102.725006\n",
      "Train Epoch: 36 [8960/10000 (89%)]\tLoss: 106.350830\n",
      "Train Epoch: 37 [0/10000 (0%)]\tLoss: 99.297455\n",
      "Train Epoch: 37 [1280/10000 (13%)]\tLoss: 103.142288\n",
      "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 102.027031\n",
      "Train Epoch: 37 [3840/10000 (38%)]\tLoss: 107.727783\n",
      "Train Epoch: 37 [5120/10000 (51%)]\tLoss: 101.695084\n",
      "Train Epoch: 37 [6400/10000 (63%)]\tLoss: 102.922516\n",
      "Train Epoch: 37 [7680/10000 (76%)]\tLoss: 102.816040\n",
      "Train Epoch: 37 [8960/10000 (89%)]\tLoss: 106.740257\n",
      "Train Epoch: 38 [0/10000 (0%)]\tLoss: 100.050964\n",
      "Train Epoch: 38 [1280/10000 (13%)]\tLoss: 103.540085\n",
      "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 102.272491\n",
      "Train Epoch: 38 [3840/10000 (38%)]\tLoss: 105.316513\n",
      "Train Epoch: 38 [5120/10000 (51%)]\tLoss: 101.854889\n",
      "Train Epoch: 38 [6400/10000 (63%)]\tLoss: 103.279373\n",
      "Train Epoch: 38 [7680/10000 (76%)]\tLoss: 102.866806\n",
      "Train Epoch: 38 [8960/10000 (89%)]\tLoss: 107.267990\n",
      "Train Epoch: 39 [0/10000 (0%)]\tLoss: 99.836151\n",
      "Train Epoch: 39 [1280/10000 (13%)]\tLoss: 103.885086\n",
      "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 102.989662\n",
      "Train Epoch: 39 [3840/10000 (38%)]\tLoss: 105.315231\n",
      "Train Epoch: 39 [5120/10000 (51%)]\tLoss: 102.461617\n",
      "Train Epoch: 39 [6400/10000 (63%)]\tLoss: 102.453148\n",
      "Train Epoch: 39 [7680/10000 (76%)]\tLoss: 103.414551\n",
      "Train Epoch: 39 [8960/10000 (89%)]\tLoss: 108.352295\n",
      "Train Epoch: 40 [0/10000 (0%)]\tLoss: 100.330963\n",
      "Train Epoch: 40 [1280/10000 (13%)]\tLoss: 103.181496\n",
      "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 103.055611\n",
      "Train Epoch: 40 [3840/10000 (38%)]\tLoss: 105.856430\n",
      "Train Epoch: 40 [5120/10000 (51%)]\tLoss: 101.494568\n",
      "Train Epoch: 40 [6400/10000 (63%)]\tLoss: 103.301743\n",
      "Train Epoch: 40 [7680/10000 (76%)]\tLoss: 103.193741\n",
      "Train Epoch: 40 [8960/10000 (89%)]\tLoss: 106.608932\n",
      "Train Epoch: 0 [0/10000 (0%)]\tLoss: 94.069733\n",
      "Train Epoch: 0 [1280/10000 (13%)]\tLoss: 98.729347\n",
      "Train Epoch: 0 [2560/10000 (25%)]\tLoss: 97.401939\n",
      "Train Epoch: 0 [3840/10000 (38%)]\tLoss: 101.938782\n",
      "Train Epoch: 0 [5120/10000 (51%)]\tLoss: 97.779366\n",
      "Train Epoch: 0 [6400/10000 (63%)]\tLoss: 98.103882\n",
      "Train Epoch: 0 [7680/10000 (76%)]\tLoss: 97.237030\n",
      "Train Epoch: 0 [8960/10000 (89%)]\tLoss: 102.933334\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 94.275558\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 98.212997\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 97.737640\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 101.369171\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 98.698975\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 98.736633\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 98.818558\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 100.865356\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 94.159271\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 97.434509\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 97.234467\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 100.306206\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 98.019844\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 99.121376\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 99.437347\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 102.281631\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 94.084274\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 97.547752\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 97.985214\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 101.071564\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 98.149948\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 98.716049\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 99.259430\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 102.150139\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 94.201523\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 98.083115\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 98.528275\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 102.054794\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 97.999756\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 97.852211\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 98.618164\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 102.494064\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 94.935654\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 97.494072\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 97.383484\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 101.948082\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 98.835068\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 98.123962\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 97.946198\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 102.234467\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 94.409103\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 97.724182\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 97.092682\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 101.532204\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 98.182297\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 98.630783\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 98.658554\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 101.798668\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 94.424484\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 98.052696\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 98.145882\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 101.408508\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 97.910507\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 97.881386\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 98.208908\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 102.611610\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 93.257385\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 97.582695\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 97.526306\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 102.030418\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 98.783989\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 98.991844\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 98.608734\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 102.114014\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 93.948547\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 97.122292\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 98.101135\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 101.255600\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 97.852814\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 97.905533\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 97.973160\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 101.528641\n",
      "====> Test set NLL: 96.8194\n",
      "Running time: 7943.390625 Seconds\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to fashionmnist_data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fashionmnist_data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to fashionmnist_data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to fashionmnist_data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fashionmnist_data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to fashionmnist_data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to fashionmnist_data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fashionmnist_data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to fashionmnist_data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to fashionmnist_data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fashionmnist_data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to fashionmnist_data\\FashionMNIST\\raw\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 688.837402\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 317.168427\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 264.555023\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 266.646545\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 264.577209\n",
      "====> Test set loss: 258.2698\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 255.412384\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 252.168579\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 262.611542\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 234.400391\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 248.821625\n",
      "====> Test set loss: 250.9579\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 250.182159\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 244.472382\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 250.930069\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 248.503479\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 240.580261\n",
      "====> Test set loss: 247.9019\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 246.879959\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 244.320984\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 241.292099\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 243.547699\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 246.005737\n",
      "====> Test set loss: 245.6281\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 247.747589\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 239.961517\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 233.907959\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 244.545654\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 262.835388\n",
      "====> Test set loss: 244.0494\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 246.206146\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 241.865295\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 245.048035\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 241.431763\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 256.857269\n",
      "====> Test set loss: 246.0073\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 251.888306\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 239.907532\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 242.128723\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 249.583649\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 242.951645\n",
      "====> Test set loss: 258.9976\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 256.218201\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 258.213226\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 237.279999\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 258.511017\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 248.154129\n",
      "====> Test set loss: 270.6588\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 271.976624\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 263.755554\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 243.263458\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 260.371429\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 259.169128\n",
      "====> Test set loss: 258.2443\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 245.573242\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 268.894348\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 261.710205\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 252.806198\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 263.564087\n",
      "====> Test set loss: 264.0515\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 262.899994\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 270.347137\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 248.733124\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 256.166382\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 275.464264\n",
      "====> Test set loss: 266.3973\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 257.234741\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 254.920013\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 259.666199\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 266.771271\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 262.087402\n",
      "====> Test set loss: 260.9879\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 263.742249\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 292.814301\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 260.335022\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 264.846497\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 272.010376\n",
      "====> Test set loss: 262.4643\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 258.811676\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 255.427460\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 291.056458\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 273.357788\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 277.107300\n",
      "====> Test set loss: 271.1788\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 272.151917\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 273.096100\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 244.610321\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 264.136719\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 268.050934\n",
      "====> Test set loss: 276.6870\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 266.198486\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 288.730347\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 275.670654\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 286.193787\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 274.029999\n",
      "====> Test set loss: 271.7624\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 260.082397\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 264.642578\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 274.475922\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 284.269531\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 285.425964\n",
      "====> Test set loss: 273.6716\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 276.628235\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 270.981934\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 305.831970\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 271.796570\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 285.950043\n",
      "====> Test set loss: 273.4859\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 281.815002\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 280.193420\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 263.681183\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 273.815369\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 260.276947\n",
      "====> Test set loss: 271.5053\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 267.998901\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 276.021362\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 271.223358\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 266.799500\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 257.074615\n",
      "====> Test set loss: 283.0969\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 282.675842\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 269.369385\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 254.550644\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 271.998169\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 263.801819\n",
      "====> Test set loss: 289.6180\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 290.393524\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 270.000366\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 296.614929\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 272.263641\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 285.156647\n",
      "====> Test set loss: 286.6373\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 277.644470\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 283.463684\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 271.039001\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 278.623352\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 311.096191\n",
      "====> Test set loss: 284.4428\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 283.759888\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 274.749329\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 274.260651\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 275.621826\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 282.628601\n",
      "====> Test set loss: 284.0972\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 276.177612\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 279.511597\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 282.213074\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 275.350098\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 270.694031\n",
      "====> Test set loss: 287.4722\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 286.626282\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 277.906952\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 294.504608\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 284.674377\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 304.527039\n",
      "====> Test set loss: 304.6278\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 302.567810\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 297.735779\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 301.007019\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 307.342896\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 289.795807\n",
      "====> Test set loss: 300.3455\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 293.442261\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 313.329712\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 302.497498\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 296.388000\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 310.759460\n",
      "====> Test set loss: 294.1909\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 291.325317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 284.450775\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 302.855469\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 298.747162\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 287.803192\n",
      "====> Test set loss: 287.6420\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 297.554321\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 273.158630\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 284.778259\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 295.366089\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 288.788086\n",
      "====> Test set loss: 291.7893\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 299.783630\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 274.204193\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 307.597778\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 288.538757\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 284.513519\n",
      "====> Test set loss: 324.5279\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 316.756470\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 337.086121\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 346.083618\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 313.109222\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 325.891296\n",
      "====> Test set loss: 317.0475\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 314.395996\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 306.584106\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 283.115692\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 292.094299\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 313.753967\n",
      "====> Test set loss: 311.3809\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 311.366760\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 312.789795\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 326.824402\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 355.094116\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 357.723022\n",
      "====> Test set loss: 308.5773\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 308.768951\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 319.374390\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 312.743042\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 316.256409\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 322.291809\n",
      "====> Test set loss: 311.3539\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 313.281555\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 345.101898\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 306.835907\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 318.841919\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 351.086121\n",
      "====> Test set loss: 321.2123\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 321.966278\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 306.686401\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 319.697815\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 331.126526\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 319.438599\n",
      "====> Test set loss: 359.3398\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 359.350708\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 297.893311\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 310.419861\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 321.556335\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 337.482635\n",
      "====> Test set loss: 322.3713\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 305.727783\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 313.456268\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 303.188232\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 313.901123\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 308.782867\n",
      "====> Test set loss: 304.8240\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 299.472595\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 350.195374\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 330.735352\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 301.407867\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 321.762024\n",
      "====> Test set loss: 332.7388\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 461.169830\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 313.601013\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 301.886627\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 279.304993\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 273.511353\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 269.714813\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 263.317719\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 280.426514\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 271.503448\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 271.696167\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 280.037384\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 266.697693\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 263.718872\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 265.419006\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 257.850769\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 275.931396\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 262.835571\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 270.352661\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 278.179260\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 264.606140\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 262.338074\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 263.579468\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 256.353973\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 277.073181\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 263.929138\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 269.615265\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 276.963898\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 263.471008\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 263.449463\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 263.659607\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 256.128418\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 275.324402\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 261.239410\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 268.824860\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 276.731323\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 264.331757\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 261.421570\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 261.627136\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 255.209030\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 275.778259\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 262.180725\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 268.623993\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 276.700134\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 264.402954\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 261.306946\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 263.083923\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 255.498962\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 274.691772\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 260.626495\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 267.704620\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 276.038483\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 264.047668\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 260.539215\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 261.572083\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 255.371078\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 274.435120\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 264.854523\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 267.931580\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 273.794189\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 262.492188\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 262.350708\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 263.330536\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 255.178925\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 274.315460\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 261.465515\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 267.429504\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 275.005829\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 262.891083\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 260.810547\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 263.350525\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 254.613846\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 274.507935\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 260.934326\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 266.461304\n",
      "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 273.785034\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 262.316467\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 259.284973\n",
      "Train Epoch: 10 [6400/10000 (63%)]\tLoss: 262.066345\n",
      "Train Epoch: 10 [7680/10000 (76%)]\tLoss: 254.425354\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 273.357300\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 258.831146\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 268.304291\n",
      "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 275.556335\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 261.780029\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 260.116913\n",
      "Train Epoch: 11 [6400/10000 (63%)]\tLoss: 262.183960\n",
      "Train Epoch: 11 [7680/10000 (76%)]\tLoss: 254.640228\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 275.820068\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 260.495544\n",
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 267.973511\n",
      "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 274.466583\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 263.379181\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 259.734192\n",
      "Train Epoch: 12 [6400/10000 (63%)]\tLoss: 262.066315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [7680/10000 (76%)]\tLoss: 254.497131\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 274.244385\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 259.646973\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 266.992462\n",
      "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 275.622986\n",
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 262.443298\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 259.131836\n",
      "Train Epoch: 13 [6400/10000 (63%)]\tLoss: 262.643860\n",
      "Train Epoch: 13 [7680/10000 (76%)]\tLoss: 254.225449\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 272.614990\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 259.448914\n",
      "Train Epoch: 14 [1280/10000 (13%)]\tLoss: 266.583008\n",
      "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 275.849487\n",
      "Train Epoch: 14 [3840/10000 (38%)]\tLoss: 263.315735\n",
      "Train Epoch: 14 [5120/10000 (51%)]\tLoss: 260.185394\n",
      "Train Epoch: 14 [6400/10000 (63%)]\tLoss: 261.654144\n",
      "Train Epoch: 14 [7680/10000 (76%)]\tLoss: 254.944199\n",
      "Train Epoch: 14 [8960/10000 (89%)]\tLoss: 273.074890\n",
      "Train Epoch: 15 [0/10000 (0%)]\tLoss: 259.400024\n",
      "Train Epoch: 15 [1280/10000 (13%)]\tLoss: 268.395569\n",
      "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 275.992676\n",
      "Train Epoch: 15 [3840/10000 (38%)]\tLoss: 262.367798\n",
      "Train Epoch: 15 [5120/10000 (51%)]\tLoss: 260.191589\n",
      "Train Epoch: 15 [6400/10000 (63%)]\tLoss: 262.196960\n",
      "Train Epoch: 15 [7680/10000 (76%)]\tLoss: 254.485550\n",
      "Train Epoch: 15 [8960/10000 (89%)]\tLoss: 272.098389\n",
      "Train Epoch: 16 [0/10000 (0%)]\tLoss: 259.768738\n",
      "Train Epoch: 16 [1280/10000 (13%)]\tLoss: 266.972229\n",
      "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 274.800903\n",
      "Train Epoch: 16 [3840/10000 (38%)]\tLoss: 261.642059\n",
      "Train Epoch: 16 [5120/10000 (51%)]\tLoss: 259.571106\n",
      "Train Epoch: 16 [6400/10000 (63%)]\tLoss: 262.084045\n",
      "Train Epoch: 16 [7680/10000 (76%)]\tLoss: 254.760300\n",
      "Train Epoch: 16 [8960/10000 (89%)]\tLoss: 274.127411\n",
      "Train Epoch: 17 [0/10000 (0%)]\tLoss: 259.918671\n",
      "Train Epoch: 17 [1280/10000 (13%)]\tLoss: 265.034180\n",
      "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 275.022644\n",
      "Train Epoch: 17 [3840/10000 (38%)]\tLoss: 261.984283\n",
      "Train Epoch: 17 [5120/10000 (51%)]\tLoss: 259.680206\n",
      "Train Epoch: 17 [6400/10000 (63%)]\tLoss: 262.183990\n",
      "Train Epoch: 17 [7680/10000 (76%)]\tLoss: 254.947433\n",
      "Train Epoch: 17 [8960/10000 (89%)]\tLoss: 273.363098\n",
      "Train Epoch: 18 [0/10000 (0%)]\tLoss: 259.872803\n",
      "Train Epoch: 18 [1280/10000 (13%)]\tLoss: 265.886627\n",
      "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 274.152161\n",
      "Train Epoch: 18 [3840/10000 (38%)]\tLoss: 262.858398\n",
      "Train Epoch: 18 [5120/10000 (51%)]\tLoss: 258.352325\n",
      "Train Epoch: 18 [6400/10000 (63%)]\tLoss: 262.044189\n",
      "Train Epoch: 18 [7680/10000 (76%)]\tLoss: 254.651138\n",
      "Train Epoch: 18 [8960/10000 (89%)]\tLoss: 274.594482\n",
      "Train Epoch: 19 [0/10000 (0%)]\tLoss: 259.525085\n",
      "Train Epoch: 19 [1280/10000 (13%)]\tLoss: 267.119751\n",
      "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 274.138794\n",
      "Train Epoch: 19 [3840/10000 (38%)]\tLoss: 261.934570\n",
      "Train Epoch: 19 [5120/10000 (51%)]\tLoss: 259.012115\n",
      "Train Epoch: 19 [6400/10000 (63%)]\tLoss: 260.426575\n",
      "Train Epoch: 19 [7680/10000 (76%)]\tLoss: 253.499222\n",
      "Train Epoch: 19 [8960/10000 (89%)]\tLoss: 272.983826\n",
      "Train Epoch: 20 [0/10000 (0%)]\tLoss: 260.802368\n",
      "Train Epoch: 20 [1280/10000 (13%)]\tLoss: 267.678406\n",
      "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 274.711761\n",
      "Train Epoch: 20 [3840/10000 (38%)]\tLoss: 262.441772\n",
      "Train Epoch: 20 [5120/10000 (51%)]\tLoss: 258.783020\n",
      "Train Epoch: 20 [6400/10000 (63%)]\tLoss: 263.205048\n",
      "Train Epoch: 20 [7680/10000 (76%)]\tLoss: 254.311676\n",
      "Train Epoch: 20 [8960/10000 (89%)]\tLoss: 274.292297\n",
      "Train Epoch: 21 [0/10000 (0%)]\tLoss: 259.062744\n",
      "Train Epoch: 21 [1280/10000 (13%)]\tLoss: 267.691681\n",
      "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 274.858215\n",
      "Train Epoch: 21 [3840/10000 (38%)]\tLoss: 263.359375\n",
      "Train Epoch: 21 [5120/10000 (51%)]\tLoss: 258.760437\n",
      "Train Epoch: 21 [6400/10000 (63%)]\tLoss: 261.129639\n",
      "Train Epoch: 21 [7680/10000 (76%)]\tLoss: 253.988358\n",
      "Train Epoch: 21 [8960/10000 (89%)]\tLoss: 272.166443\n",
      "Train Epoch: 22 [0/10000 (0%)]\tLoss: 259.308807\n",
      "Train Epoch: 22 [1280/10000 (13%)]\tLoss: 267.168579\n",
      "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 274.483521\n",
      "Train Epoch: 22 [3840/10000 (38%)]\tLoss: 261.474457\n",
      "Train Epoch: 22 [5120/10000 (51%)]\tLoss: 259.845032\n",
      "Train Epoch: 22 [6400/10000 (63%)]\tLoss: 261.152039\n",
      "Train Epoch: 22 [7680/10000 (76%)]\tLoss: 253.532593\n",
      "Train Epoch: 22 [8960/10000 (89%)]\tLoss: 273.079529\n",
      "Train Epoch: 23 [0/10000 (0%)]\tLoss: 258.443359\n",
      "Train Epoch: 23 [1280/10000 (13%)]\tLoss: 266.018921\n",
      "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 274.740417\n",
      "Train Epoch: 23 [3840/10000 (38%)]\tLoss: 261.819031\n",
      "Train Epoch: 23 [5120/10000 (51%)]\tLoss: 258.752197\n",
      "Train Epoch: 23 [6400/10000 (63%)]\tLoss: 262.484467\n",
      "Train Epoch: 23 [7680/10000 (76%)]\tLoss: 254.593262\n",
      "Train Epoch: 23 [8960/10000 (89%)]\tLoss: 273.354889\n",
      "Train Epoch: 24 [0/10000 (0%)]\tLoss: 260.906067\n",
      "Train Epoch: 24 [1280/10000 (13%)]\tLoss: 266.950897\n",
      "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 274.127045\n",
      "Train Epoch: 24 [3840/10000 (38%)]\tLoss: 261.007202\n",
      "Train Epoch: 24 [5120/10000 (51%)]\tLoss: 258.103302\n",
      "Train Epoch: 24 [6400/10000 (63%)]\tLoss: 261.759186\n",
      "Train Epoch: 24 [7680/10000 (76%)]\tLoss: 254.746033\n",
      "Train Epoch: 24 [8960/10000 (89%)]\tLoss: 272.261078\n",
      "Train Epoch: 25 [0/10000 (0%)]\tLoss: 260.703979\n",
      "Train Epoch: 25 [1280/10000 (13%)]\tLoss: 267.568726\n",
      "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 273.599121\n",
      "Train Epoch: 25 [3840/10000 (38%)]\tLoss: 261.526093\n",
      "Train Epoch: 25 [5120/10000 (51%)]\tLoss: 258.592163\n",
      "Train Epoch: 25 [6400/10000 (63%)]\tLoss: 260.516785\n",
      "Train Epoch: 25 [7680/10000 (76%)]\tLoss: 253.185806\n",
      "Train Epoch: 25 [8960/10000 (89%)]\tLoss: 273.840332\n",
      "Train Epoch: 26 [0/10000 (0%)]\tLoss: 258.577972\n",
      "Train Epoch: 26 [1280/10000 (13%)]\tLoss: 266.522278\n",
      "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 273.367828\n",
      "Train Epoch: 26 [3840/10000 (38%)]\tLoss: 261.650299\n",
      "Train Epoch: 26 [5120/10000 (51%)]\tLoss: 259.256317\n",
      "Train Epoch: 26 [6400/10000 (63%)]\tLoss: 261.328552\n",
      "Train Epoch: 26 [7680/10000 (76%)]\tLoss: 252.718353\n",
      "Train Epoch: 26 [8960/10000 (89%)]\tLoss: 273.167206\n",
      "Train Epoch: 27 [0/10000 (0%)]\tLoss: 259.722137\n",
      "Train Epoch: 27 [1280/10000 (13%)]\tLoss: 264.963623\n",
      "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 274.752319\n",
      "Train Epoch: 27 [3840/10000 (38%)]\tLoss: 260.752991\n",
      "Train Epoch: 27 [5120/10000 (51%)]\tLoss: 259.099731\n",
      "Train Epoch: 27 [6400/10000 (63%)]\tLoss: 260.476013\n",
      "Train Epoch: 27 [7680/10000 (76%)]\tLoss: 253.608734\n",
      "Train Epoch: 27 [8960/10000 (89%)]\tLoss: 272.397705\n",
      "Train Epoch: 28 [0/10000 (0%)]\tLoss: 259.989288\n",
      "Train Epoch: 28 [1280/10000 (13%)]\tLoss: 266.413910\n",
      "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 273.607941\n",
      "Train Epoch: 28 [3840/10000 (38%)]\tLoss: 261.669800\n",
      "Train Epoch: 28 [5120/10000 (51%)]\tLoss: 259.336945\n",
      "Train Epoch: 28 [6400/10000 (63%)]\tLoss: 260.659088\n",
      "Train Epoch: 28 [7680/10000 (76%)]\tLoss: 253.260559\n",
      "Train Epoch: 28 [8960/10000 (89%)]\tLoss: 273.420227\n",
      "Train Epoch: 29 [0/10000 (0%)]\tLoss: 260.314209\n",
      "Train Epoch: 29 [1280/10000 (13%)]\tLoss: 266.429047\n",
      "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 274.798340\n",
      "Train Epoch: 29 [3840/10000 (38%)]\tLoss: 261.709473\n",
      "Train Epoch: 29 [5120/10000 (51%)]\tLoss: 260.316254\n",
      "Train Epoch: 29 [6400/10000 (63%)]\tLoss: 260.873413\n",
      "Train Epoch: 29 [7680/10000 (76%)]\tLoss: 253.124298\n",
      "Train Epoch: 29 [8960/10000 (89%)]\tLoss: 274.100494\n",
      "Train Epoch: 30 [0/10000 (0%)]\tLoss: 259.402679\n",
      "Train Epoch: 30 [1280/10000 (13%)]\tLoss: 265.665100\n",
      "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 273.647644\n",
      "Train Epoch: 30 [3840/10000 (38%)]\tLoss: 261.241577\n",
      "Train Epoch: 30 [5120/10000 (51%)]\tLoss: 258.261414\n",
      "Train Epoch: 30 [6400/10000 (63%)]\tLoss: 260.332275\n",
      "Train Epoch: 30 [7680/10000 (76%)]\tLoss: 253.245163\n",
      "Train Epoch: 30 [8960/10000 (89%)]\tLoss: 271.956299\n",
      "Train Epoch: 31 [0/10000 (0%)]\tLoss: 260.536011\n",
      "Train Epoch: 31 [1280/10000 (13%)]\tLoss: 266.453064\n",
      "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 274.487427\n",
      "Train Epoch: 31 [3840/10000 (38%)]\tLoss: 262.031525\n",
      "Train Epoch: 31 [5120/10000 (51%)]\tLoss: 259.579559\n",
      "Train Epoch: 31 [6400/10000 (63%)]\tLoss: 260.082947\n",
      "Train Epoch: 31 [7680/10000 (76%)]\tLoss: 252.656143\n",
      "Train Epoch: 31 [8960/10000 (89%)]\tLoss: 273.431152\n",
      "Train Epoch: 32 [0/10000 (0%)]\tLoss: 259.359985\n",
      "Train Epoch: 32 [1280/10000 (13%)]\tLoss: 266.590576\n",
      "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 274.142792\n",
      "Train Epoch: 32 [3840/10000 (38%)]\tLoss: 262.691437\n",
      "Train Epoch: 32 [5120/10000 (51%)]\tLoss: 258.069763\n",
      "Train Epoch: 32 [6400/10000 (63%)]\tLoss: 259.920044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [7680/10000 (76%)]\tLoss: 253.321304\n",
      "Train Epoch: 32 [8960/10000 (89%)]\tLoss: 272.548950\n",
      "Train Epoch: 33 [0/10000 (0%)]\tLoss: 257.854919\n",
      "Train Epoch: 33 [1280/10000 (13%)]\tLoss: 266.411560\n",
      "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 274.788239\n",
      "Train Epoch: 33 [3840/10000 (38%)]\tLoss: 262.161957\n",
      "Train Epoch: 33 [5120/10000 (51%)]\tLoss: 258.974792\n",
      "Train Epoch: 33 [6400/10000 (63%)]\tLoss: 261.568481\n",
      "Train Epoch: 33 [7680/10000 (76%)]\tLoss: 254.181213\n",
      "Train Epoch: 33 [8960/10000 (89%)]\tLoss: 272.114227\n",
      "Train Epoch: 34 [0/10000 (0%)]\tLoss: 258.809357\n",
      "Train Epoch: 34 [1280/10000 (13%)]\tLoss: 265.910828\n",
      "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 272.401184\n",
      "Train Epoch: 34 [3840/10000 (38%)]\tLoss: 261.061768\n",
      "Train Epoch: 34 [5120/10000 (51%)]\tLoss: 259.430786\n",
      "Train Epoch: 34 [6400/10000 (63%)]\tLoss: 261.251770\n",
      "Train Epoch: 34 [7680/10000 (76%)]\tLoss: 253.640045\n",
      "Train Epoch: 34 [8960/10000 (89%)]\tLoss: 272.801422\n",
      "Train Epoch: 35 [0/10000 (0%)]\tLoss: 258.171356\n",
      "Train Epoch: 35 [1280/10000 (13%)]\tLoss: 267.002258\n",
      "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 274.400421\n",
      "Train Epoch: 35 [3840/10000 (38%)]\tLoss: 261.374573\n",
      "Train Epoch: 35 [5120/10000 (51%)]\tLoss: 258.983459\n",
      "Train Epoch: 35 [6400/10000 (63%)]\tLoss: 260.517792\n",
      "Train Epoch: 35 [7680/10000 (76%)]\tLoss: 252.869659\n",
      "Train Epoch: 35 [8960/10000 (89%)]\tLoss: 272.904572\n",
      "Train Epoch: 36 [0/10000 (0%)]\tLoss: 258.835510\n",
      "Train Epoch: 36 [1280/10000 (13%)]\tLoss: 265.695221\n",
      "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 274.099640\n",
      "Train Epoch: 36 [3840/10000 (38%)]\tLoss: 260.814087\n",
      "Train Epoch: 36 [5120/10000 (51%)]\tLoss: 259.539520\n",
      "Train Epoch: 36 [6400/10000 (63%)]\tLoss: 260.167786\n",
      "Train Epoch: 36 [7680/10000 (76%)]\tLoss: 254.728073\n",
      "Train Epoch: 36 [8960/10000 (89%)]\tLoss: 273.088501\n",
      "Train Epoch: 37 [0/10000 (0%)]\tLoss: 258.566284\n",
      "Train Epoch: 37 [1280/10000 (13%)]\tLoss: 265.293213\n",
      "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 274.768066\n",
      "Train Epoch: 37 [3840/10000 (38%)]\tLoss: 260.408630\n",
      "Train Epoch: 37 [5120/10000 (51%)]\tLoss: 258.876587\n",
      "Train Epoch: 37 [6400/10000 (63%)]\tLoss: 261.428162\n",
      "Train Epoch: 37 [7680/10000 (76%)]\tLoss: 253.946350\n",
      "Train Epoch: 37 [8960/10000 (89%)]\tLoss: 271.666809\n",
      "Train Epoch: 38 [0/10000 (0%)]\tLoss: 259.884766\n",
      "Train Epoch: 38 [1280/10000 (13%)]\tLoss: 266.421631\n",
      "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 273.508972\n",
      "Train Epoch: 38 [3840/10000 (38%)]\tLoss: 262.064209\n",
      "Train Epoch: 38 [5120/10000 (51%)]\tLoss: 259.406067\n",
      "Train Epoch: 38 [6400/10000 (63%)]\tLoss: 260.672241\n",
      "Train Epoch: 38 [7680/10000 (76%)]\tLoss: 253.449448\n",
      "Train Epoch: 38 [8960/10000 (89%)]\tLoss: 272.546570\n",
      "Train Epoch: 39 [0/10000 (0%)]\tLoss: 259.178711\n",
      "Train Epoch: 39 [1280/10000 (13%)]\tLoss: 265.794586\n",
      "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 273.249512\n",
      "Train Epoch: 39 [3840/10000 (38%)]\tLoss: 261.172852\n",
      "Train Epoch: 39 [5120/10000 (51%)]\tLoss: 259.604492\n",
      "Train Epoch: 39 [6400/10000 (63%)]\tLoss: 260.023499\n",
      "Train Epoch: 39 [7680/10000 (76%)]\tLoss: 253.091721\n",
      "Train Epoch: 39 [8960/10000 (89%)]\tLoss: 272.998352\n",
      "Train Epoch: 40 [0/10000 (0%)]\tLoss: 260.017883\n",
      "Train Epoch: 40 [1280/10000 (13%)]\tLoss: 265.181671\n",
      "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 274.549072\n",
      "Train Epoch: 40 [3840/10000 (38%)]\tLoss: 261.131592\n",
      "Train Epoch: 40 [5120/10000 (51%)]\tLoss: 257.516998\n",
      "Train Epoch: 40 [6400/10000 (63%)]\tLoss: 261.701447\n",
      "Train Epoch: 40 [7680/10000 (76%)]\tLoss: 254.442108\n",
      "Train Epoch: 40 [8960/10000 (89%)]\tLoss: 273.475708\n",
      "Train Epoch: 0 [0/10000 (0%)]\tLoss: 253.556793\n",
      "Train Epoch: 0 [1280/10000 (13%)]\tLoss: 262.172729\n",
      "Train Epoch: 0 [2560/10000 (25%)]\tLoss: 269.026672\n",
      "Train Epoch: 0 [3840/10000 (38%)]\tLoss: 256.434143\n",
      "Train Epoch: 0 [5120/10000 (51%)]\tLoss: 254.401352\n",
      "Train Epoch: 0 [6400/10000 (63%)]\tLoss: 256.896912\n",
      "Train Epoch: 0 [7680/10000 (76%)]\tLoss: 249.272049\n",
      "Train Epoch: 0 [8960/10000 (89%)]\tLoss: 269.655273\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 256.046814\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 261.167877\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 270.333618\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 258.686218\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 253.985229\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 257.205963\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 248.764191\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 268.903595\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 254.582031\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 262.111206\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 269.312927\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 257.617065\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 256.571259\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 257.359924\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 248.791245\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 267.883301\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 254.755951\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 262.331909\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 269.955200\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 257.631500\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 253.751297\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 256.805237\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 248.848526\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 269.343689\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 256.835663\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 262.623413\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 270.399139\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 256.259888\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 254.094208\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 257.787323\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 248.690460\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 269.539734\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 255.272064\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 262.763184\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 269.201355\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 257.083282\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 254.806061\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 257.073120\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 249.664246\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 267.927917\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 255.336212\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 262.240173\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 270.694061\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 256.994324\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 254.172516\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 257.907684\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 250.099945\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 269.110657\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 255.843414\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 261.583191\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 269.762634\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 257.741760\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 254.947632\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 256.733032\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 250.033295\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 268.532593\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 254.167969\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 261.393982\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 270.869995\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 258.013977\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 255.174133\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 256.505310\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 249.398926\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 268.032166\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 255.683212\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 262.150177\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 269.650513\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 257.523956\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 255.034882\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 257.404175\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 249.274658\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 269.267853\n",
      "====> Test set NLL: 259.6149\n",
      "Running time: 7664.09375 Seconds\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 545.927429\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 193.398621\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 162.994217\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 143.568649\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 133.354660\n",
      "====> Test set loss: 126.4996\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 128.760788\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 122.444748\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 117.306824\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 117.750793\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 115.026047\n",
      "====> Test set loss: 109.5897\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 111.174873\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 112.173798\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 109.795090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 103.930183\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 104.589310\n",
      "====> Test set loss: 105.1388\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 100.412872\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 103.469383\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 105.140182\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 105.281998\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 101.278015\n",
      "====> Test set loss: 102.5701\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 103.251755\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 101.579437\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 103.611298\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 100.889793\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 103.956970\n",
      "====> Test set loss: 101.1181\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 102.848724\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 99.295174\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 97.946091\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 102.255463\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 97.744377\n",
      "====> Test set loss: 99.7554\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 95.728012\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 99.188400\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 100.415977\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 97.322365\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 97.703949\n",
      "====> Test set loss: 98.7246\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 103.525879\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 99.855942\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 98.526367\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 95.894974\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 96.201691\n",
      "====> Test set loss: 97.9893\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 100.984634\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 96.490448\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 100.074280\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 96.235672\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 92.861069\n",
      "====> Test set loss: 97.4544\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 101.314697\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 96.904984\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 99.773674\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 99.457748\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 97.169312\n",
      "====> Test set loss: 96.7191\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 97.994225\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 91.353416\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 100.108963\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 97.410309\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 95.964195\n",
      "====> Test set loss: 96.4141\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 94.660782\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 95.226517\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 98.951317\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 96.170288\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 95.233795\n",
      "====> Test set loss: 96.3260\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 97.644531\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 96.247055\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 101.772003\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 99.407379\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 96.598091\n",
      "====> Test set loss: 95.8211\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 98.464996\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 91.206635\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 95.077438\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 97.169891\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 99.750984\n",
      "====> Test set loss: 95.8275\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 90.933502\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 94.028183\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 89.270187\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 98.922699\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 93.626617\n",
      "====> Test set loss: 95.6023\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 91.710098\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 95.222763\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 97.142899\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 93.234512\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 94.209061\n",
      "====> Test set loss: 95.0727\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 89.845238\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 100.993744\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 94.962852\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 97.412041\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 93.249855\n",
      "====> Test set loss: 94.7467\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 93.347473\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 93.134827\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 91.287628\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 94.914368\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 88.669327\n",
      "====> Test set loss: 94.7971\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 94.408371\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 94.982536\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 92.997513\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 92.441330\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 94.059906\n",
      "====> Test set loss: 94.6296\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 92.278427\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 94.639755\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 97.315475\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 92.790794\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 94.658302\n",
      "====> Test set loss: 94.4563\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 94.129883\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 90.300331\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 93.286316\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 92.643181\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 94.866653\n",
      "====> Test set loss: 94.2299\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 94.287323\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 91.613083\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 93.848366\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 93.466759\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 93.708702\n",
      "====> Test set loss: 94.1343\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 91.805946\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 88.979103\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 92.351448\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 89.385590\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 92.679886\n",
      "====> Test set loss: 93.9956\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 95.227859\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 89.999809\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 92.415817\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 93.977341\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 94.152176\n",
      "====> Test set loss: 93.7358\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 92.691246\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 90.170868\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 89.845619\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 91.042274\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 95.460793\n",
      "====> Test set loss: 93.7071\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 91.576843\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 90.030266\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 92.665512\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 91.237732\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 92.672569\n",
      "====> Test set loss: 93.6895\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 91.597183\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 90.629051\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 94.556267\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 95.415482\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 91.548477\n",
      "====> Test set loss: 93.9093\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 94.339516\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 92.996834\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 93.908295\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 92.080818\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 90.817703\n",
      "====> Test set loss: 93.5024\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 91.890945\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 91.043686\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 91.822205\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 90.783607\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 88.442459\n",
      "====> Test set loss: 93.7688\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 91.044922\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 90.726006\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 91.177170\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 91.688660\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 95.815323\n",
      "====> Test set loss: 93.3593\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 94.531509\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 96.432060\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 90.363205\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 90.292656\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 95.653717\n",
      "====> Test set loss: 93.1843\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 89.733124\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 93.164978\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 91.712776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 87.979202\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 92.066154\n",
      "====> Test set loss: 93.3536\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 94.562622\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 94.304428\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 95.037521\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 92.416466\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 92.070923\n",
      "====> Test set loss: 93.2102\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 90.854362\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 91.747566\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 89.058746\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 92.296227\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 91.352768\n",
      "====> Test set loss: 93.2277\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 90.926659\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 94.154083\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 90.630501\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 93.148293\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 90.098755\n",
      "====> Test set loss: 93.0816\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 89.937080\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 94.063385\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 91.442612\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 95.981133\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 88.641701\n",
      "====> Test set loss: 92.8832\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 88.263718\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 91.777161\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 91.661407\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 91.277245\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 91.538483\n",
      "====> Test set loss: 92.7914\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 88.246140\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 90.497528\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 91.050919\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 92.165543\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 89.790543\n",
      "====> Test set loss: 92.8634\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 91.204147\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 92.806931\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 90.319824\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 94.242599\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 90.489456\n",
      "====> Test set loss: 92.9022\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 90.606010\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 89.703835\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 92.298584\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 91.572067\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 93.346695\n",
      "====> Test set loss: 92.9281\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 555.420959\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 215.224335\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 167.916290\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 156.242126\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 139.167694\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 130.257111\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 131.987320\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 133.503632\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 120.616150\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 120.415726\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 112.068863\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 117.236954\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 109.984802\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 109.733276\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 109.560135\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 115.813263\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 109.715942\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 108.904922\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 106.764130\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 110.021629\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 106.035049\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 107.323158\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 104.564240\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 109.773254\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 104.310501\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 106.746796\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 102.777771\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 109.018463\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 103.000488\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 104.109222\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 103.780212\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 106.423561\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 106.345703\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 103.843277\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 101.032150\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 105.700996\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 99.816902\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 102.236778\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 101.713470\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 107.546280\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 102.084282\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 100.828186\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 101.621056\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 105.195351\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 98.293518\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 100.492859\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 99.523712\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 104.135681\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 101.499046\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 100.568787\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 100.664825\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 104.727036\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 97.999619\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 100.659073\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 98.023918\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 104.296097\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 100.178032\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 99.641479\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 98.649811\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 106.767288\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 99.078453\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 100.162201\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 99.687004\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 104.226875\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 100.688431\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 102.537987\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 97.987740\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 103.989159\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 97.870773\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 99.743515\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 99.619766\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 103.581459\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 100.079895\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 98.856476\n",
      "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 99.284393\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 102.313126\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 96.748024\n",
      "Train Epoch: 10 [6400/10000 (63%)]\tLoss: 99.189644\n",
      "Train Epoch: 10 [7680/10000 (76%)]\tLoss: 98.530396\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 104.056068\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 96.922783\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 100.394707\n",
      "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 97.308350\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 102.450745\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 96.246826\n",
      "Train Epoch: 11 [6400/10000 (63%)]\tLoss: 97.340660\n",
      "Train Epoch: 11 [7680/10000 (76%)]\tLoss: 96.382904\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 104.765198\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 95.998856\n",
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 97.623337\n",
      "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 97.354172\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 100.997253\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 97.495331\n",
      "Train Epoch: 12 [6400/10000 (63%)]\tLoss: 96.637833\n",
      "Train Epoch: 12 [7680/10000 (76%)]\tLoss: 97.035271\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 100.314575\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 95.966904\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 99.526947\n",
      "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 97.153732\n",
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 100.100449\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 97.368690\n",
      "Train Epoch: 13 [6400/10000 (63%)]\tLoss: 97.426949\n",
      "Train Epoch: 13 [7680/10000 (76%)]\tLoss: 97.480453\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 103.116745\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 94.649086\n",
      "Train Epoch: 14 [1280/10000 (13%)]\tLoss: 96.575714\n",
      "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 95.417732\n",
      "Train Epoch: 14 [3840/10000 (38%)]\tLoss: 101.412148\n",
      "Train Epoch: 14 [5120/10000 (51%)]\tLoss: 96.875771\n",
      "Train Epoch: 14 [6400/10000 (63%)]\tLoss: 97.765671\n",
      "Train Epoch: 14 [7680/10000 (76%)]\tLoss: 95.861755\n",
      "Train Epoch: 14 [8960/10000 (89%)]\tLoss: 100.815567\n",
      "Train Epoch: 15 [0/10000 (0%)]\tLoss: 96.662102\n",
      "Train Epoch: 15 [1280/10000 (13%)]\tLoss: 97.550568\n",
      "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 96.958023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 15 [3840/10000 (38%)]\tLoss: 100.678642\n",
      "Train Epoch: 15 [5120/10000 (51%)]\tLoss: 95.649841\n",
      "Train Epoch: 15 [6400/10000 (63%)]\tLoss: 96.959976\n",
      "Train Epoch: 15 [7680/10000 (76%)]\tLoss: 96.886276\n",
      "Train Epoch: 15 [8960/10000 (89%)]\tLoss: 102.425011\n",
      "Train Epoch: 16 [0/10000 (0%)]\tLoss: 96.543549\n",
      "Train Epoch: 16 [1280/10000 (13%)]\tLoss: 97.743744\n",
      "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 94.616722\n",
      "Train Epoch: 16 [3840/10000 (38%)]\tLoss: 101.369507\n",
      "Train Epoch: 16 [5120/10000 (51%)]\tLoss: 95.520218\n",
      "Train Epoch: 16 [6400/10000 (63%)]\tLoss: 96.637817\n",
      "Train Epoch: 16 [7680/10000 (76%)]\tLoss: 93.932320\n",
      "Train Epoch: 16 [8960/10000 (89%)]\tLoss: 101.647568\n",
      "Train Epoch: 17 [0/10000 (0%)]\tLoss: 94.719421\n",
      "Train Epoch: 17 [1280/10000 (13%)]\tLoss: 98.108124\n",
      "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 95.818695\n",
      "Train Epoch: 17 [3840/10000 (38%)]\tLoss: 101.412842\n",
      "Train Epoch: 17 [5120/10000 (51%)]\tLoss: 94.759262\n",
      "Train Epoch: 17 [6400/10000 (63%)]\tLoss: 96.525162\n",
      "Train Epoch: 17 [7680/10000 (76%)]\tLoss: 94.391418\n",
      "Train Epoch: 17 [8960/10000 (89%)]\tLoss: 101.186234\n",
      "Train Epoch: 18 [0/10000 (0%)]\tLoss: 94.936157\n",
      "Train Epoch: 18 [1280/10000 (13%)]\tLoss: 97.371704\n",
      "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 96.162582\n",
      "Train Epoch: 18 [3840/10000 (38%)]\tLoss: 102.511505\n",
      "Train Epoch: 18 [5120/10000 (51%)]\tLoss: 95.610611\n",
      "Train Epoch: 18 [6400/10000 (63%)]\tLoss: 96.959389\n",
      "Train Epoch: 18 [7680/10000 (76%)]\tLoss: 95.927826\n",
      "Train Epoch: 18 [8960/10000 (89%)]\tLoss: 101.210304\n",
      "Train Epoch: 19 [0/10000 (0%)]\tLoss: 96.180099\n",
      "Train Epoch: 19 [1280/10000 (13%)]\tLoss: 97.172440\n",
      "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 96.338120\n",
      "Train Epoch: 19 [3840/10000 (38%)]\tLoss: 99.282776\n",
      "Train Epoch: 19 [5120/10000 (51%)]\tLoss: 94.223412\n",
      "Train Epoch: 19 [6400/10000 (63%)]\tLoss: 95.718445\n",
      "Train Epoch: 19 [7680/10000 (76%)]\tLoss: 94.548462\n",
      "Train Epoch: 19 [8960/10000 (89%)]\tLoss: 100.208656\n",
      "Train Epoch: 20 [0/10000 (0%)]\tLoss: 96.447250\n",
      "Train Epoch: 20 [1280/10000 (13%)]\tLoss: 96.763229\n",
      "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 95.495392\n",
      "Train Epoch: 20 [3840/10000 (38%)]\tLoss: 100.428261\n",
      "Train Epoch: 20 [5120/10000 (51%)]\tLoss: 95.470322\n",
      "Train Epoch: 20 [6400/10000 (63%)]\tLoss: 95.349197\n",
      "Train Epoch: 20 [7680/10000 (76%)]\tLoss: 95.539749\n",
      "Train Epoch: 20 [8960/10000 (89%)]\tLoss: 100.957497\n",
      "Train Epoch: 21 [0/10000 (0%)]\tLoss: 94.113403\n",
      "Train Epoch: 21 [1280/10000 (13%)]\tLoss: 96.111809\n",
      "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 95.279037\n",
      "Train Epoch: 21 [3840/10000 (38%)]\tLoss: 99.197182\n",
      "Train Epoch: 21 [5120/10000 (51%)]\tLoss: 95.241562\n",
      "Train Epoch: 21 [6400/10000 (63%)]\tLoss: 95.315918\n",
      "Train Epoch: 21 [7680/10000 (76%)]\tLoss: 94.218269\n",
      "Train Epoch: 21 [8960/10000 (89%)]\tLoss: 99.805801\n",
      "Train Epoch: 22 [0/10000 (0%)]\tLoss: 93.095634\n",
      "Train Epoch: 22 [1280/10000 (13%)]\tLoss: 96.384132\n",
      "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 96.137886\n",
      "Train Epoch: 22 [3840/10000 (38%)]\tLoss: 99.752419\n",
      "Train Epoch: 22 [5120/10000 (51%)]\tLoss: 93.457794\n",
      "Train Epoch: 22 [6400/10000 (63%)]\tLoss: 96.469284\n",
      "Train Epoch: 22 [7680/10000 (76%)]\tLoss: 95.305161\n",
      "Train Epoch: 22 [8960/10000 (89%)]\tLoss: 100.045738\n",
      "Train Epoch: 23 [0/10000 (0%)]\tLoss: 95.089081\n",
      "Train Epoch: 23 [1280/10000 (13%)]\tLoss: 95.774979\n",
      "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 94.610779\n",
      "Train Epoch: 23 [3840/10000 (38%)]\tLoss: 98.980431\n",
      "Train Epoch: 23 [5120/10000 (51%)]\tLoss: 94.569214\n",
      "Train Epoch: 23 [6400/10000 (63%)]\tLoss: 94.996902\n",
      "Train Epoch: 23 [7680/10000 (76%)]\tLoss: 94.024910\n",
      "Train Epoch: 23 [8960/10000 (89%)]\tLoss: 100.309319\n",
      "Train Epoch: 24 [0/10000 (0%)]\tLoss: 93.413208\n",
      "Train Epoch: 24 [1280/10000 (13%)]\tLoss: 97.069672\n",
      "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 95.762199\n",
      "Train Epoch: 24 [3840/10000 (38%)]\tLoss: 99.256645\n",
      "Train Epoch: 24 [5120/10000 (51%)]\tLoss: 92.801514\n",
      "Train Epoch: 24 [6400/10000 (63%)]\tLoss: 95.089836\n",
      "Train Epoch: 24 [7680/10000 (76%)]\tLoss: 94.060699\n",
      "Train Epoch: 24 [8960/10000 (89%)]\tLoss: 99.004013\n",
      "Train Epoch: 25 [0/10000 (0%)]\tLoss: 94.923065\n",
      "Train Epoch: 25 [1280/10000 (13%)]\tLoss: 96.670258\n",
      "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 95.895271\n",
      "Train Epoch: 25 [3840/10000 (38%)]\tLoss: 100.821503\n",
      "Train Epoch: 25 [5120/10000 (51%)]\tLoss: 93.789001\n",
      "Train Epoch: 25 [6400/10000 (63%)]\tLoss: 95.973495\n",
      "Train Epoch: 25 [7680/10000 (76%)]\tLoss: 95.485291\n",
      "Train Epoch: 25 [8960/10000 (89%)]\tLoss: 100.109695\n",
      "Train Epoch: 26 [0/10000 (0%)]\tLoss: 94.472130\n",
      "Train Epoch: 26 [1280/10000 (13%)]\tLoss: 96.816315\n",
      "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 95.688858\n",
      "Train Epoch: 26 [3840/10000 (38%)]\tLoss: 100.482635\n",
      "Train Epoch: 26 [5120/10000 (51%)]\tLoss: 94.581528\n",
      "Train Epoch: 26 [6400/10000 (63%)]\tLoss: 95.751251\n",
      "Train Epoch: 26 [7680/10000 (76%)]\tLoss: 94.289963\n",
      "Train Epoch: 26 [8960/10000 (89%)]\tLoss: 100.957642\n",
      "Train Epoch: 27 [0/10000 (0%)]\tLoss: 93.624542\n",
      "Train Epoch: 27 [1280/10000 (13%)]\tLoss: 94.832993\n",
      "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 94.867432\n",
      "Train Epoch: 27 [3840/10000 (38%)]\tLoss: 99.299316\n",
      "Train Epoch: 27 [5120/10000 (51%)]\tLoss: 94.542389\n",
      "Train Epoch: 27 [6400/10000 (63%)]\tLoss: 95.598808\n",
      "Train Epoch: 27 [7680/10000 (76%)]\tLoss: 95.647949\n",
      "Train Epoch: 27 [8960/10000 (89%)]\tLoss: 99.978241\n",
      "Train Epoch: 28 [0/10000 (0%)]\tLoss: 93.864304\n",
      "Train Epoch: 28 [1280/10000 (13%)]\tLoss: 94.622749\n",
      "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 93.541870\n",
      "Train Epoch: 28 [3840/10000 (38%)]\tLoss: 100.176285\n",
      "Train Epoch: 28 [5120/10000 (51%)]\tLoss: 94.099976\n",
      "Train Epoch: 28 [6400/10000 (63%)]\tLoss: 96.147469\n",
      "Train Epoch: 28 [7680/10000 (76%)]\tLoss: 94.174194\n",
      "Train Epoch: 28 [8960/10000 (89%)]\tLoss: 98.968246\n",
      "Train Epoch: 29 [0/10000 (0%)]\tLoss: 93.717690\n",
      "Train Epoch: 29 [1280/10000 (13%)]\tLoss: 95.873589\n",
      "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 93.881058\n",
      "Train Epoch: 29 [3840/10000 (38%)]\tLoss: 99.378387\n",
      "Train Epoch: 29 [5120/10000 (51%)]\tLoss: 94.286766\n",
      "Train Epoch: 29 [6400/10000 (63%)]\tLoss: 95.393127\n",
      "Train Epoch: 29 [7680/10000 (76%)]\tLoss: 93.397148\n",
      "Train Epoch: 29 [8960/10000 (89%)]\tLoss: 100.701599\n",
      "Train Epoch: 30 [0/10000 (0%)]\tLoss: 94.306671\n",
      "Train Epoch: 30 [1280/10000 (13%)]\tLoss: 96.947983\n",
      "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 95.007278\n",
      "Train Epoch: 30 [3840/10000 (38%)]\tLoss: 99.334274\n",
      "Train Epoch: 30 [5120/10000 (51%)]\tLoss: 93.515274\n",
      "Train Epoch: 30 [6400/10000 (63%)]\tLoss: 95.548660\n",
      "Train Epoch: 30 [7680/10000 (76%)]\tLoss: 93.043312\n",
      "Train Epoch: 30 [8960/10000 (89%)]\tLoss: 99.205070\n",
      "Train Epoch: 31 [0/10000 (0%)]\tLoss: 93.853615\n",
      "Train Epoch: 31 [1280/10000 (13%)]\tLoss: 95.994415\n",
      "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 95.266403\n",
      "Train Epoch: 31 [3840/10000 (38%)]\tLoss: 99.379219\n",
      "Train Epoch: 31 [5120/10000 (51%)]\tLoss: 94.402618\n",
      "Train Epoch: 31 [6400/10000 (63%)]\tLoss: 95.210815\n",
      "Train Epoch: 31 [7680/10000 (76%)]\tLoss: 95.755569\n",
      "Train Epoch: 31 [8960/10000 (89%)]\tLoss: 99.088470\n",
      "Train Epoch: 32 [0/10000 (0%)]\tLoss: 96.039101\n",
      "Train Epoch: 32 [1280/10000 (13%)]\tLoss: 95.629753\n",
      "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 95.025970\n",
      "Train Epoch: 32 [3840/10000 (38%)]\tLoss: 99.033607\n",
      "Train Epoch: 32 [5120/10000 (51%)]\tLoss: 93.166672\n",
      "Train Epoch: 32 [6400/10000 (63%)]\tLoss: 95.007126\n",
      "Train Epoch: 32 [7680/10000 (76%)]\tLoss: 94.653625\n",
      "Train Epoch: 32 [8960/10000 (89%)]\tLoss: 99.459091\n",
      "Train Epoch: 33 [0/10000 (0%)]\tLoss: 96.089569\n",
      "Train Epoch: 33 [1280/10000 (13%)]\tLoss: 95.384354\n",
      "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 95.271072\n",
      "Train Epoch: 33 [3840/10000 (38%)]\tLoss: 99.537918\n",
      "Train Epoch: 33 [5120/10000 (51%)]\tLoss: 93.802399\n",
      "Train Epoch: 33 [6400/10000 (63%)]\tLoss: 94.576218\n",
      "Train Epoch: 33 [7680/10000 (76%)]\tLoss: 94.686790\n",
      "Train Epoch: 33 [8960/10000 (89%)]\tLoss: 98.549248\n",
      "Train Epoch: 34 [0/10000 (0%)]\tLoss: 92.646393\n",
      "Train Epoch: 34 [1280/10000 (13%)]\tLoss: 95.535728\n",
      "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 94.971092\n",
      "Train Epoch: 34 [3840/10000 (38%)]\tLoss: 100.808037\n",
      "Train Epoch: 34 [5120/10000 (51%)]\tLoss: 94.144836\n",
      "Train Epoch: 34 [6400/10000 (63%)]\tLoss: 96.200256\n",
      "Train Epoch: 34 [7680/10000 (76%)]\tLoss: 94.056335\n",
      "Train Epoch: 34 [8960/10000 (89%)]\tLoss: 99.819458\n",
      "Train Epoch: 35 [0/10000 (0%)]\tLoss: 93.999908\n",
      "Train Epoch: 35 [1280/10000 (13%)]\tLoss: 95.853088\n",
      "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 94.393501\n",
      "Train Epoch: 35 [3840/10000 (38%)]\tLoss: 98.400940\n",
      "Train Epoch: 35 [5120/10000 (51%)]\tLoss: 93.035706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 35 [6400/10000 (63%)]\tLoss: 94.424911\n",
      "Train Epoch: 35 [7680/10000 (76%)]\tLoss: 93.023544\n",
      "Train Epoch: 35 [8960/10000 (89%)]\tLoss: 99.322456\n",
      "Train Epoch: 36 [0/10000 (0%)]\tLoss: 93.474335\n",
      "Train Epoch: 36 [1280/10000 (13%)]\tLoss: 94.852928\n",
      "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 93.648903\n",
      "Train Epoch: 36 [3840/10000 (38%)]\tLoss: 98.915100\n",
      "Train Epoch: 36 [5120/10000 (51%)]\tLoss: 94.933090\n",
      "Train Epoch: 36 [6400/10000 (63%)]\tLoss: 93.650055\n",
      "Train Epoch: 36 [7680/10000 (76%)]\tLoss: 94.005531\n",
      "Train Epoch: 36 [8960/10000 (89%)]\tLoss: 99.043640\n",
      "Train Epoch: 37 [0/10000 (0%)]\tLoss: 94.801758\n",
      "Train Epoch: 37 [1280/10000 (13%)]\tLoss: 95.998558\n",
      "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 93.397514\n",
      "Train Epoch: 37 [3840/10000 (38%)]\tLoss: 98.714905\n",
      "Train Epoch: 37 [5120/10000 (51%)]\tLoss: 93.942322\n",
      "Train Epoch: 37 [6400/10000 (63%)]\tLoss: 94.916145\n",
      "Train Epoch: 37 [7680/10000 (76%)]\tLoss: 93.737831\n",
      "Train Epoch: 37 [8960/10000 (89%)]\tLoss: 98.535492\n",
      "Train Epoch: 38 [0/10000 (0%)]\tLoss: 94.854942\n",
      "Train Epoch: 38 [1280/10000 (13%)]\tLoss: 94.931610\n",
      "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 95.312637\n",
      "Train Epoch: 38 [3840/10000 (38%)]\tLoss: 98.733200\n",
      "Train Epoch: 38 [5120/10000 (51%)]\tLoss: 93.447754\n",
      "Train Epoch: 38 [6400/10000 (63%)]\tLoss: 95.489105\n",
      "Train Epoch: 38 [7680/10000 (76%)]\tLoss: 94.189926\n",
      "Train Epoch: 38 [8960/10000 (89%)]\tLoss: 98.318527\n",
      "Train Epoch: 39 [0/10000 (0%)]\tLoss: 92.992828\n",
      "Train Epoch: 39 [1280/10000 (13%)]\tLoss: 94.255142\n",
      "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 93.999191\n",
      "Train Epoch: 39 [3840/10000 (38%)]\tLoss: 99.222839\n",
      "Train Epoch: 39 [5120/10000 (51%)]\tLoss: 92.037857\n",
      "Train Epoch: 39 [6400/10000 (63%)]\tLoss: 94.745377\n",
      "Train Epoch: 39 [7680/10000 (76%)]\tLoss: 93.392624\n",
      "Train Epoch: 39 [8960/10000 (89%)]\tLoss: 99.214966\n",
      "Train Epoch: 40 [0/10000 (0%)]\tLoss: 91.940285\n",
      "Train Epoch: 40 [1280/10000 (13%)]\tLoss: 95.266510\n",
      "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 93.681091\n",
      "Train Epoch: 40 [3840/10000 (38%)]\tLoss: 98.242424\n",
      "Train Epoch: 40 [5120/10000 (51%)]\tLoss: 93.450363\n",
      "Train Epoch: 40 [6400/10000 (63%)]\tLoss: 94.843430\n",
      "Train Epoch: 40 [7680/10000 (76%)]\tLoss: 93.430054\n",
      "Train Epoch: 40 [8960/10000 (89%)]\tLoss: 98.767815\n",
      "Train Epoch: 0 [0/10000 (0%)]\tLoss: 86.670334\n",
      "Train Epoch: 0 [1280/10000 (13%)]\tLoss: 88.224228\n",
      "Train Epoch: 0 [2560/10000 (25%)]\tLoss: 88.329247\n",
      "Train Epoch: 0 [3840/10000 (38%)]\tLoss: 93.817932\n",
      "Train Epoch: 0 [5120/10000 (51%)]\tLoss: 88.926422\n",
      "Train Epoch: 0 [6400/10000 (63%)]\tLoss: 90.971497\n",
      "Train Epoch: 0 [7680/10000 (76%)]\tLoss: 87.900803\n",
      "Train Epoch: 0 [8960/10000 (89%)]\tLoss: 93.581528\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 86.394432\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 88.747032\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 87.973465\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 92.236130\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 88.268936\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 89.259735\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 88.706398\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 93.366966\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 85.805176\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 88.589310\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 88.888687\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 93.018143\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 89.095726\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 91.333679\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 88.327644\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 93.280029\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 84.845695\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 88.917603\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 88.135521\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 92.610115\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 88.638702\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 90.007568\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 88.049652\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 92.723022\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 86.467232\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 89.451515\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 87.933212\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 94.275894\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 89.219963\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 89.520714\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 88.461411\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 93.432877\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 87.042572\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 88.584625\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 87.479134\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 92.952675\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 88.584366\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 89.392273\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 87.709702\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 92.531822\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 85.772446\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 89.858833\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 88.380188\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 93.419189\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 89.284348\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 90.076218\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 86.875679\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 92.555481\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 85.624397\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 89.944664\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 88.751511\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 92.861328\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 88.522156\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 89.880829\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 87.556458\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 93.570999\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 86.482780\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 89.337852\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 88.554718\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 93.947388\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 88.821472\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 90.252235\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 89.194229\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 92.716232\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 86.068939\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 89.096603\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 88.108925\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 92.957474\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 89.017700\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 90.568619\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 88.288597\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 92.604752\n",
      "====> Test set NLL: 88.2087\n",
      "Running time: 10527.03125 Seconds\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 546.921814\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 303.022614\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 268.107422\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 261.830688\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 246.353119\n",
      "====> Test set loss: 255.9460\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 256.022644\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 254.656250\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 248.829254\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 251.579163\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 252.325882\n",
      "====> Test set loss: 248.4758\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 250.479813\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 250.660767\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 234.558273\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 231.721039\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 247.382477\n",
      "====> Test set loss: 245.3227\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 229.352509\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 247.659332\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 237.043335\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 234.972046\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 229.537384\n",
      "====> Test set loss: 243.5221\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 246.390244\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 253.651611\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 235.463150\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 230.729843\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 243.873108\n",
      "====> Test set loss: 241.9737\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 243.915878\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 235.132355\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 239.667145\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 232.259735\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 233.840103\n",
      "====> Test set loss: 240.9382\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 246.739487\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 230.806442\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 245.367584\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 238.456329\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 235.047348\n",
      "====> Test set loss: 240.3649\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 235.066803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 237.256409\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 237.867828\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 242.037476\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 236.884521\n",
      "====> Test set loss: 239.6782\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 247.108978\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 242.505188\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 247.348770\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 236.881500\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 241.242828\n",
      "====> Test set loss: 238.8288\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 235.445984\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 239.242157\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 240.929779\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 240.338806\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 237.703613\n",
      "====> Test set loss: 238.2480\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 237.648224\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 235.285873\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 235.199371\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 240.300262\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 220.122437\n",
      "====> Test set loss: 237.9232\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 237.705017\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 232.646606\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 241.672546\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 229.952820\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 223.335022\n",
      "====> Test set loss: 237.6144\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 245.022095\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 232.128128\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 241.239044\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 238.628174\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 226.409973\n",
      "====> Test set loss: 237.6311\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 248.759125\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 232.054428\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 227.638382\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 227.836456\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 242.464050\n",
      "====> Test set loss: 237.1084\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 223.847626\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 237.869446\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 244.124939\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 244.246857\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 227.821304\n",
      "====> Test set loss: 237.1187\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 250.118881\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 232.138565\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 233.033539\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 239.350067\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 235.351822\n",
      "====> Test set loss: 236.7414\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 220.910385\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 228.911758\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 228.558533\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 232.521194\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 221.190018\n",
      "====> Test set loss: 236.2719\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 232.919907\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 245.730820\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 234.906754\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 228.527725\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 236.309006\n",
      "====> Test set loss: 236.2683\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 227.421661\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 244.195190\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 229.610901\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 234.673523\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 221.787476\n",
      "====> Test set loss: 236.4014\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 232.891464\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 219.265778\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 220.851837\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 239.538498\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 229.819168\n",
      "====> Test set loss: 235.9385\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 225.712952\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 244.069733\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 231.927704\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 237.553116\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 241.715515\n",
      "====> Test set loss: 235.6694\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 239.817993\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 239.266113\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 227.887299\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 226.877625\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 230.665527\n",
      "====> Test set loss: 235.6479\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 232.176880\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 227.373825\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 237.073151\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 243.168579\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 234.797180\n",
      "====> Test set loss: 235.7227\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 239.765167\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 235.879364\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 233.501556\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 230.144684\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 234.824005\n",
      "====> Test set loss: 235.3376\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 229.848877\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 236.170227\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 237.087189\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 243.203491\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 225.906296\n",
      "====> Test set loss: 235.2327\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 232.901031\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 237.192963\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 238.169067\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 225.292206\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 231.437302\n",
      "====> Test set loss: 235.3947\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 234.183838\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 224.692978\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 243.364685\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 229.934830\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 242.845215\n",
      "====> Test set loss: 235.0274\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 233.497009\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 234.153000\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 233.190857\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 230.852570\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 230.864395\n",
      "====> Test set loss: 235.0982\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 241.622818\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 233.414124\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 217.357849\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 235.187134\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 257.223816\n",
      "====> Test set loss: 235.1374\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 230.016571\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 236.519196\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 248.655701\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 223.201355\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 222.051941\n",
      "====> Test set loss: 234.8654\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 222.723114\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 230.238770\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 234.874496\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 224.327362\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 237.514236\n",
      "====> Test set loss: 234.8595\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 248.314972\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 236.379868\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 229.199158\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 231.053436\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 238.714996\n",
      "====> Test set loss: 234.7641\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 229.796387\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 228.206085\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 235.492798\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 244.116180\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 233.535034\n",
      "====> Test set loss: 234.8782\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 232.170227\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 233.066650\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 226.940582\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 223.518967\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 225.896072\n",
      "====> Test set loss: 234.8629\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 228.922089\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 229.925125\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 238.506393\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 234.028015\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 233.326492\n",
      "====> Test set loss: 234.7095\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 233.412872\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 233.205399\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 249.535507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 231.231079\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 234.811401\n",
      "====> Test set loss: 234.6987\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 234.047852\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 227.856689\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 234.012665\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 225.415405\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 233.785156\n",
      "====> Test set loss: 234.7446\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 219.022247\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 223.535370\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 231.669220\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 233.510101\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 235.723297\n",
      "====> Test set loss: 234.6060\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 224.299377\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 238.457062\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 235.843201\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 225.228836\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 233.635757\n",
      "====> Test set loss: 234.2604\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 233.891815\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 230.874695\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 223.413101\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 231.345123\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 242.470428\n",
      "====> Test set loss: 234.3314\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 1049.705322\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 379.129974\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 330.596252\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 301.399597\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 288.870911\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 277.567139\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 266.739838\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 277.843872\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 265.715179\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 262.882080\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 267.946320\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 261.188721\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 254.678131\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 253.303711\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 248.601135\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 261.603699\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 250.209076\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 253.159943\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 257.858582\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 250.425201\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 243.638367\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 245.858368\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 238.004761\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 254.736755\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 241.765213\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 248.468811\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 252.113770\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 246.167633\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 237.840790\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 243.197327\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 236.040619\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 255.520813\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 244.086411\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 244.371490\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 253.100006\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 241.109344\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 238.030746\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 238.972656\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 233.999542\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 252.944260\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 239.832031\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 243.462631\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 248.719360\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 243.330093\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 237.242310\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 239.929626\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 233.573730\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 251.172546\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 238.888947\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 242.451935\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 246.414337\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 239.264130\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 234.161926\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 238.357971\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 229.635742\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 249.108032\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 239.263000\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 243.481659\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 249.231613\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 240.726089\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 233.620758\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 237.402786\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 231.959167\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 247.884293\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 238.795090\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 241.855042\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 248.485687\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 240.186752\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 234.215149\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 237.420837\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 228.977966\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 249.645020\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 237.746277\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 239.634033\n",
      "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 247.488464\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 239.942368\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 232.919067\n",
      "Train Epoch: 10 [6400/10000 (63%)]\tLoss: 238.080063\n",
      "Train Epoch: 10 [7680/10000 (76%)]\tLoss: 227.571747\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 248.859924\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 237.892914\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 241.824051\n",
      "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 247.893646\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 239.231293\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 234.892288\n",
      "Train Epoch: 11 [6400/10000 (63%)]\tLoss: 236.451599\n",
      "Train Epoch: 11 [7680/10000 (76%)]\tLoss: 229.485519\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 248.968201\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 236.903076\n",
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 238.523804\n",
      "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 246.478058\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 238.517227\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 233.003189\n",
      "Train Epoch: 12 [6400/10000 (63%)]\tLoss: 235.387253\n",
      "Train Epoch: 12 [7680/10000 (76%)]\tLoss: 226.970932\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 248.986084\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 235.122803\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 237.690567\n",
      "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 245.937592\n",
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 237.340378\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 230.978043\n",
      "Train Epoch: 13 [6400/10000 (63%)]\tLoss: 234.949921\n",
      "Train Epoch: 13 [7680/10000 (76%)]\tLoss: 227.867767\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 247.468628\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 237.236298\n",
      "Train Epoch: 14 [1280/10000 (13%)]\tLoss: 237.710022\n",
      "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 245.612854\n",
      "Train Epoch: 14 [3840/10000 (38%)]\tLoss: 238.506119\n",
      "Train Epoch: 14 [5120/10000 (51%)]\tLoss: 231.210220\n",
      "Train Epoch: 14 [6400/10000 (63%)]\tLoss: 236.371490\n",
      "Train Epoch: 14 [7680/10000 (76%)]\tLoss: 228.391663\n",
      "Train Epoch: 14 [8960/10000 (89%)]\tLoss: 246.742615\n",
      "Train Epoch: 15 [0/10000 (0%)]\tLoss: 236.124603\n",
      "Train Epoch: 15 [1280/10000 (13%)]\tLoss: 237.410339\n",
      "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 246.010513\n",
      "Train Epoch: 15 [3840/10000 (38%)]\tLoss: 237.790359\n",
      "Train Epoch: 15 [5120/10000 (51%)]\tLoss: 231.910446\n",
      "Train Epoch: 15 [6400/10000 (63%)]\tLoss: 234.295135\n",
      "Train Epoch: 15 [7680/10000 (76%)]\tLoss: 226.621429\n",
      "Train Epoch: 15 [8960/10000 (89%)]\tLoss: 248.739899\n",
      "Train Epoch: 16 [0/10000 (0%)]\tLoss: 234.921082\n",
      "Train Epoch: 16 [1280/10000 (13%)]\tLoss: 237.805099\n",
      "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 246.080811\n",
      "Train Epoch: 16 [3840/10000 (38%)]\tLoss: 239.005112\n",
      "Train Epoch: 16 [5120/10000 (51%)]\tLoss: 232.075439\n",
      "Train Epoch: 16 [6400/10000 (63%)]\tLoss: 236.035889\n",
      "Train Epoch: 16 [7680/10000 (76%)]\tLoss: 226.236954\n",
      "Train Epoch: 16 [8960/10000 (89%)]\tLoss: 247.474533\n",
      "Train Epoch: 17 [0/10000 (0%)]\tLoss: 234.768890\n",
      "Train Epoch: 17 [1280/10000 (13%)]\tLoss: 237.361130\n",
      "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 244.406372\n",
      "Train Epoch: 17 [3840/10000 (38%)]\tLoss: 236.538239\n",
      "Train Epoch: 17 [5120/10000 (51%)]\tLoss: 232.357239\n",
      "Train Epoch: 17 [6400/10000 (63%)]\tLoss: 236.282593\n",
      "Train Epoch: 17 [7680/10000 (76%)]\tLoss: 226.306702\n",
      "Train Epoch: 17 [8960/10000 (89%)]\tLoss: 248.030029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 18 [0/10000 (0%)]\tLoss: 234.738144\n",
      "Train Epoch: 18 [1280/10000 (13%)]\tLoss: 238.289307\n",
      "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 245.993668\n",
      "Train Epoch: 18 [3840/10000 (38%)]\tLoss: 237.661621\n",
      "Train Epoch: 18 [5120/10000 (51%)]\tLoss: 232.846985\n",
      "Train Epoch: 18 [6400/10000 (63%)]\tLoss: 234.480331\n",
      "Train Epoch: 18 [7680/10000 (76%)]\tLoss: 226.135864\n",
      "Train Epoch: 18 [8960/10000 (89%)]\tLoss: 247.896545\n",
      "Train Epoch: 19 [0/10000 (0%)]\tLoss: 236.196472\n",
      "Train Epoch: 19 [1280/10000 (13%)]\tLoss: 239.397644\n",
      "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 246.126312\n",
      "Train Epoch: 19 [3840/10000 (38%)]\tLoss: 236.444153\n",
      "Train Epoch: 19 [5120/10000 (51%)]\tLoss: 231.114639\n",
      "Train Epoch: 19 [6400/10000 (63%)]\tLoss: 235.644547\n",
      "Train Epoch: 19 [7680/10000 (76%)]\tLoss: 226.416779\n",
      "Train Epoch: 19 [8960/10000 (89%)]\tLoss: 244.618210\n",
      "Train Epoch: 20 [0/10000 (0%)]\tLoss: 235.853195\n",
      "Train Epoch: 20 [1280/10000 (13%)]\tLoss: 238.843384\n",
      "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 243.783768\n",
      "Train Epoch: 20 [3840/10000 (38%)]\tLoss: 237.207886\n",
      "Train Epoch: 20 [5120/10000 (51%)]\tLoss: 230.375015\n",
      "Train Epoch: 20 [6400/10000 (63%)]\tLoss: 235.307449\n",
      "Train Epoch: 20 [7680/10000 (76%)]\tLoss: 228.299179\n",
      "Train Epoch: 20 [8960/10000 (89%)]\tLoss: 245.878494\n",
      "Train Epoch: 21 [0/10000 (0%)]\tLoss: 233.168228\n",
      "Train Epoch: 21 [1280/10000 (13%)]\tLoss: 240.675415\n",
      "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 245.272827\n",
      "Train Epoch: 21 [3840/10000 (38%)]\tLoss: 237.816284\n",
      "Train Epoch: 21 [5120/10000 (51%)]\tLoss: 230.104523\n",
      "Train Epoch: 21 [6400/10000 (63%)]\tLoss: 234.464294\n",
      "Train Epoch: 21 [7680/10000 (76%)]\tLoss: 227.742157\n",
      "Train Epoch: 21 [8960/10000 (89%)]\tLoss: 245.548050\n",
      "Train Epoch: 22 [0/10000 (0%)]\tLoss: 233.569794\n",
      "Train Epoch: 22 [1280/10000 (13%)]\tLoss: 238.770386\n",
      "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 244.188354\n",
      "Train Epoch: 22 [3840/10000 (38%)]\tLoss: 237.709335\n",
      "Train Epoch: 22 [5120/10000 (51%)]\tLoss: 230.259583\n",
      "Train Epoch: 22 [6400/10000 (63%)]\tLoss: 233.254959\n",
      "Train Epoch: 22 [7680/10000 (76%)]\tLoss: 226.356354\n",
      "Train Epoch: 22 [8960/10000 (89%)]\tLoss: 244.044830\n",
      "Train Epoch: 23 [0/10000 (0%)]\tLoss: 234.421600\n",
      "Train Epoch: 23 [1280/10000 (13%)]\tLoss: 238.593216\n",
      "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 243.881134\n",
      "Train Epoch: 23 [3840/10000 (38%)]\tLoss: 237.192886\n",
      "Train Epoch: 23 [5120/10000 (51%)]\tLoss: 231.062485\n",
      "Train Epoch: 23 [6400/10000 (63%)]\tLoss: 233.836700\n",
      "Train Epoch: 23 [7680/10000 (76%)]\tLoss: 226.593842\n",
      "Train Epoch: 23 [8960/10000 (89%)]\tLoss: 245.681061\n",
      "Train Epoch: 24 [0/10000 (0%)]\tLoss: 233.000061\n",
      "Train Epoch: 24 [1280/10000 (13%)]\tLoss: 239.155121\n",
      "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 244.725189\n",
      "Train Epoch: 24 [3840/10000 (38%)]\tLoss: 234.799500\n",
      "Train Epoch: 24 [5120/10000 (51%)]\tLoss: 231.134186\n",
      "Train Epoch: 24 [6400/10000 (63%)]\tLoss: 233.882172\n",
      "Train Epoch: 24 [7680/10000 (76%)]\tLoss: 227.514618\n",
      "Train Epoch: 24 [8960/10000 (89%)]\tLoss: 245.545288\n",
      "Train Epoch: 25 [0/10000 (0%)]\tLoss: 235.342178\n",
      "Train Epoch: 25 [1280/10000 (13%)]\tLoss: 236.334045\n",
      "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 244.414429\n",
      "Train Epoch: 25 [3840/10000 (38%)]\tLoss: 236.404694\n",
      "Train Epoch: 25 [5120/10000 (51%)]\tLoss: 230.986588\n",
      "Train Epoch: 25 [6400/10000 (63%)]\tLoss: 234.206268\n",
      "Train Epoch: 25 [7680/10000 (76%)]\tLoss: 226.411346\n",
      "Train Epoch: 25 [8960/10000 (89%)]\tLoss: 245.699081\n",
      "Train Epoch: 26 [0/10000 (0%)]\tLoss: 232.980316\n",
      "Train Epoch: 26 [1280/10000 (13%)]\tLoss: 235.805725\n",
      "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 243.633667\n",
      "Train Epoch: 26 [3840/10000 (38%)]\tLoss: 235.437317\n",
      "Train Epoch: 26 [5120/10000 (51%)]\tLoss: 230.843231\n",
      "Train Epoch: 26 [6400/10000 (63%)]\tLoss: 234.136444\n",
      "Train Epoch: 26 [7680/10000 (76%)]\tLoss: 226.100830\n",
      "Train Epoch: 26 [8960/10000 (89%)]\tLoss: 245.605286\n",
      "Train Epoch: 27 [0/10000 (0%)]\tLoss: 233.541916\n",
      "Train Epoch: 27 [1280/10000 (13%)]\tLoss: 238.873230\n",
      "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 245.673218\n",
      "Train Epoch: 27 [3840/10000 (38%)]\tLoss: 235.188232\n",
      "Train Epoch: 27 [5120/10000 (51%)]\tLoss: 231.176773\n",
      "Train Epoch: 27 [6400/10000 (63%)]\tLoss: 233.735397\n",
      "Train Epoch: 27 [7680/10000 (76%)]\tLoss: 225.522491\n",
      "Train Epoch: 27 [8960/10000 (89%)]\tLoss: 245.266235\n",
      "Train Epoch: 28 [0/10000 (0%)]\tLoss: 233.910126\n",
      "Train Epoch: 28 [1280/10000 (13%)]\tLoss: 237.387222\n",
      "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 244.503906\n",
      "Train Epoch: 28 [3840/10000 (38%)]\tLoss: 236.384079\n",
      "Train Epoch: 28 [5120/10000 (51%)]\tLoss: 230.351501\n",
      "Train Epoch: 28 [6400/10000 (63%)]\tLoss: 234.796722\n",
      "Train Epoch: 28 [7680/10000 (76%)]\tLoss: 224.926910\n",
      "Train Epoch: 28 [8960/10000 (89%)]\tLoss: 246.835327\n",
      "Train Epoch: 29 [0/10000 (0%)]\tLoss: 233.067856\n",
      "Train Epoch: 29 [1280/10000 (13%)]\tLoss: 235.398697\n",
      "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 244.665268\n",
      "Train Epoch: 29 [3840/10000 (38%)]\tLoss: 235.004395\n",
      "Train Epoch: 29 [5120/10000 (51%)]\tLoss: 230.026138\n",
      "Train Epoch: 29 [6400/10000 (63%)]\tLoss: 233.073181\n",
      "Train Epoch: 29 [7680/10000 (76%)]\tLoss: 225.801239\n",
      "Train Epoch: 29 [8960/10000 (89%)]\tLoss: 245.458313\n",
      "Train Epoch: 30 [0/10000 (0%)]\tLoss: 233.968994\n",
      "Train Epoch: 30 [1280/10000 (13%)]\tLoss: 235.362213\n",
      "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 243.866882\n",
      "Train Epoch: 30 [3840/10000 (38%)]\tLoss: 236.372650\n",
      "Train Epoch: 30 [5120/10000 (51%)]\tLoss: 230.222595\n",
      "Train Epoch: 30 [6400/10000 (63%)]\tLoss: 232.221191\n",
      "Train Epoch: 30 [7680/10000 (76%)]\tLoss: 225.213379\n",
      "Train Epoch: 30 [8960/10000 (89%)]\tLoss: 244.061325\n",
      "Train Epoch: 31 [0/10000 (0%)]\tLoss: 233.912415\n",
      "Train Epoch: 31 [1280/10000 (13%)]\tLoss: 237.360580\n",
      "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 243.310638\n",
      "Train Epoch: 31 [3840/10000 (38%)]\tLoss: 235.874802\n",
      "Train Epoch: 31 [5120/10000 (51%)]\tLoss: 229.982056\n",
      "Train Epoch: 31 [6400/10000 (63%)]\tLoss: 234.138550\n",
      "Train Epoch: 31 [7680/10000 (76%)]\tLoss: 224.877716\n",
      "Train Epoch: 31 [8960/10000 (89%)]\tLoss: 246.860504\n",
      "Train Epoch: 32 [0/10000 (0%)]\tLoss: 232.479980\n",
      "Train Epoch: 32 [1280/10000 (13%)]\tLoss: 237.735626\n",
      "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 243.660355\n",
      "Train Epoch: 32 [3840/10000 (38%)]\tLoss: 236.141388\n",
      "Train Epoch: 32 [5120/10000 (51%)]\tLoss: 231.300049\n",
      "Train Epoch: 32 [6400/10000 (63%)]\tLoss: 233.536072\n",
      "Train Epoch: 32 [7680/10000 (76%)]\tLoss: 224.542053\n",
      "Train Epoch: 32 [8960/10000 (89%)]\tLoss: 246.236771\n",
      "Train Epoch: 33 [0/10000 (0%)]\tLoss: 232.295746\n",
      "Train Epoch: 33 [1280/10000 (13%)]\tLoss: 237.814240\n",
      "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 243.212463\n",
      "Train Epoch: 33 [3840/10000 (38%)]\tLoss: 236.745956\n",
      "Train Epoch: 33 [5120/10000 (51%)]\tLoss: 230.648193\n",
      "Train Epoch: 33 [6400/10000 (63%)]\tLoss: 234.225494\n",
      "Train Epoch: 33 [7680/10000 (76%)]\tLoss: 224.963501\n",
      "Train Epoch: 33 [8960/10000 (89%)]\tLoss: 245.375397\n",
      "Train Epoch: 34 [0/10000 (0%)]\tLoss: 232.265900\n",
      "Train Epoch: 34 [1280/10000 (13%)]\tLoss: 237.237839\n",
      "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 243.783737\n",
      "Train Epoch: 34 [3840/10000 (38%)]\tLoss: 234.836380\n",
      "Train Epoch: 34 [5120/10000 (51%)]\tLoss: 229.879715\n",
      "Train Epoch: 34 [6400/10000 (63%)]\tLoss: 234.504807\n",
      "Train Epoch: 34 [7680/10000 (76%)]\tLoss: 225.820923\n",
      "Train Epoch: 34 [8960/10000 (89%)]\tLoss: 244.884918\n",
      "Train Epoch: 35 [0/10000 (0%)]\tLoss: 234.268066\n",
      "Train Epoch: 35 [1280/10000 (13%)]\tLoss: 236.846848\n",
      "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 244.623901\n",
      "Train Epoch: 35 [3840/10000 (38%)]\tLoss: 236.244858\n",
      "Train Epoch: 35 [5120/10000 (51%)]\tLoss: 230.432144\n",
      "Train Epoch: 35 [6400/10000 (63%)]\tLoss: 233.016068\n",
      "Train Epoch: 35 [7680/10000 (76%)]\tLoss: 225.361984\n",
      "Train Epoch: 35 [8960/10000 (89%)]\tLoss: 245.017273\n",
      "Train Epoch: 36 [0/10000 (0%)]\tLoss: 232.011322\n",
      "Train Epoch: 36 [1280/10000 (13%)]\tLoss: 236.293060\n",
      "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 243.647568\n",
      "Train Epoch: 36 [3840/10000 (38%)]\tLoss: 235.580231\n",
      "Train Epoch: 36 [5120/10000 (51%)]\tLoss: 230.530243\n",
      "Train Epoch: 36 [6400/10000 (63%)]\tLoss: 233.417847\n",
      "Train Epoch: 36 [7680/10000 (76%)]\tLoss: 225.409927\n",
      "Train Epoch: 36 [8960/10000 (89%)]\tLoss: 244.066498\n",
      "Train Epoch: 37 [0/10000 (0%)]\tLoss: 233.615494\n",
      "Train Epoch: 37 [1280/10000 (13%)]\tLoss: 235.685516\n",
      "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 245.180573\n",
      "Train Epoch: 37 [3840/10000 (38%)]\tLoss: 235.192734\n",
      "Train Epoch: 37 [5120/10000 (51%)]\tLoss: 230.747452\n",
      "Train Epoch: 37 [6400/10000 (63%)]\tLoss: 233.549011\n",
      "Train Epoch: 37 [7680/10000 (76%)]\tLoss: 223.625366\n",
      "Train Epoch: 37 [8960/10000 (89%)]\tLoss: 246.291809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [0/10000 (0%)]\tLoss: 233.769989\n",
      "Train Epoch: 38 [1280/10000 (13%)]\tLoss: 235.783844\n",
      "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 243.619568\n",
      "Train Epoch: 38 [3840/10000 (38%)]\tLoss: 234.301453\n",
      "Train Epoch: 38 [5120/10000 (51%)]\tLoss: 229.690308\n",
      "Train Epoch: 38 [6400/10000 (63%)]\tLoss: 232.931900\n",
      "Train Epoch: 38 [7680/10000 (76%)]\tLoss: 223.385315\n",
      "Train Epoch: 38 [8960/10000 (89%)]\tLoss: 245.029678\n",
      "Train Epoch: 39 [0/10000 (0%)]\tLoss: 233.198776\n",
      "Train Epoch: 39 [1280/10000 (13%)]\tLoss: 236.349670\n",
      "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 242.761353\n",
      "Train Epoch: 39 [3840/10000 (38%)]\tLoss: 237.504654\n",
      "Train Epoch: 39 [5120/10000 (51%)]\tLoss: 231.404785\n",
      "Train Epoch: 39 [6400/10000 (63%)]\tLoss: 232.270416\n",
      "Train Epoch: 39 [7680/10000 (76%)]\tLoss: 224.826355\n",
      "Train Epoch: 39 [8960/10000 (89%)]\tLoss: 245.322586\n",
      "Train Epoch: 40 [0/10000 (0%)]\tLoss: 233.441650\n",
      "Train Epoch: 40 [1280/10000 (13%)]\tLoss: 235.922485\n",
      "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 243.939484\n",
      "Train Epoch: 40 [3840/10000 (38%)]\tLoss: 234.061096\n",
      "Train Epoch: 40 [5120/10000 (51%)]\tLoss: 230.718933\n",
      "Train Epoch: 40 [6400/10000 (63%)]\tLoss: 232.207184\n",
      "Train Epoch: 40 [7680/10000 (76%)]\tLoss: 226.318787\n",
      "Train Epoch: 40 [8960/10000 (89%)]\tLoss: 243.013306\n",
      "Train Epoch: 0 [0/10000 (0%)]\tLoss: 229.362244\n",
      "Train Epoch: 0 [1280/10000 (13%)]\tLoss: 231.254425\n",
      "Train Epoch: 0 [2560/10000 (25%)]\tLoss: 239.583069\n",
      "Train Epoch: 0 [3840/10000 (38%)]\tLoss: 231.322388\n",
      "Train Epoch: 0 [5120/10000 (51%)]\tLoss: 226.439865\n",
      "Train Epoch: 0 [6400/10000 (63%)]\tLoss: 227.670349\n",
      "Train Epoch: 0 [7680/10000 (76%)]\tLoss: 221.150940\n",
      "Train Epoch: 0 [8960/10000 (89%)]\tLoss: 239.903091\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 228.638092\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 230.877991\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 237.900101\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 230.204651\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 224.906494\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 229.675171\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 221.956955\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 240.894928\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 228.728607\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 229.449127\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 241.291458\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 231.634415\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 225.219574\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 228.697632\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 222.460876\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 239.779053\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 228.827759\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 230.860657\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 238.032043\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 230.984512\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 226.889511\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 228.871582\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 220.759338\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 240.459717\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 229.158997\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 230.773682\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 239.350052\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 229.918457\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 225.121735\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 228.833923\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 220.473572\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 241.292328\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 228.663025\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 230.894684\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 237.726288\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 229.408707\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 224.240936\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 227.492004\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 221.257507\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 241.549530\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 227.882858\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 231.095383\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 240.213135\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 229.359711\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 226.087219\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 228.227112\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 221.319061\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 241.130951\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 227.490112\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 231.942200\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 239.990005\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 229.630280\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 224.251221\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 227.308182\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 219.463318\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 239.767883\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 227.726532\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 232.235748\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 238.831238\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 230.252167\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 224.428421\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 229.174850\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 220.053925\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 240.310944\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 226.977844\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 230.922302\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 237.875748\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 230.533218\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 226.656708\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 228.039978\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 220.874725\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 241.015106\n",
      "====> Test set NLL: 231.6458\n",
      "Running time: 13436.21875 Seconds\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 544.117798\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 212.693604\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 202.764435\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 198.166885\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 209.845688\n",
      "====> Test set loss: 207.0557\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 204.339417\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 211.178268\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 205.219971\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 213.711395\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 210.809891\n",
      "====> Test set loss: 206.6956\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 205.325409\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 204.637299\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 211.114899\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 203.361725\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 203.444168\n",
      "====> Test set loss: 206.5808\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 204.043427\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 202.030380\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 201.206543\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 201.552734\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 209.486664\n",
      "====> Test set loss: 206.1211\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 210.038666\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 210.802155\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 206.838272\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 206.797943\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 209.427963\n",
      "====> Test set loss: 206.2860\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 213.786407\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 206.922394\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 197.387787\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 206.027252\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 205.916138\n",
      "====> Test set loss: 203.4679\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 203.230774\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 208.110519\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 202.844513\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 199.292358\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 196.586609\n",
      "====> Test set loss: 206.2150\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 200.344299\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 212.705475\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 204.264572\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 211.387177\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 215.116058\n",
      "====> Test set loss: 205.8312\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 200.650055\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 204.400543\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 208.062775\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 206.044342\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 201.418381\n",
      "====> Test set loss: 202.6040\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 203.866425\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 208.376404\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 204.737244\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 209.270416\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 206.128906\n",
      "====> Test set loss: 211.6887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 215.663025\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 213.719391\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 191.859894\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 207.567673\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 218.548157\n",
      "====> Test set loss: 195.4048\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 198.793961\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 214.112946\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 209.491302\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 193.856766\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 216.638275\n",
      "====> Test set loss: 195.6504\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 194.663116\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 215.508759\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 198.248108\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 195.275970\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 195.377167\n",
      "====> Test set loss: 223.8770\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 227.477173\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 196.892792\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 201.371277\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 198.737396\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 198.039017\n",
      "====> Test set loss: 204.4399\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 206.035675\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 192.263092\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 220.335556\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 200.038910\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 204.189789\n",
      "====> Test set loss: 196.2484\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 196.665695\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 223.493866\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 207.774216\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 206.205109\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 199.497894\n",
      "====> Test set loss: 205.3531\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 203.389130\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 206.591965\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 205.222427\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 208.958954\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 213.738251\n",
      "====> Test set loss: 208.2405\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 209.833069\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 207.130127\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 211.388397\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 206.463394\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 211.684845\n",
      "====> Test set loss: 206.7349\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 199.670319\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 211.711349\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 199.307037\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 208.191833\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 208.982956\n",
      "====> Test set loss: 207.0803\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 202.751038\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 214.344452\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 203.439362\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 210.805557\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 200.243729\n",
      "====> Test set loss: 207.9969\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 199.795563\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 211.395676\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 203.823578\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 209.230682\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 197.379974\n",
      "====> Test set loss: 209.1292\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 202.703201\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 211.793991\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 207.126053\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 200.798767\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 208.278610\n",
      "====> Test set loss: 209.4120\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 211.701660\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 210.538605\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 205.043976\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 213.018402\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 207.848831\n",
      "====> Test set loss: 206.1982\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 207.366837\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 202.787811\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 203.091812\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 211.652924\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 206.987961\n",
      "====> Test set loss: 207.1072\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 198.875549\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 200.944977\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 208.693787\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 204.589233\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 208.888458\n",
      "====> Test set loss: 208.5181\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 207.226028\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 206.053833\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 210.843430\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 210.648590\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 198.180023\n",
      "====> Test set loss: 203.7684\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 203.005798\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 207.231018\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 222.613770\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 212.232849\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 198.905136\n",
      "====> Test set loss: 203.6482\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 205.620819\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 204.818604\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 207.630585\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 201.630981\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 210.320496\n",
      "====> Test set loss: 206.6702\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 201.520752\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 203.571777\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 210.718048\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 205.595322\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 207.709351\n",
      "====> Test set loss: 205.8361\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 207.896255\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 200.531647\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 204.772064\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 209.753479\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 209.177261\n",
      "====> Test set loss: 207.5423\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 208.234619\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 212.674103\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 205.297195\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 211.441940\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 204.751160\n",
      "====> Test set loss: 206.9615\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 212.273315\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 204.770432\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 206.438934\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 204.238922\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 203.115204\n",
      "====> Test set loss: 206.9622\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 214.049774\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 201.909485\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 208.295288\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 203.742981\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 197.525604\n",
      "====> Test set loss: 205.7766\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 206.795670\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 197.293732\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 205.912415\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 209.705841\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 213.626160\n",
      "====> Test set loss: 207.6150\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 203.800842\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 199.985107\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 204.508972\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 207.649704\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 210.859772\n",
      "====> Test set loss: 206.7956\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 207.742828\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 204.892120\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 199.813812\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 199.153931\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 208.001633\n",
      "====> Test set loss: 206.2006\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 209.208160\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 206.581650\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 216.336212\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 203.749939\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 202.587891\n",
      "====> Test set loss: 205.5860\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 202.147736\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 208.171844\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 202.356384\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 207.991547\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 206.711884\n",
      "====> Test set loss: 206.6784\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 210.898392\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 207.356339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 203.973907\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 201.676849\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 209.156311\n",
      "====> Test set loss: 206.4566\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 204.757751\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 202.007080\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 205.356903\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 202.633881\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 199.927673\n",
      "====> Test set loss: 204.1159\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 204.612961\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 202.936584\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 203.736496\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 211.176086\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 206.110077\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 215.832596\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 231.308136\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 235.127869\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 201.991745\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 202.234344\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 204.529633\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 210.716080\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 206.008057\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 215.543488\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 231.498566\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 234.924423\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 202.477829\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 203.003693\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 203.949661\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 210.310699\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 206.790024\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 215.755035\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 230.751556\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 235.231995\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 203.172211\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 202.408112\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 203.344757\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 209.406342\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 206.678894\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 215.055130\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 231.529022\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 235.003281\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 202.402130\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 202.815155\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 202.950378\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 209.333893\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 205.734299\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 215.601654\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 231.433823\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 234.138123\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 202.574219\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 202.161682\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 203.097061\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 210.496292\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 204.869812\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 215.892120\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 230.840012\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 234.547333\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 202.673950\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 202.631149\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 203.363861\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 210.101547\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 205.516296\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 215.812683\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 230.893188\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 235.076675\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 202.358673\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 202.346909\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 203.339355\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 210.903381\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 205.983200\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 215.359940\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 231.187149\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 234.897186\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 201.998703\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 202.993530\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 203.494171\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 210.215240\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 206.430542\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 216.383728\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 230.866547\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 235.017090\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 202.311005\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 202.936905\n",
      "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 204.007736\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 210.411469\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 205.869385\n",
      "Train Epoch: 10 [6400/10000 (63%)]\tLoss: 214.791901\n",
      "Train Epoch: 10 [7680/10000 (76%)]\tLoss: 230.401184\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 235.315720\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 202.160431\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 201.868698\n",
      "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 202.836975\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 210.608673\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 206.028427\n",
      "Train Epoch: 11 [6400/10000 (63%)]\tLoss: 215.687775\n",
      "Train Epoch: 11 [7680/10000 (76%)]\tLoss: 231.260742\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 234.374847\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 203.162827\n",
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 202.874664\n",
      "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 202.827667\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 210.233505\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 206.191772\n",
      "Train Epoch: 12 [6400/10000 (63%)]\tLoss: 215.869141\n",
      "Train Epoch: 12 [7680/10000 (76%)]\tLoss: 231.046753\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 235.227966\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 202.786133\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 202.086456\n",
      "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 202.731522\n",
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 210.218842\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 205.407074\n",
      "Train Epoch: 13 [6400/10000 (63%)]\tLoss: 215.529755\n",
      "Train Epoch: 13 [7680/10000 (76%)]\tLoss: 230.912384\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 234.596512\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 201.850510\n",
      "Train Epoch: 14 [1280/10000 (13%)]\tLoss: 202.439453\n",
      "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 203.220901\n",
      "Train Epoch: 14 [3840/10000 (38%)]\tLoss: 209.410294\n",
      "Train Epoch: 14 [5120/10000 (51%)]\tLoss: 205.341797\n",
      "Train Epoch: 14 [6400/10000 (63%)]\tLoss: 215.483887\n",
      "Train Epoch: 14 [7680/10000 (76%)]\tLoss: 231.163483\n",
      "Train Epoch: 14 [8960/10000 (89%)]\tLoss: 235.083969\n",
      "Train Epoch: 15 [0/10000 (0%)]\tLoss: 202.584412\n",
      "Train Epoch: 15 [1280/10000 (13%)]\tLoss: 202.449341\n",
      "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 203.720245\n",
      "Train Epoch: 15 [3840/10000 (38%)]\tLoss: 210.726776\n",
      "Train Epoch: 15 [5120/10000 (51%)]\tLoss: 204.992554\n",
      "Train Epoch: 15 [6400/10000 (63%)]\tLoss: 216.002289\n",
      "Train Epoch: 15 [7680/10000 (76%)]\tLoss: 231.064026\n",
      "Train Epoch: 15 [8960/10000 (89%)]\tLoss: 234.956024\n",
      "Train Epoch: 16 [0/10000 (0%)]\tLoss: 202.743073\n",
      "Train Epoch: 16 [1280/10000 (13%)]\tLoss: 202.810242\n",
      "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 202.766357\n",
      "Train Epoch: 16 [3840/10000 (38%)]\tLoss: 210.409668\n",
      "Train Epoch: 16 [5120/10000 (51%)]\tLoss: 205.526627\n",
      "Train Epoch: 16 [6400/10000 (63%)]\tLoss: 216.076813\n",
      "Train Epoch: 16 [7680/10000 (76%)]\tLoss: 230.952164\n",
      "Train Epoch: 16 [8960/10000 (89%)]\tLoss: 235.365936\n",
      "Train Epoch: 17 [0/10000 (0%)]\tLoss: 202.856873\n",
      "Train Epoch: 17 [1280/10000 (13%)]\tLoss: 202.519867\n",
      "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 203.627228\n",
      "Train Epoch: 17 [3840/10000 (38%)]\tLoss: 210.972778\n",
      "Train Epoch: 17 [5120/10000 (51%)]\tLoss: 205.794205\n",
      "Train Epoch: 17 [6400/10000 (63%)]\tLoss: 216.088348\n",
      "Train Epoch: 17 [7680/10000 (76%)]\tLoss: 231.621017\n",
      "Train Epoch: 17 [8960/10000 (89%)]\tLoss: 234.594498\n",
      "Train Epoch: 18 [0/10000 (0%)]\tLoss: 202.223389\n",
      "Train Epoch: 18 [1280/10000 (13%)]\tLoss: 202.441223\n",
      "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 203.782303\n",
      "Train Epoch: 18 [3840/10000 (38%)]\tLoss: 210.964569\n",
      "Train Epoch: 18 [5120/10000 (51%)]\tLoss: 205.447815\n",
      "Train Epoch: 18 [6400/10000 (63%)]\tLoss: 215.252884\n",
      "Train Epoch: 18 [7680/10000 (76%)]\tLoss: 231.263031\n",
      "Train Epoch: 18 [8960/10000 (89%)]\tLoss: 234.654419\n",
      "Train Epoch: 19 [0/10000 (0%)]\tLoss: 201.446777\n",
      "Train Epoch: 19 [1280/10000 (13%)]\tLoss: 202.752960\n",
      "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 202.525909\n",
      "Train Epoch: 19 [3840/10000 (38%)]\tLoss: 210.092041\n",
      "Train Epoch: 19 [5120/10000 (51%)]\tLoss: 205.604111\n",
      "Train Epoch: 19 [6400/10000 (63%)]\tLoss: 215.408112\n",
      "Train Epoch: 19 [7680/10000 (76%)]\tLoss: 231.034653\n",
      "Train Epoch: 19 [8960/10000 (89%)]\tLoss: 235.754227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [0/10000 (0%)]\tLoss: 202.381989\n",
      "Train Epoch: 20 [1280/10000 (13%)]\tLoss: 202.278702\n",
      "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 203.616608\n",
      "Train Epoch: 20 [3840/10000 (38%)]\tLoss: 211.202347\n",
      "Train Epoch: 20 [5120/10000 (51%)]\tLoss: 205.557770\n",
      "Train Epoch: 20 [6400/10000 (63%)]\tLoss: 215.401062\n",
      "Train Epoch: 20 [7680/10000 (76%)]\tLoss: 231.523911\n",
      "Train Epoch: 20 [8960/10000 (89%)]\tLoss: 234.497650\n",
      "Train Epoch: 21 [0/10000 (0%)]\tLoss: 202.186798\n",
      "Train Epoch: 21 [1280/10000 (13%)]\tLoss: 202.104218\n",
      "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 203.786469\n",
      "Train Epoch: 21 [3840/10000 (38%)]\tLoss: 210.429657\n",
      "Train Epoch: 21 [5120/10000 (51%)]\tLoss: 204.756714\n",
      "Train Epoch: 21 [6400/10000 (63%)]\tLoss: 215.696609\n",
      "Train Epoch: 21 [7680/10000 (76%)]\tLoss: 230.458725\n",
      "Train Epoch: 21 [8960/10000 (89%)]\tLoss: 234.689087\n",
      "Train Epoch: 22 [0/10000 (0%)]\tLoss: 202.034424\n",
      "Train Epoch: 22 [1280/10000 (13%)]\tLoss: 202.250214\n",
      "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 203.309952\n",
      "Train Epoch: 22 [3840/10000 (38%)]\tLoss: 210.250549\n",
      "Train Epoch: 22 [5120/10000 (51%)]\tLoss: 205.421356\n",
      "Train Epoch: 22 [6400/10000 (63%)]\tLoss: 215.552917\n",
      "Train Epoch: 22 [7680/10000 (76%)]\tLoss: 231.853455\n",
      "Train Epoch: 22 [8960/10000 (89%)]\tLoss: 233.410431\n",
      "Train Epoch: 23 [0/10000 (0%)]\tLoss: 202.083603\n",
      "Train Epoch: 23 [1280/10000 (13%)]\tLoss: 203.004456\n",
      "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 203.793121\n",
      "Train Epoch: 23 [3840/10000 (38%)]\tLoss: 210.665741\n",
      "Train Epoch: 23 [5120/10000 (51%)]\tLoss: 206.144318\n",
      "Train Epoch: 23 [6400/10000 (63%)]\tLoss: 216.176117\n",
      "Train Epoch: 23 [7680/10000 (76%)]\tLoss: 231.248291\n",
      "Train Epoch: 23 [8960/10000 (89%)]\tLoss: 235.237000\n",
      "Train Epoch: 24 [0/10000 (0%)]\tLoss: 201.766617\n",
      "Train Epoch: 24 [1280/10000 (13%)]\tLoss: 203.031860\n",
      "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 203.461594\n",
      "Train Epoch: 24 [3840/10000 (38%)]\tLoss: 210.661804\n",
      "Train Epoch: 24 [5120/10000 (51%)]\tLoss: 205.911163\n",
      "Train Epoch: 24 [6400/10000 (63%)]\tLoss: 215.102280\n",
      "Train Epoch: 24 [7680/10000 (76%)]\tLoss: 231.109283\n",
      "Train Epoch: 24 [8960/10000 (89%)]\tLoss: 233.431290\n",
      "Train Epoch: 25 [0/10000 (0%)]\tLoss: 202.501892\n",
      "Train Epoch: 25 [1280/10000 (13%)]\tLoss: 202.279922\n",
      "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 202.949493\n",
      "Train Epoch: 25 [3840/10000 (38%)]\tLoss: 210.143921\n",
      "Train Epoch: 25 [5120/10000 (51%)]\tLoss: 205.090973\n",
      "Train Epoch: 25 [6400/10000 (63%)]\tLoss: 216.054443\n",
      "Train Epoch: 25 [7680/10000 (76%)]\tLoss: 231.647491\n",
      "Train Epoch: 25 [8960/10000 (89%)]\tLoss: 235.062836\n",
      "Train Epoch: 26 [0/10000 (0%)]\tLoss: 201.891724\n",
      "Train Epoch: 26 [1280/10000 (13%)]\tLoss: 202.090088\n",
      "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 203.304016\n",
      "Train Epoch: 26 [3840/10000 (38%)]\tLoss: 210.122498\n",
      "Train Epoch: 26 [5120/10000 (51%)]\tLoss: 205.265533\n",
      "Train Epoch: 26 [6400/10000 (63%)]\tLoss: 216.195145\n",
      "Train Epoch: 26 [7680/10000 (76%)]\tLoss: 230.736572\n",
      "Train Epoch: 26 [8960/10000 (89%)]\tLoss: 235.446716\n",
      "Train Epoch: 27 [0/10000 (0%)]\tLoss: 202.050934\n",
      "Train Epoch: 27 [1280/10000 (13%)]\tLoss: 203.434937\n",
      "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 203.005005\n",
      "Train Epoch: 27 [3840/10000 (38%)]\tLoss: 210.774384\n",
      "Train Epoch: 27 [5120/10000 (51%)]\tLoss: 205.755051\n",
      "Train Epoch: 27 [6400/10000 (63%)]\tLoss: 215.654053\n",
      "Train Epoch: 27 [7680/10000 (76%)]\tLoss: 231.024536\n",
      "Train Epoch: 27 [8960/10000 (89%)]\tLoss: 234.402557\n",
      "Train Epoch: 28 [0/10000 (0%)]\tLoss: 202.495361\n",
      "Train Epoch: 28 [1280/10000 (13%)]\tLoss: 201.835251\n",
      "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 202.603210\n",
      "Train Epoch: 28 [3840/10000 (38%)]\tLoss: 209.733627\n",
      "Train Epoch: 28 [5120/10000 (51%)]\tLoss: 205.512238\n",
      "Train Epoch: 28 [6400/10000 (63%)]\tLoss: 215.430695\n",
      "Train Epoch: 28 [7680/10000 (76%)]\tLoss: 231.361664\n",
      "Train Epoch: 28 [8960/10000 (89%)]\tLoss: 234.713196\n",
      "Train Epoch: 29 [0/10000 (0%)]\tLoss: 202.083893\n",
      "Train Epoch: 29 [1280/10000 (13%)]\tLoss: 201.994141\n",
      "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 202.346161\n",
      "Train Epoch: 29 [3840/10000 (38%)]\tLoss: 211.290253\n",
      "Train Epoch: 29 [5120/10000 (51%)]\tLoss: 205.808914\n",
      "Train Epoch: 29 [6400/10000 (63%)]\tLoss: 216.280487\n",
      "Train Epoch: 29 [7680/10000 (76%)]\tLoss: 231.414932\n",
      "Train Epoch: 29 [8960/10000 (89%)]\tLoss: 235.429916\n",
      "Train Epoch: 30 [0/10000 (0%)]\tLoss: 202.489410\n",
      "Train Epoch: 30 [1280/10000 (13%)]\tLoss: 202.017151\n",
      "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 202.745911\n",
      "Train Epoch: 30 [3840/10000 (38%)]\tLoss: 209.957794\n",
      "Train Epoch: 30 [5120/10000 (51%)]\tLoss: 206.605347\n",
      "Train Epoch: 30 [6400/10000 (63%)]\tLoss: 215.924576\n",
      "Train Epoch: 30 [7680/10000 (76%)]\tLoss: 231.025513\n",
      "Train Epoch: 30 [8960/10000 (89%)]\tLoss: 235.199799\n",
      "Train Epoch: 31 [0/10000 (0%)]\tLoss: 201.402740\n",
      "Train Epoch: 31 [1280/10000 (13%)]\tLoss: 202.575348\n",
      "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 203.757843\n",
      "Train Epoch: 31 [3840/10000 (38%)]\tLoss: 209.835342\n",
      "Train Epoch: 31 [5120/10000 (51%)]\tLoss: 206.428741\n",
      "Train Epoch: 31 [6400/10000 (63%)]\tLoss: 215.942932\n",
      "Train Epoch: 31 [7680/10000 (76%)]\tLoss: 231.073639\n",
      "Train Epoch: 31 [8960/10000 (89%)]\tLoss: 235.753571\n",
      "Train Epoch: 32 [0/10000 (0%)]\tLoss: 201.724945\n",
      "Train Epoch: 32 [1280/10000 (13%)]\tLoss: 202.540115\n",
      "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 203.182068\n",
      "Train Epoch: 32 [3840/10000 (38%)]\tLoss: 210.096542\n",
      "Train Epoch: 32 [5120/10000 (51%)]\tLoss: 205.885071\n",
      "Train Epoch: 32 [6400/10000 (63%)]\tLoss: 215.819153\n",
      "Train Epoch: 32 [7680/10000 (76%)]\tLoss: 232.060699\n",
      "Train Epoch: 32 [8960/10000 (89%)]\tLoss: 234.113037\n",
      "Train Epoch: 33 [0/10000 (0%)]\tLoss: 202.038910\n",
      "Train Epoch: 33 [1280/10000 (13%)]\tLoss: 203.222321\n",
      "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 202.937469\n",
      "Train Epoch: 33 [3840/10000 (38%)]\tLoss: 211.103027\n",
      "Train Epoch: 33 [5120/10000 (51%)]\tLoss: 206.245560\n",
      "Train Epoch: 33 [6400/10000 (63%)]\tLoss: 215.376923\n",
      "Train Epoch: 33 [7680/10000 (76%)]\tLoss: 231.129700\n",
      "Train Epoch: 33 [8960/10000 (89%)]\tLoss: 235.239151\n",
      "Train Epoch: 34 [0/10000 (0%)]\tLoss: 202.720398\n",
      "Train Epoch: 34 [1280/10000 (13%)]\tLoss: 202.248764\n",
      "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 202.640411\n",
      "Train Epoch: 34 [3840/10000 (38%)]\tLoss: 210.349091\n",
      "Train Epoch: 34 [5120/10000 (51%)]\tLoss: 205.459106\n",
      "Train Epoch: 34 [6400/10000 (63%)]\tLoss: 215.539429\n",
      "Train Epoch: 34 [7680/10000 (76%)]\tLoss: 230.522522\n",
      "Train Epoch: 34 [8960/10000 (89%)]\tLoss: 234.102768\n",
      "Train Epoch: 35 [0/10000 (0%)]\tLoss: 202.243240\n",
      "Train Epoch: 35 [1280/10000 (13%)]\tLoss: 202.940887\n",
      "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 202.965088\n",
      "Train Epoch: 35 [3840/10000 (38%)]\tLoss: 209.443283\n",
      "Train Epoch: 35 [5120/10000 (51%)]\tLoss: 206.123566\n",
      "Train Epoch: 35 [6400/10000 (63%)]\tLoss: 215.291397\n",
      "Train Epoch: 35 [7680/10000 (76%)]\tLoss: 230.394394\n",
      "Train Epoch: 35 [8960/10000 (89%)]\tLoss: 235.264771\n",
      "Train Epoch: 36 [0/10000 (0%)]\tLoss: 202.215973\n",
      "Train Epoch: 36 [1280/10000 (13%)]\tLoss: 201.828506\n",
      "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 202.810623\n",
      "Train Epoch: 36 [3840/10000 (38%)]\tLoss: 209.656418\n",
      "Train Epoch: 36 [5120/10000 (51%)]\tLoss: 206.373520\n",
      "Train Epoch: 36 [6400/10000 (63%)]\tLoss: 216.221008\n",
      "Train Epoch: 36 [7680/10000 (76%)]\tLoss: 231.260956\n",
      "Train Epoch: 36 [8960/10000 (89%)]\tLoss: 233.904755\n",
      "Train Epoch: 37 [0/10000 (0%)]\tLoss: 202.931091\n",
      "Train Epoch: 37 [1280/10000 (13%)]\tLoss: 201.764572\n",
      "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 203.085846\n",
      "Train Epoch: 37 [3840/10000 (38%)]\tLoss: 210.261475\n",
      "Train Epoch: 37 [5120/10000 (51%)]\tLoss: 205.755615\n",
      "Train Epoch: 37 [6400/10000 (63%)]\tLoss: 215.435059\n",
      "Train Epoch: 37 [7680/10000 (76%)]\tLoss: 231.253250\n",
      "Train Epoch: 37 [8960/10000 (89%)]\tLoss: 234.900955\n",
      "Train Epoch: 38 [0/10000 (0%)]\tLoss: 202.599274\n",
      "Train Epoch: 38 [1280/10000 (13%)]\tLoss: 202.676270\n",
      "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 203.686020\n",
      "Train Epoch: 38 [3840/10000 (38%)]\tLoss: 210.196960\n",
      "Train Epoch: 38 [5120/10000 (51%)]\tLoss: 205.679352\n",
      "Train Epoch: 38 [6400/10000 (63%)]\tLoss: 216.429428\n",
      "Train Epoch: 38 [7680/10000 (76%)]\tLoss: 231.074554\n",
      "Train Epoch: 38 [8960/10000 (89%)]\tLoss: 234.825348\n",
      "Train Epoch: 39 [0/10000 (0%)]\tLoss: 202.531830\n",
      "Train Epoch: 39 [1280/10000 (13%)]\tLoss: 202.730042\n",
      "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 202.933548\n",
      "Train Epoch: 39 [3840/10000 (38%)]\tLoss: 210.101868\n",
      "Train Epoch: 39 [5120/10000 (51%)]\tLoss: 204.844421\n",
      "Train Epoch: 39 [6400/10000 (63%)]\tLoss: 216.045258\n",
      "Train Epoch: 39 [7680/10000 (76%)]\tLoss: 230.888855\n",
      "Train Epoch: 39 [8960/10000 (89%)]\tLoss: 235.198624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [0/10000 (0%)]\tLoss: 201.494995\n",
      "Train Epoch: 40 [1280/10000 (13%)]\tLoss: 203.171692\n",
      "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 204.526398\n",
      "Train Epoch: 40 [3840/10000 (38%)]\tLoss: 210.605057\n",
      "Train Epoch: 40 [5120/10000 (51%)]\tLoss: 205.240326\n",
      "Train Epoch: 40 [6400/10000 (63%)]\tLoss: 215.889343\n",
      "Train Epoch: 40 [7680/10000 (76%)]\tLoss: 230.710129\n",
      "Train Epoch: 40 [8960/10000 (89%)]\tLoss: 234.692307\n",
      "Train Epoch: 0 [0/10000 (0%)]\tLoss: 202.965973\n",
      "Train Epoch: 0 [1280/10000 (13%)]\tLoss: 201.952438\n",
      "Train Epoch: 0 [2560/10000 (25%)]\tLoss: 202.876266\n",
      "Train Epoch: 0 [3840/10000 (38%)]\tLoss: 210.262863\n",
      "Train Epoch: 0 [5120/10000 (51%)]\tLoss: 205.769440\n",
      "Train Epoch: 0 [6400/10000 (63%)]\tLoss: 216.268555\n",
      "Train Epoch: 0 [7680/10000 (76%)]\tLoss: 231.092606\n",
      "Train Epoch: 0 [8960/10000 (89%)]\tLoss: 234.768280\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 202.246063\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 202.815903\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 202.211548\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 210.540756\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 205.627960\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 215.885986\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 230.612701\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 235.125153\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 202.448425\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 202.950134\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 203.227966\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 210.141876\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 204.787827\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 215.995361\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 230.669769\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 235.072952\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 201.711334\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 201.860947\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 203.261353\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 210.129791\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 205.352051\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 215.792572\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 230.664444\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 234.489258\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 202.394714\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 202.267029\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 202.844864\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 210.753784\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 206.256851\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 215.370850\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 231.305542\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 235.602020\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 201.631241\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 201.562561\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 202.601624\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 210.575989\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 206.090332\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 215.143860\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 231.054626\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 234.871063\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 202.486267\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 202.644577\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 203.266968\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 210.091278\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 205.855560\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 215.988953\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 230.965912\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 234.904266\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 202.759430\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 202.978043\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 203.552124\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 209.417313\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 205.735168\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 216.023148\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 231.300293\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 234.364670\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 202.877609\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 202.911514\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 203.574219\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 210.126312\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 206.034302\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 215.305542\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 231.327377\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 235.823608\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 202.631958\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 202.374176\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 202.530991\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 210.470856\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 206.720276\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 215.705139\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 231.151459\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 234.340530\n",
      "====> Test set NLL: 209.9231\n",
      "Running time: 35052.671875 Seconds\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.703735\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 379.420837\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 371.772766\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 368.213684\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 351.542664\n",
      "====> Test set loss: 368.3632\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 371.640808\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 345.786072\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 392.599670\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 365.656738\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 367.930176\n",
      "====> Test set loss: 368.6836\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 371.670685\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 373.395142\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 398.015106\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 379.336853\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 381.272156\n",
      "====> Test set loss: 380.2391\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 376.198425\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 375.056458\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 377.661682\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 390.683716\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 382.933350\n",
      "====> Test set loss: 389.2225\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 384.532562\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 383.457642\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 382.177185\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 389.497192\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 374.538422\n",
      "====> Test set loss: 388.1197\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 379.871826\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 388.595703\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 390.925537\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 385.052612\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 383.421692\n",
      "====> Test set loss: 387.9507\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 382.731323\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 380.710175\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 392.020355\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 380.460632\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 384.431641\n",
      "====> Test set loss: 395.4375\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 387.399841\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 387.318237\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 384.550171\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 387.323822\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 388.764587\n",
      "====> Test set loss: 387.9137\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 385.823120\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 381.926239\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 388.904419\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 389.854370\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 393.719330\n",
      "====> Test set loss: 385.1315\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 381.619629\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 388.568237\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 384.073975\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 384.019318\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 384.360840\n",
      "====> Test set loss: 383.7395\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 380.376465\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 376.727478\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 383.398926\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 374.288269\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 391.839996\n",
      "====> Test set loss: 383.4373\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 371.251709\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 384.927673\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 379.974060\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 381.246094\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 387.599365\n",
      "====> Test set loss: 386.3138\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 383.802124\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 384.575012\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 376.741150\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 388.043762\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 388.059967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 383.9717\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 385.701965\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 379.492859\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 383.210510\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 380.024536\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 384.454681\n",
      "====> Test set loss: 384.2430\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 374.252136\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 386.563599\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 376.064178\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 382.143524\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 385.493164\n",
      "====> Test set loss: 383.8242\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 382.721008\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 390.777222\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 379.825867\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 366.749664\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 389.673706\n",
      "====> Test set loss: 384.5674\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 382.715179\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 375.593445\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 406.013306\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 395.629120\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 386.900970\n",
      "====> Test set loss: 385.9729\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 372.208191\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 383.547791\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 379.834930\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 388.176880\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 403.471863\n",
      "====> Test set loss: 385.8953\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 389.897980\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 394.054077\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 385.562134\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 393.552002\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 381.613464\n",
      "====> Test set loss: 384.5959\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 382.939117\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 398.144135\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 375.162964\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 381.005432\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 384.995300\n",
      "====> Test set loss: 386.4113\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 387.762268\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 379.922668\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 393.757416\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 384.991547\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 381.593445\n",
      "====> Test set loss: 384.8155\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 399.072205\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 381.193054\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 387.319092\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 378.043152\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 388.075470\n",
      "====> Test set loss: 384.9977\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 377.182587\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 387.412537\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 386.093079\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 382.476898\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 378.743347\n",
      "====> Test set loss: 387.1582\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 380.228302\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 397.058563\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 395.023346\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 374.368835\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 389.593994\n",
      "====> Test set loss: 385.4830\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 397.268738\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 386.377930\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 380.016602\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 389.133423\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 394.984619\n",
      "====> Test set loss: 387.7874\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 378.900757\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 386.814301\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 385.282654\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 389.775330\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 388.164429\n",
      "====> Test set loss: 386.6260\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 377.567017\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 387.857513\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 387.315216\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 384.036194\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 393.220703\n",
      "====> Test set loss: 386.3531\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 384.508545\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 377.258850\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 368.955841\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 374.769165\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 399.799652\n",
      "====> Test set loss: 387.0647\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 389.985107\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 375.041443\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 388.269287\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 375.533569\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 391.678986\n",
      "====> Test set loss: 387.0857\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 386.918762\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 390.150574\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 380.447510\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 386.142029\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 390.422729\n",
      "====> Test set loss: 385.4707\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 380.258362\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 387.153900\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 384.068817\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 391.150269\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 385.696198\n",
      "====> Test set loss: 386.4599\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 384.176941\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 384.282043\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 390.707855\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 386.136353\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 390.969727\n",
      "====> Test set loss: 384.6655\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 373.958099\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 395.405151\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 390.410095\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 381.242462\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 385.537109\n",
      "====> Test set loss: 384.6605\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 382.857239\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 384.100311\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 398.108582\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 388.670105\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 380.678558\n",
      "====> Test set loss: 385.5905\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 380.782593\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 383.025391\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 386.573975\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 379.220276\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 382.485443\n",
      "====> Test set loss: 385.4129\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 378.141296\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 391.431152\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 371.642639\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 388.756287\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 380.775421\n",
      "====> Test set loss: 386.6488\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 381.849457\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 389.753906\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 376.179443\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 387.498444\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 392.309387\n",
      "====> Test set loss: 387.0078\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 378.157043\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 385.032166\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 377.398743\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 383.729309\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 378.957153\n",
      "====> Test set loss: 386.7946\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 388.648010\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 386.773102\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 381.307129\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 380.323425\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 390.619415\n",
      "====> Test set loss: 386.6037\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 387.322754\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 381.044525\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 383.341553\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 379.214996\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 378.366699\n",
      "====> Test set loss: 384.8957\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 397.251312\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 392.291321\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 394.334991\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 384.061279\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 383.513611\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 387.204620\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 387.664062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 398.486572\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 396.256104\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 393.672821\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 394.105286\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 383.312561\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 383.141632\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 387.076599\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 388.255188\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 398.655823\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 395.092194\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 392.241974\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 394.184753\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 382.252411\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 383.443848\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 386.797974\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 388.069702\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 398.224487\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 395.940002\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 390.782166\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 394.105682\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 383.533569\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 383.050476\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 387.922668\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 388.902344\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 398.220856\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 396.497498\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 391.483154\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 395.225372\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 383.198914\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 383.739319\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 387.545837\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 387.758484\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 398.034729\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 396.096558\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 392.053345\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 395.440369\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 382.264832\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 383.347412\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 387.167023\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 387.413757\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 398.907532\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 394.751648\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 390.816284\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 393.645996\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 383.609436\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 382.955505\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 387.490997\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 387.963654\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 399.357635\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 394.788635\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 391.684631\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 395.622803\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 382.130737\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 383.285583\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 386.262817\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 387.615662\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 399.309265\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 396.690857\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 392.151978\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 394.872437\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 382.736786\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 383.510864\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 387.488037\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 388.585419\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 398.328247\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 394.655518\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 392.396362\n",
      "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 395.171265\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 383.728821\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 382.554016\n",
      "Train Epoch: 10 [6400/10000 (63%)]\tLoss: 387.608337\n",
      "Train Epoch: 10 [7680/10000 (76%)]\tLoss: 388.350952\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 398.265350\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 396.049438\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 392.726868\n",
      "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 396.023560\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 382.239441\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 383.169434\n",
      "Train Epoch: 11 [6400/10000 (63%)]\tLoss: 388.457611\n",
      "Train Epoch: 11 [7680/10000 (76%)]\tLoss: 386.894989\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 398.382599\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 396.087646\n",
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 391.897980\n",
      "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 394.010315\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 383.855164\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 383.794312\n",
      "Train Epoch: 12 [6400/10000 (63%)]\tLoss: 387.127686\n",
      "Train Epoch: 12 [7680/10000 (76%)]\tLoss: 387.023987\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 397.539246\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 395.838684\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 392.297455\n",
      "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 395.413269\n",
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 383.587463\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 381.838501\n",
      "Train Epoch: 13 [6400/10000 (63%)]\tLoss: 387.272156\n",
      "Train Epoch: 13 [7680/10000 (76%)]\tLoss: 387.731812\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 397.707397\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 395.843323\n",
      "Train Epoch: 14 [1280/10000 (13%)]\tLoss: 391.385925\n",
      "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 395.116455\n",
      "Train Epoch: 14 [3840/10000 (38%)]\tLoss: 384.108093\n",
      "Train Epoch: 14 [5120/10000 (51%)]\tLoss: 383.101746\n",
      "Train Epoch: 14 [6400/10000 (63%)]\tLoss: 386.966980\n",
      "Train Epoch: 14 [7680/10000 (76%)]\tLoss: 387.416290\n",
      "Train Epoch: 14 [8960/10000 (89%)]\tLoss: 397.175323\n",
      "Train Epoch: 15 [0/10000 (0%)]\tLoss: 396.808228\n",
      "Train Epoch: 15 [1280/10000 (13%)]\tLoss: 390.501282\n",
      "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 394.852936\n",
      "Train Epoch: 15 [3840/10000 (38%)]\tLoss: 384.095886\n",
      "Train Epoch: 15 [5120/10000 (51%)]\tLoss: 382.562195\n",
      "Train Epoch: 15 [6400/10000 (63%)]\tLoss: 386.426819\n",
      "Train Epoch: 15 [7680/10000 (76%)]\tLoss: 386.990479\n",
      "Train Epoch: 15 [8960/10000 (89%)]\tLoss: 396.342804\n",
      "Train Epoch: 16 [0/10000 (0%)]\tLoss: 395.898193\n",
      "Train Epoch: 16 [1280/10000 (13%)]\tLoss: 391.693420\n",
      "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 393.553497\n",
      "Train Epoch: 16 [3840/10000 (38%)]\tLoss: 383.458282\n",
      "Train Epoch: 16 [5120/10000 (51%)]\tLoss: 382.930939\n",
      "Train Epoch: 16 [6400/10000 (63%)]\tLoss: 386.502289\n",
      "Train Epoch: 16 [7680/10000 (76%)]\tLoss: 387.097595\n",
      "Train Epoch: 16 [8960/10000 (89%)]\tLoss: 398.769897\n",
      "Train Epoch: 17 [0/10000 (0%)]\tLoss: 395.897766\n",
      "Train Epoch: 17 [1280/10000 (13%)]\tLoss: 390.951813\n",
      "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 393.808594\n",
      "Train Epoch: 17 [3840/10000 (38%)]\tLoss: 382.622131\n",
      "Train Epoch: 17 [5120/10000 (51%)]\tLoss: 383.417358\n",
      "Train Epoch: 17 [6400/10000 (63%)]\tLoss: 386.105469\n",
      "Train Epoch: 17 [7680/10000 (76%)]\tLoss: 387.640198\n",
      "Train Epoch: 17 [8960/10000 (89%)]\tLoss: 397.502167\n",
      "Train Epoch: 18 [0/10000 (0%)]\tLoss: 396.570190\n",
      "Train Epoch: 18 [1280/10000 (13%)]\tLoss: 392.433167\n",
      "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 395.461975\n",
      "Train Epoch: 18 [3840/10000 (38%)]\tLoss: 383.657257\n",
      "Train Epoch: 18 [5120/10000 (51%)]\tLoss: 383.511230\n",
      "Train Epoch: 18 [6400/10000 (63%)]\tLoss: 386.619263\n",
      "Train Epoch: 18 [7680/10000 (76%)]\tLoss: 387.680725\n",
      "Train Epoch: 18 [8960/10000 (89%)]\tLoss: 397.446106\n",
      "Train Epoch: 19 [0/10000 (0%)]\tLoss: 396.068420\n",
      "Train Epoch: 19 [1280/10000 (13%)]\tLoss: 391.882080\n",
      "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 394.201599\n",
      "Train Epoch: 19 [3840/10000 (38%)]\tLoss: 383.050598\n",
      "Train Epoch: 19 [5120/10000 (51%)]\tLoss: 383.857635\n",
      "Train Epoch: 19 [6400/10000 (63%)]\tLoss: 387.709229\n",
      "Train Epoch: 19 [7680/10000 (76%)]\tLoss: 387.477173\n",
      "Train Epoch: 19 [8960/10000 (89%)]\tLoss: 397.695862\n",
      "Train Epoch: 20 [0/10000 (0%)]\tLoss: 395.701477\n",
      "Train Epoch: 20 [1280/10000 (13%)]\tLoss: 391.345093\n",
      "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 394.433228\n",
      "Train Epoch: 20 [3840/10000 (38%)]\tLoss: 382.764038\n",
      "Train Epoch: 20 [5120/10000 (51%)]\tLoss: 382.855103\n",
      "Train Epoch: 20 [6400/10000 (63%)]\tLoss: 387.824982\n",
      "Train Epoch: 20 [7680/10000 (76%)]\tLoss: 387.051636\n",
      "Train Epoch: 20 [8960/10000 (89%)]\tLoss: 397.924774\n",
      "Train Epoch: 21 [0/10000 (0%)]\tLoss: 395.679779\n",
      "Train Epoch: 21 [1280/10000 (13%)]\tLoss: 392.161407\n",
      "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 394.292297\n",
      "Train Epoch: 21 [3840/10000 (38%)]\tLoss: 382.357483\n",
      "Train Epoch: 21 [5120/10000 (51%)]\tLoss: 383.162964\n",
      "Train Epoch: 21 [6400/10000 (63%)]\tLoss: 387.566559\n",
      "Train Epoch: 21 [7680/10000 (76%)]\tLoss: 388.273071\n",
      "Train Epoch: 21 [8960/10000 (89%)]\tLoss: 398.288208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [0/10000 (0%)]\tLoss: 394.907043\n",
      "Train Epoch: 22 [1280/10000 (13%)]\tLoss: 391.639160\n",
      "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 395.119507\n",
      "Train Epoch: 22 [3840/10000 (38%)]\tLoss: 383.820007\n",
      "Train Epoch: 22 [5120/10000 (51%)]\tLoss: 383.697052\n",
      "Train Epoch: 22 [6400/10000 (63%)]\tLoss: 386.191437\n",
      "Train Epoch: 22 [7680/10000 (76%)]\tLoss: 387.197449\n",
      "Train Epoch: 22 [8960/10000 (89%)]\tLoss: 398.175507\n",
      "Train Epoch: 23 [0/10000 (0%)]\tLoss: 396.559082\n",
      "Train Epoch: 23 [1280/10000 (13%)]\tLoss: 390.240234\n",
      "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 395.091248\n",
      "Train Epoch: 23 [3840/10000 (38%)]\tLoss: 383.391022\n",
      "Train Epoch: 23 [5120/10000 (51%)]\tLoss: 382.826660\n",
      "Train Epoch: 23 [6400/10000 (63%)]\tLoss: 387.254883\n",
      "Train Epoch: 23 [7680/10000 (76%)]\tLoss: 387.757019\n",
      "Train Epoch: 23 [8960/10000 (89%)]\tLoss: 397.799011\n",
      "Train Epoch: 24 [0/10000 (0%)]\tLoss: 396.136841\n",
      "Train Epoch: 24 [1280/10000 (13%)]\tLoss: 392.282227\n",
      "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 394.326935\n",
      "Train Epoch: 24 [3840/10000 (38%)]\tLoss: 383.291687\n",
      "Train Epoch: 24 [5120/10000 (51%)]\tLoss: 383.482483\n",
      "Train Epoch: 24 [6400/10000 (63%)]\tLoss: 386.552002\n",
      "Train Epoch: 24 [7680/10000 (76%)]\tLoss: 386.811920\n",
      "Train Epoch: 24 [8960/10000 (89%)]\tLoss: 398.320343\n",
      "Train Epoch: 25 [0/10000 (0%)]\tLoss: 396.788757\n",
      "Train Epoch: 25 [1280/10000 (13%)]\tLoss: 392.584167\n",
      "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 393.844177\n",
      "Train Epoch: 25 [3840/10000 (38%)]\tLoss: 381.243042\n",
      "Train Epoch: 25 [5120/10000 (51%)]\tLoss: 383.882935\n",
      "Train Epoch: 25 [6400/10000 (63%)]\tLoss: 387.934021\n",
      "Train Epoch: 25 [7680/10000 (76%)]\tLoss: 387.696533\n",
      "Train Epoch: 25 [8960/10000 (89%)]\tLoss: 397.032654\n",
      "Train Epoch: 26 [0/10000 (0%)]\tLoss: 396.866394\n",
      "Train Epoch: 26 [1280/10000 (13%)]\tLoss: 389.337341\n",
      "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 394.411072\n",
      "Train Epoch: 26 [3840/10000 (38%)]\tLoss: 383.214478\n",
      "Train Epoch: 26 [5120/10000 (51%)]\tLoss: 383.313568\n",
      "Train Epoch: 26 [6400/10000 (63%)]\tLoss: 387.741455\n",
      "Train Epoch: 26 [7680/10000 (76%)]\tLoss: 387.533875\n",
      "Train Epoch: 26 [8960/10000 (89%)]\tLoss: 399.357208\n",
      "Train Epoch: 27 [0/10000 (0%)]\tLoss: 397.307434\n",
      "Train Epoch: 27 [1280/10000 (13%)]\tLoss: 391.149536\n",
      "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 395.401794\n",
      "Train Epoch: 27 [3840/10000 (38%)]\tLoss: 382.316162\n",
      "Train Epoch: 27 [5120/10000 (51%)]\tLoss: 384.348083\n",
      "Train Epoch: 27 [6400/10000 (63%)]\tLoss: 387.644867\n",
      "Train Epoch: 27 [7680/10000 (76%)]\tLoss: 386.862274\n",
      "Train Epoch: 27 [8960/10000 (89%)]\tLoss: 396.856140\n",
      "Train Epoch: 28 [0/10000 (0%)]\tLoss: 395.696808\n",
      "Train Epoch: 28 [1280/10000 (13%)]\tLoss: 391.713654\n",
      "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 393.244965\n",
      "Train Epoch: 28 [3840/10000 (38%)]\tLoss: 382.544006\n",
      "Train Epoch: 28 [5120/10000 (51%)]\tLoss: 383.779419\n",
      "Train Epoch: 28 [6400/10000 (63%)]\tLoss: 386.876801\n",
      "Train Epoch: 28 [7680/10000 (76%)]\tLoss: 387.966370\n",
      "Train Epoch: 28 [8960/10000 (89%)]\tLoss: 399.488098\n",
      "Train Epoch: 29 [0/10000 (0%)]\tLoss: 395.391846\n",
      "Train Epoch: 29 [1280/10000 (13%)]\tLoss: 391.337646\n",
      "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 394.142975\n",
      "Train Epoch: 29 [3840/10000 (38%)]\tLoss: 382.255188\n",
      "Train Epoch: 29 [5120/10000 (51%)]\tLoss: 382.311005\n",
      "Train Epoch: 29 [6400/10000 (63%)]\tLoss: 386.539886\n",
      "Train Epoch: 29 [7680/10000 (76%)]\tLoss: 388.183014\n",
      "Train Epoch: 29 [8960/10000 (89%)]\tLoss: 398.941864\n",
      "Train Epoch: 30 [0/10000 (0%)]\tLoss: 395.557281\n",
      "Train Epoch: 30 [1280/10000 (13%)]\tLoss: 391.078064\n",
      "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 394.327454\n",
      "Train Epoch: 30 [3840/10000 (38%)]\tLoss: 382.444000\n",
      "Train Epoch: 30 [5120/10000 (51%)]\tLoss: 383.263031\n",
      "Train Epoch: 30 [6400/10000 (63%)]\tLoss: 386.270264\n",
      "Train Epoch: 30 [7680/10000 (76%)]\tLoss: 388.569733\n",
      "Train Epoch: 30 [8960/10000 (89%)]\tLoss: 398.890930\n",
      "Train Epoch: 31 [0/10000 (0%)]\tLoss: 397.588867\n",
      "Train Epoch: 31 [1280/10000 (13%)]\tLoss: 390.437378\n",
      "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 393.126373\n",
      "Train Epoch: 31 [3840/10000 (38%)]\tLoss: 383.116882\n",
      "Train Epoch: 31 [5120/10000 (51%)]\tLoss: 381.759064\n",
      "Train Epoch: 31 [6400/10000 (63%)]\tLoss: 386.590607\n",
      "Train Epoch: 31 [7680/10000 (76%)]\tLoss: 387.371338\n",
      "Train Epoch: 31 [8960/10000 (89%)]\tLoss: 397.543945\n",
      "Train Epoch: 32 [0/10000 (0%)]\tLoss: 396.264160\n",
      "Train Epoch: 32 [1280/10000 (13%)]\tLoss: 392.885376\n",
      "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 395.291046\n",
      "Train Epoch: 32 [3840/10000 (38%)]\tLoss: 384.029449\n",
      "Train Epoch: 32 [5120/10000 (51%)]\tLoss: 383.385651\n",
      "Train Epoch: 32 [6400/10000 (63%)]\tLoss: 387.587128\n",
      "Train Epoch: 32 [7680/10000 (76%)]\tLoss: 387.293549\n",
      "Train Epoch: 32 [8960/10000 (89%)]\tLoss: 399.242493\n",
      "Train Epoch: 33 [0/10000 (0%)]\tLoss: 395.468811\n",
      "Train Epoch: 33 [1280/10000 (13%)]\tLoss: 391.005768\n",
      "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 395.281677\n",
      "Train Epoch: 33 [3840/10000 (38%)]\tLoss: 382.838745\n",
      "Train Epoch: 33 [5120/10000 (51%)]\tLoss: 383.811218\n",
      "Train Epoch: 33 [6400/10000 (63%)]\tLoss: 388.387207\n",
      "Train Epoch: 33 [7680/10000 (76%)]\tLoss: 387.896545\n",
      "Train Epoch: 33 [8960/10000 (89%)]\tLoss: 397.871796\n",
      "Train Epoch: 34 [0/10000 (0%)]\tLoss: 396.487396\n",
      "Train Epoch: 34 [1280/10000 (13%)]\tLoss: 389.639435\n",
      "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 394.848816\n",
      "Train Epoch: 34 [3840/10000 (38%)]\tLoss: 382.025940\n",
      "Train Epoch: 34 [5120/10000 (51%)]\tLoss: 383.685394\n",
      "Train Epoch: 34 [6400/10000 (63%)]\tLoss: 386.994019\n",
      "Train Epoch: 34 [7680/10000 (76%)]\tLoss: 386.863281\n",
      "Train Epoch: 34 [8960/10000 (89%)]\tLoss: 398.651398\n",
      "Train Epoch: 35 [0/10000 (0%)]\tLoss: 395.425232\n",
      "Train Epoch: 35 [1280/10000 (13%)]\tLoss: 391.378662\n",
      "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 394.907898\n",
      "Train Epoch: 35 [3840/10000 (38%)]\tLoss: 383.851624\n",
      "Train Epoch: 35 [5120/10000 (51%)]\tLoss: 382.087860\n",
      "Train Epoch: 35 [6400/10000 (63%)]\tLoss: 387.686523\n",
      "Train Epoch: 35 [7680/10000 (76%)]\tLoss: 387.754272\n",
      "Train Epoch: 35 [8960/10000 (89%)]\tLoss: 398.992737\n",
      "Train Epoch: 36 [0/10000 (0%)]\tLoss: 394.413147\n",
      "Train Epoch: 36 [1280/10000 (13%)]\tLoss: 391.765991\n",
      "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 394.855225\n",
      "Train Epoch: 36 [3840/10000 (38%)]\tLoss: 383.513885\n",
      "Train Epoch: 36 [5120/10000 (51%)]\tLoss: 383.160217\n",
      "Train Epoch: 36 [6400/10000 (63%)]\tLoss: 387.340363\n",
      "Train Epoch: 36 [7680/10000 (76%)]\tLoss: 388.200806\n",
      "Train Epoch: 36 [8960/10000 (89%)]\tLoss: 399.112396\n",
      "Train Epoch: 37 [0/10000 (0%)]\tLoss: 396.129883\n",
      "Train Epoch: 37 [1280/10000 (13%)]\tLoss: 391.563416\n",
      "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 394.523071\n",
      "Train Epoch: 37 [3840/10000 (38%)]\tLoss: 382.717743\n",
      "Train Epoch: 37 [5120/10000 (51%)]\tLoss: 382.899902\n",
      "Train Epoch: 37 [6400/10000 (63%)]\tLoss: 386.873779\n",
      "Train Epoch: 37 [7680/10000 (76%)]\tLoss: 386.657837\n",
      "Train Epoch: 37 [8960/10000 (89%)]\tLoss: 397.789124\n",
      "Train Epoch: 38 [0/10000 (0%)]\tLoss: 395.652252\n",
      "Train Epoch: 38 [1280/10000 (13%)]\tLoss: 390.870300\n",
      "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 393.494995\n",
      "Train Epoch: 38 [3840/10000 (38%)]\tLoss: 383.045319\n",
      "Train Epoch: 38 [5120/10000 (51%)]\tLoss: 383.221680\n",
      "Train Epoch: 38 [6400/10000 (63%)]\tLoss: 387.516174\n",
      "Train Epoch: 38 [7680/10000 (76%)]\tLoss: 387.583801\n",
      "Train Epoch: 38 [8960/10000 (89%)]\tLoss: 398.745880\n",
      "Train Epoch: 39 [0/10000 (0%)]\tLoss: 396.291931\n",
      "Train Epoch: 39 [1280/10000 (13%)]\tLoss: 392.122467\n",
      "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 394.219025\n",
      "Train Epoch: 39 [3840/10000 (38%)]\tLoss: 382.479218\n",
      "Train Epoch: 39 [5120/10000 (51%)]\tLoss: 382.683411\n",
      "Train Epoch: 39 [6400/10000 (63%)]\tLoss: 387.045441\n",
      "Train Epoch: 39 [7680/10000 (76%)]\tLoss: 387.424377\n",
      "Train Epoch: 39 [8960/10000 (89%)]\tLoss: 397.528351\n",
      "Train Epoch: 40 [0/10000 (0%)]\tLoss: 397.415344\n",
      "Train Epoch: 40 [1280/10000 (13%)]\tLoss: 390.387909\n",
      "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 395.311462\n",
      "Train Epoch: 40 [3840/10000 (38%)]\tLoss: 382.863708\n",
      "Train Epoch: 40 [5120/10000 (51%)]\tLoss: 382.427521\n",
      "Train Epoch: 40 [6400/10000 (63%)]\tLoss: 388.213135\n",
      "Train Epoch: 40 [7680/10000 (76%)]\tLoss: 387.138794\n",
      "Train Epoch: 40 [8960/10000 (89%)]\tLoss: 398.183746\n",
      "Train Epoch: 0 [0/10000 (0%)]\tLoss: 394.850037\n",
      "Train Epoch: 0 [1280/10000 (13%)]\tLoss: 391.008209\n",
      "Train Epoch: 0 [2560/10000 (25%)]\tLoss: 394.484741\n",
      "Train Epoch: 0 [3840/10000 (38%)]\tLoss: 382.616699\n",
      "Train Epoch: 0 [5120/10000 (51%)]\tLoss: 383.153015\n",
      "Train Epoch: 0 [6400/10000 (63%)]\tLoss: 388.016327\n",
      "Train Epoch: 0 [7680/10000 (76%)]\tLoss: 387.350952\n",
      "Train Epoch: 0 [8960/10000 (89%)]\tLoss: 397.615845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 395.804779\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 391.305695\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 394.973022\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 382.815033\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 383.601257\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 387.372192\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 388.367676\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 398.881470\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 396.539520\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 391.583069\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 394.938507\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 383.531372\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 383.965027\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 387.084137\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 386.219025\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 398.670044\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 395.177063\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 392.131836\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 394.695770\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 382.525299\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 382.920227\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 387.216705\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 387.278595\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 398.457062\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 396.754089\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 392.346680\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 394.634521\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 384.286652\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 383.951965\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 386.064392\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 387.346741\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 397.507874\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 396.434631\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 391.786560\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 394.064087\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 382.917480\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 382.851990\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 388.575195\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 387.330994\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 398.227051\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 396.021606\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 391.608368\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 394.033112\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 381.716370\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 384.380615\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 386.987488\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 387.030457\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 397.344604\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 395.019653\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 391.121552\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 395.027985\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 382.669067\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 385.200073\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 386.415161\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 387.548004\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 398.139404\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 395.327637\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 392.945984\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 392.862244\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 382.926788\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 382.178772\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 386.670135\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 386.750061\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 397.922485\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 396.290863\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 391.832825\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 395.351196\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 383.822144\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 384.111816\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 387.349609\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 388.013428\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 398.677490\n",
      "====> Test set NLL: 389.7032\n",
      "Running time: 34978.6875 Seconds\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 545.885071\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 195.890015\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 171.620682\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 144.515381\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 128.366287\n",
      "====> Test set loss: 124.9433\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 124.263962\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 114.692474\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 116.231354\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 108.887642\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 110.050949\n",
      "====> Test set loss: 110.0039\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 105.305267\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 113.606628\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 106.350922\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 105.996483\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 108.017822\n",
      "====> Test set loss: 104.8252\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 107.581673\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 103.274162\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 105.365997\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 102.319695\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 103.281822\n",
      "====> Test set loss: 102.6714\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 104.095596\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 99.224594\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 99.332840\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 101.786362\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 100.448425\n",
      "====> Test set loss: 101.2123\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 98.048759\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 102.887680\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 102.775146\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 95.530060\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 93.798248\n",
      "====> Test set loss: 99.9616\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 99.035614\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 100.380020\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 99.089745\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 100.557266\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 97.405426\n",
      "====> Test set loss: 99.2251\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 95.250534\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 100.616074\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 103.069099\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 100.353828\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 97.962120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 98.0813\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 97.721176\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 95.159050\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 98.877625\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 102.218307\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 95.780212\n",
      "====> Test set loss: 97.9425\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 97.971725\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 94.461838\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 101.876541\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 98.899025\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 103.166809\n",
      "====> Test set loss: 97.1815\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 98.531174\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 94.284683\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 96.032341\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 96.350998\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 94.457657\n",
      "====> Test set loss: 96.7787\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 97.058701\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 95.489311\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 95.772079\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 95.816383\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 98.005951\n",
      "====> Test set loss: 96.2061\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 93.904770\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 97.539322\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 96.110733\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 98.758606\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 92.082848\n",
      "====> Test set loss: 95.9096\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 96.665100\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 98.723373\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 95.736694\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 95.260574\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 91.755630\n",
      "====> Test set loss: 95.6717\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 98.619476\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 94.320358\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 90.987297\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 94.867378\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 101.690269\n",
      "====> Test set loss: 95.2904\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 97.712914\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 90.950966\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 93.656731\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 98.280266\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 92.644150\n",
      "====> Test set loss: 95.1713\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 96.131729\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 89.612335\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 94.894608\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 97.303909\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 98.381607\n",
      "====> Test set loss: 95.0325\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 93.938454\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 93.040565\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 96.480484\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 92.865860\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 93.725693\n",
      "====> Test set loss: 94.8880\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 92.784996\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 92.650421\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 93.803284\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 95.037941\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 93.041237\n",
      "====> Test set loss: 94.5661\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 92.549866\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 92.426132\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 94.565186\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 92.001755\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 90.717499\n",
      "====> Test set loss: 94.4325\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 92.808960\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 92.471077\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 94.813812\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 94.296249\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 97.115425\n",
      "====> Test set loss: 94.3478\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 92.660950\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 93.373428\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 97.051682\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 89.709869\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 94.552406\n",
      "====> Test set loss: 94.0995\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 93.754280\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 94.412384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 92.884544\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 92.827614\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 92.818375\n",
      "====> Test set loss: 94.2508\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 91.443970\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 92.967010\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 91.666687\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 95.088272\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 97.323402\n",
      "====> Test set loss: 93.8671\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 91.572182\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 92.528137\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 91.246307\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 96.736465\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 93.230133\n",
      "====> Test set loss: 93.7271\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 95.380066\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 94.507317\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 89.829781\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 93.015289\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 93.263245\n",
      "====> Test set loss: 93.6631\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 94.120422\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 94.883057\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 94.802994\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 93.516068\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 91.420547\n",
      "====> Test set loss: 93.4150\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 93.170044\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 92.347733\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 89.791321\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 96.636566\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 91.988815\n",
      "====> Test set loss: 93.6794\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 94.382927\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 88.522972\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 93.194412\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 98.256294\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 90.318382\n",
      "====> Test set loss: 93.4527\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 92.386185\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 94.214012\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 94.478958\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 90.778961\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 95.722061\n",
      "====> Test set loss: 93.7165\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 92.610481\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 93.246475\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 94.278732\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 90.369995\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 95.957291\n",
      "====> Test set loss: 93.2737\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 91.771561\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 91.982841\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 88.353470\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 92.311264\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 92.959976\n",
      "====> Test set loss: 93.3514\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 92.608749\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 94.484291\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 90.294922\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 91.294830\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 92.568726\n",
      "====> Test set loss: 93.0668\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 92.339676\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 90.896729\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 92.649040\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 91.405563\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 92.808121\n",
      "====> Test set loss: 93.0556\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 92.756561\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 90.894440\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 91.546494\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 92.548492\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 90.776436\n",
      "====> Test set loss: 92.8109\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 97.184929\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 92.737289\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 89.328690\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 94.243286\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 93.181877\n",
      "====> Test set loss: 92.9520\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 86.177582\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 90.700668\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 94.541756\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 87.195755\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 88.916290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 92.8116\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 93.766350\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 92.567619\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 89.123718\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 92.650146\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 90.738098\n",
      "====> Test set loss: 92.7133\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 91.388123\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 92.580856\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 94.212296\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 87.178543\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 93.129898\n",
      "====> Test set loss: 92.7519\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 91.084534\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 91.650238\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 91.264412\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 91.300552\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 91.764999\n",
      "====> Test set loss: 92.9703\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 557.267151\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 212.583603\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 171.808167\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 152.642242\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 141.027176\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 132.669312\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 131.212296\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 141.896042\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 128.626434\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 118.502502\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 116.570007\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 118.886497\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 110.984764\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 112.948730\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 111.286804\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 117.547287\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 110.020012\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 111.773445\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 108.812920\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 111.648804\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 102.727234\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 105.403503\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 106.747696\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 110.149200\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 103.974121\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 106.312553\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 104.973877\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 108.518845\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 101.256897\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 104.315697\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 103.407211\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 106.481186\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 102.586601\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 106.171043\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 102.142273\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 107.100983\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 101.322090\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 105.828239\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 101.153229\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 109.247559\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 100.402702\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 104.383446\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 102.552567\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 105.267410\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 99.299759\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 101.742203\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 99.771133\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 106.176102\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 98.997437\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 103.138550\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 100.920410\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 104.611626\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 99.022202\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 99.092346\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 98.625954\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 102.689362\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 98.947189\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 100.873894\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 98.523994\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 104.465508\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 96.890099\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 99.305283\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 99.395828\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 104.724945\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 98.670059\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 98.692444\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 98.626717\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 102.293671\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 98.715302\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 98.706085\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 98.855301\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 104.353645\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 98.413757\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 100.370026\n",
      "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 98.391708\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 101.650452\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 97.202560\n",
      "Train Epoch: 10 [6400/10000 (63%)]\tLoss: 99.872482\n",
      "Train Epoch: 10 [7680/10000 (76%)]\tLoss: 98.701996\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 104.935440\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 98.940216\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 98.817818\n",
      "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 96.755089\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 101.163765\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 97.144928\n",
      "Train Epoch: 11 [6400/10000 (63%)]\tLoss: 96.618607\n",
      "Train Epoch: 11 [7680/10000 (76%)]\tLoss: 96.706932\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 103.923294\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 97.174141\n",
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 97.490288\n",
      "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 97.176514\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 102.875259\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 97.827789\n",
      "Train Epoch: 12 [6400/10000 (63%)]\tLoss: 97.147896\n",
      "Train Epoch: 12 [7680/10000 (76%)]\tLoss: 96.939491\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 101.271889\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 96.635353\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 99.429054\n",
      "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 97.828804\n",
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 102.311630\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 96.457825\n",
      "Train Epoch: 13 [6400/10000 (63%)]\tLoss: 97.590866\n",
      "Train Epoch: 13 [7680/10000 (76%)]\tLoss: 95.396423\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 103.871536\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 95.858795\n",
      "Train Epoch: 14 [1280/10000 (13%)]\tLoss: 98.736412\n",
      "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 97.358269\n",
      "Train Epoch: 14 [3840/10000 (38%)]\tLoss: 102.214935\n",
      "Train Epoch: 14 [5120/10000 (51%)]\tLoss: 94.949333\n",
      "Train Epoch: 14 [6400/10000 (63%)]\tLoss: 96.721794\n",
      "Train Epoch: 14 [7680/10000 (76%)]\tLoss: 95.573418\n",
      "Train Epoch: 14 [8960/10000 (89%)]\tLoss: 99.728394\n",
      "Train Epoch: 15 [0/10000 (0%)]\tLoss: 94.356194\n",
      "Train Epoch: 15 [1280/10000 (13%)]\tLoss: 98.269852\n",
      "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 96.351654\n",
      "Train Epoch: 15 [3840/10000 (38%)]\tLoss: 100.625084\n",
      "Train Epoch: 15 [5120/10000 (51%)]\tLoss: 97.002808\n",
      "Train Epoch: 15 [6400/10000 (63%)]\tLoss: 97.014450\n",
      "Train Epoch: 15 [7680/10000 (76%)]\tLoss: 96.574188\n",
      "Train Epoch: 15 [8960/10000 (89%)]\tLoss: 102.797791\n",
      "Train Epoch: 16 [0/10000 (0%)]\tLoss: 95.536201\n",
      "Train Epoch: 16 [1280/10000 (13%)]\tLoss: 97.748825\n",
      "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 95.384064\n",
      "Train Epoch: 16 [3840/10000 (38%)]\tLoss: 100.058434\n",
      "Train Epoch: 16 [5120/10000 (51%)]\tLoss: 94.201736\n",
      "Train Epoch: 16 [6400/10000 (63%)]\tLoss: 98.877182\n",
      "Train Epoch: 16 [7680/10000 (76%)]\tLoss: 96.871445\n",
      "Train Epoch: 16 [8960/10000 (89%)]\tLoss: 100.837837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [0/10000 (0%)]\tLoss: 95.953598\n",
      "Train Epoch: 17 [1280/10000 (13%)]\tLoss: 97.402290\n",
      "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 97.713821\n",
      "Train Epoch: 17 [3840/10000 (38%)]\tLoss: 100.822433\n",
      "Train Epoch: 17 [5120/10000 (51%)]\tLoss: 94.863281\n",
      "Train Epoch: 17 [6400/10000 (63%)]\tLoss: 97.759926\n",
      "Train Epoch: 17 [7680/10000 (76%)]\tLoss: 95.650879\n",
      "Train Epoch: 17 [8960/10000 (89%)]\tLoss: 101.413620\n",
      "Train Epoch: 18 [0/10000 (0%)]\tLoss: 96.292877\n",
      "Train Epoch: 18 [1280/10000 (13%)]\tLoss: 97.033432\n",
      "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 94.904434\n",
      "Train Epoch: 18 [3840/10000 (38%)]\tLoss: 98.356186\n",
      "Train Epoch: 18 [5120/10000 (51%)]\tLoss: 95.317131\n",
      "Train Epoch: 18 [6400/10000 (63%)]\tLoss: 95.762283\n",
      "Train Epoch: 18 [7680/10000 (76%)]\tLoss: 95.000595\n",
      "Train Epoch: 18 [8960/10000 (89%)]\tLoss: 100.615196\n",
      "Train Epoch: 19 [0/10000 (0%)]\tLoss: 97.113129\n",
      "Train Epoch: 19 [1280/10000 (13%)]\tLoss: 97.618515\n",
      "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 95.796204\n",
      "Train Epoch: 19 [3840/10000 (38%)]\tLoss: 100.902039\n",
      "Train Epoch: 19 [5120/10000 (51%)]\tLoss: 96.369614\n",
      "Train Epoch: 19 [6400/10000 (63%)]\tLoss: 97.830254\n",
      "Train Epoch: 19 [7680/10000 (76%)]\tLoss: 93.725616\n",
      "Train Epoch: 19 [8960/10000 (89%)]\tLoss: 100.932091\n",
      "Train Epoch: 20 [0/10000 (0%)]\tLoss: 94.242340\n",
      "Train Epoch: 20 [1280/10000 (13%)]\tLoss: 96.550636\n",
      "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 95.524826\n",
      "Train Epoch: 20 [3840/10000 (38%)]\tLoss: 100.167130\n",
      "Train Epoch: 20 [5120/10000 (51%)]\tLoss: 93.707207\n",
      "Train Epoch: 20 [6400/10000 (63%)]\tLoss: 96.297691\n",
      "Train Epoch: 20 [7680/10000 (76%)]\tLoss: 95.301056\n",
      "Train Epoch: 20 [8960/10000 (89%)]\tLoss: 99.777451\n",
      "Train Epoch: 21 [0/10000 (0%)]\tLoss: 95.808144\n",
      "Train Epoch: 21 [1280/10000 (13%)]\tLoss: 95.844101\n",
      "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 95.032303\n",
      "Train Epoch: 21 [3840/10000 (38%)]\tLoss: 99.654861\n",
      "Train Epoch: 21 [5120/10000 (51%)]\tLoss: 93.664574\n",
      "Train Epoch: 21 [6400/10000 (63%)]\tLoss: 96.504692\n",
      "Train Epoch: 21 [7680/10000 (76%)]\tLoss: 94.931702\n",
      "Train Epoch: 21 [8960/10000 (89%)]\tLoss: 100.670807\n",
      "Train Epoch: 22 [0/10000 (0%)]\tLoss: 93.718956\n",
      "Train Epoch: 22 [1280/10000 (13%)]\tLoss: 95.355255\n",
      "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 94.512192\n",
      "Train Epoch: 22 [3840/10000 (38%)]\tLoss: 100.889336\n",
      "Train Epoch: 22 [5120/10000 (51%)]\tLoss: 93.773300\n",
      "Train Epoch: 22 [6400/10000 (63%)]\tLoss: 95.704231\n",
      "Train Epoch: 22 [7680/10000 (76%)]\tLoss: 95.233269\n",
      "Train Epoch: 22 [8960/10000 (89%)]\tLoss: 99.063492\n",
      "Train Epoch: 23 [0/10000 (0%)]\tLoss: 94.444946\n",
      "Train Epoch: 23 [1280/10000 (13%)]\tLoss: 95.112282\n",
      "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 96.834122\n",
      "Train Epoch: 23 [3840/10000 (38%)]\tLoss: 99.440475\n",
      "Train Epoch: 23 [5120/10000 (51%)]\tLoss: 94.560905\n",
      "Train Epoch: 23 [6400/10000 (63%)]\tLoss: 97.115562\n",
      "Train Epoch: 23 [7680/10000 (76%)]\tLoss: 94.317261\n",
      "Train Epoch: 23 [8960/10000 (89%)]\tLoss: 100.965935\n",
      "Train Epoch: 24 [0/10000 (0%)]\tLoss: 94.412216\n",
      "Train Epoch: 24 [1280/10000 (13%)]\tLoss: 96.672203\n",
      "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 95.444641\n",
      "Train Epoch: 24 [3840/10000 (38%)]\tLoss: 99.771553\n",
      "Train Epoch: 24 [5120/10000 (51%)]\tLoss: 94.683167\n",
      "Train Epoch: 24 [6400/10000 (63%)]\tLoss: 95.827744\n",
      "Train Epoch: 24 [7680/10000 (76%)]\tLoss: 95.640152\n",
      "Train Epoch: 24 [8960/10000 (89%)]\tLoss: 100.488144\n",
      "Train Epoch: 25 [0/10000 (0%)]\tLoss: 94.082291\n",
      "Train Epoch: 25 [1280/10000 (13%)]\tLoss: 95.826302\n",
      "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 95.322617\n",
      "Train Epoch: 25 [3840/10000 (38%)]\tLoss: 100.648254\n",
      "Train Epoch: 25 [5120/10000 (51%)]\tLoss: 93.869339\n",
      "Train Epoch: 25 [6400/10000 (63%)]\tLoss: 95.823357\n",
      "Train Epoch: 25 [7680/10000 (76%)]\tLoss: 93.827438\n",
      "Train Epoch: 25 [8960/10000 (89%)]\tLoss: 101.587914\n",
      "Train Epoch: 26 [0/10000 (0%)]\tLoss: 94.435913\n",
      "Train Epoch: 26 [1280/10000 (13%)]\tLoss: 96.977615\n",
      "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 96.008781\n",
      "Train Epoch: 26 [3840/10000 (38%)]\tLoss: 99.392586\n",
      "Train Epoch: 26 [5120/10000 (51%)]\tLoss: 93.614517\n",
      "Train Epoch: 26 [6400/10000 (63%)]\tLoss: 94.815964\n",
      "Train Epoch: 26 [7680/10000 (76%)]\tLoss: 95.229568\n",
      "Train Epoch: 26 [8960/10000 (89%)]\tLoss: 99.577477\n",
      "Train Epoch: 27 [0/10000 (0%)]\tLoss: 93.694168\n",
      "Train Epoch: 27 [1280/10000 (13%)]\tLoss: 96.556839\n",
      "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 95.933075\n",
      "Train Epoch: 27 [3840/10000 (38%)]\tLoss: 100.581406\n",
      "Train Epoch: 27 [5120/10000 (51%)]\tLoss: 95.434662\n",
      "Train Epoch: 27 [6400/10000 (63%)]\tLoss: 95.348312\n",
      "Train Epoch: 27 [7680/10000 (76%)]\tLoss: 94.150154\n",
      "Train Epoch: 27 [8960/10000 (89%)]\tLoss: 100.527390\n",
      "Train Epoch: 28 [0/10000 (0%)]\tLoss: 92.374207\n",
      "Train Epoch: 28 [1280/10000 (13%)]\tLoss: 97.877075\n",
      "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 96.213745\n",
      "Train Epoch: 28 [3840/10000 (38%)]\tLoss: 99.933556\n",
      "Train Epoch: 28 [5120/10000 (51%)]\tLoss: 95.113503\n",
      "Train Epoch: 28 [6400/10000 (63%)]\tLoss: 95.074081\n",
      "Train Epoch: 28 [7680/10000 (76%)]\tLoss: 94.515724\n",
      "Train Epoch: 28 [8960/10000 (89%)]\tLoss: 99.460052\n",
      "Train Epoch: 29 [0/10000 (0%)]\tLoss: 94.107376\n",
      "Train Epoch: 29 [1280/10000 (13%)]\tLoss: 95.869392\n",
      "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 94.300674\n",
      "Train Epoch: 29 [3840/10000 (38%)]\tLoss: 99.546135\n",
      "Train Epoch: 29 [5120/10000 (51%)]\tLoss: 93.379196\n",
      "Train Epoch: 29 [6400/10000 (63%)]\tLoss: 96.829453\n",
      "Train Epoch: 29 [7680/10000 (76%)]\tLoss: 94.945854\n",
      "Train Epoch: 29 [8960/10000 (89%)]\tLoss: 99.930664\n",
      "Train Epoch: 30 [0/10000 (0%)]\tLoss: 93.144760\n",
      "Train Epoch: 30 [1280/10000 (13%)]\tLoss: 96.600784\n",
      "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 94.890564\n",
      "Train Epoch: 30 [3840/10000 (38%)]\tLoss: 99.786057\n",
      "Train Epoch: 30 [5120/10000 (51%)]\tLoss: 94.002777\n",
      "Train Epoch: 30 [6400/10000 (63%)]\tLoss: 95.562431\n",
      "Train Epoch: 30 [7680/10000 (76%)]\tLoss: 93.396500\n",
      "Train Epoch: 30 [8960/10000 (89%)]\tLoss: 101.199677\n",
      "Train Epoch: 31 [0/10000 (0%)]\tLoss: 93.269981\n",
      "Train Epoch: 31 [1280/10000 (13%)]\tLoss: 97.664192\n",
      "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 95.375031\n",
      "Train Epoch: 31 [3840/10000 (38%)]\tLoss: 99.989067\n",
      "Train Epoch: 31 [5120/10000 (51%)]\tLoss: 95.093811\n",
      "Train Epoch: 31 [6400/10000 (63%)]\tLoss: 95.978294\n",
      "Train Epoch: 31 [7680/10000 (76%)]\tLoss: 92.798042\n",
      "Train Epoch: 31 [8960/10000 (89%)]\tLoss: 100.415543\n",
      "Train Epoch: 32 [0/10000 (0%)]\tLoss: 93.460892\n",
      "Train Epoch: 32 [1280/10000 (13%)]\tLoss: 97.045891\n",
      "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 95.635521\n",
      "Train Epoch: 32 [3840/10000 (38%)]\tLoss: 99.302765\n",
      "Train Epoch: 32 [5120/10000 (51%)]\tLoss: 93.791039\n",
      "Train Epoch: 32 [6400/10000 (63%)]\tLoss: 95.184090\n",
      "Train Epoch: 32 [7680/10000 (76%)]\tLoss: 95.131058\n",
      "Train Epoch: 32 [8960/10000 (89%)]\tLoss: 97.167587\n",
      "Train Epoch: 33 [0/10000 (0%)]\tLoss: 94.381149\n",
      "Train Epoch: 33 [1280/10000 (13%)]\tLoss: 95.053177\n",
      "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 93.863724\n",
      "Train Epoch: 33 [3840/10000 (38%)]\tLoss: 100.539032\n",
      "Train Epoch: 33 [5120/10000 (51%)]\tLoss: 94.635948\n",
      "Train Epoch: 33 [6400/10000 (63%)]\tLoss: 94.475380\n",
      "Train Epoch: 33 [7680/10000 (76%)]\tLoss: 94.057640\n",
      "Train Epoch: 33 [8960/10000 (89%)]\tLoss: 99.707375\n",
      "Train Epoch: 34 [0/10000 (0%)]\tLoss: 92.074821\n",
      "Train Epoch: 34 [1280/10000 (13%)]\tLoss: 95.413971\n",
      "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 93.897926\n",
      "Train Epoch: 34 [3840/10000 (38%)]\tLoss: 99.304764\n",
      "Train Epoch: 34 [5120/10000 (51%)]\tLoss: 93.418671\n",
      "Train Epoch: 34 [6400/10000 (63%)]\tLoss: 95.485184\n",
      "Train Epoch: 34 [7680/10000 (76%)]\tLoss: 94.500916\n",
      "Train Epoch: 34 [8960/10000 (89%)]\tLoss: 98.577255\n",
      "Train Epoch: 35 [0/10000 (0%)]\tLoss: 92.274284\n",
      "Train Epoch: 35 [1280/10000 (13%)]\tLoss: 95.708870\n",
      "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 94.981247\n",
      "Train Epoch: 35 [3840/10000 (38%)]\tLoss: 98.298859\n",
      "Train Epoch: 35 [5120/10000 (51%)]\tLoss: 94.117012\n",
      "Train Epoch: 35 [6400/10000 (63%)]\tLoss: 94.842239\n",
      "Train Epoch: 35 [7680/10000 (76%)]\tLoss: 93.923645\n",
      "Train Epoch: 35 [8960/10000 (89%)]\tLoss: 97.216476\n",
      "Train Epoch: 36 [0/10000 (0%)]\tLoss: 92.909882\n",
      "Train Epoch: 36 [1280/10000 (13%)]\tLoss: 95.428841\n",
      "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 94.048012\n",
      "Train Epoch: 36 [3840/10000 (38%)]\tLoss: 98.616745\n",
      "Train Epoch: 36 [5120/10000 (51%)]\tLoss: 94.157562\n",
      "Train Epoch: 36 [6400/10000 (63%)]\tLoss: 94.985977\n",
      "Train Epoch: 36 [7680/10000 (76%)]\tLoss: 92.954552\n",
      "Train Epoch: 36 [8960/10000 (89%)]\tLoss: 99.614105\n",
      "Train Epoch: 37 [0/10000 (0%)]\tLoss: 92.936790\n",
      "Train Epoch: 37 [1280/10000 (13%)]\tLoss: 96.345482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 93.725800\n",
      "Train Epoch: 37 [3840/10000 (38%)]\tLoss: 99.330276\n",
      "Train Epoch: 37 [5120/10000 (51%)]\tLoss: 93.143616\n",
      "Train Epoch: 37 [6400/10000 (63%)]\tLoss: 95.705887\n",
      "Train Epoch: 37 [7680/10000 (76%)]\tLoss: 93.943741\n",
      "Train Epoch: 37 [8960/10000 (89%)]\tLoss: 98.296982\n",
      "Train Epoch: 38 [0/10000 (0%)]\tLoss: 93.702286\n",
      "Train Epoch: 38 [1280/10000 (13%)]\tLoss: 95.503624\n",
      "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 94.279877\n",
      "Train Epoch: 38 [3840/10000 (38%)]\tLoss: 99.413925\n",
      "Train Epoch: 38 [5120/10000 (51%)]\tLoss: 93.032486\n",
      "Train Epoch: 38 [6400/10000 (63%)]\tLoss: 94.784157\n",
      "Train Epoch: 38 [7680/10000 (76%)]\tLoss: 94.028015\n",
      "Train Epoch: 38 [8960/10000 (89%)]\tLoss: 98.700813\n",
      "Train Epoch: 39 [0/10000 (0%)]\tLoss: 92.950394\n",
      "Train Epoch: 39 [1280/10000 (13%)]\tLoss: 95.112656\n",
      "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 93.891418\n",
      "Train Epoch: 39 [3840/10000 (38%)]\tLoss: 98.694061\n",
      "Train Epoch: 39 [5120/10000 (51%)]\tLoss: 92.096054\n",
      "Train Epoch: 39 [6400/10000 (63%)]\tLoss: 96.024780\n",
      "Train Epoch: 39 [7680/10000 (76%)]\tLoss: 95.037735\n",
      "Train Epoch: 39 [8960/10000 (89%)]\tLoss: 98.733810\n",
      "Train Epoch: 40 [0/10000 (0%)]\tLoss: 94.468460\n",
      "Train Epoch: 40 [1280/10000 (13%)]\tLoss: 96.454849\n",
      "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 94.655334\n",
      "Train Epoch: 40 [3840/10000 (38%)]\tLoss: 99.462479\n",
      "Train Epoch: 40 [5120/10000 (51%)]\tLoss: 93.413170\n",
      "Train Epoch: 40 [6400/10000 (63%)]\tLoss: 95.636963\n",
      "Train Epoch: 40 [7680/10000 (76%)]\tLoss: 94.697876\n",
      "Train Epoch: 40 [8960/10000 (89%)]\tLoss: 98.528580\n",
      "Train Epoch: 0 [0/10000 (0%)]\tLoss: 86.918449\n",
      "Train Epoch: 0 [1280/10000 (13%)]\tLoss: 89.617661\n",
      "Train Epoch: 0 [2560/10000 (25%)]\tLoss: 88.496323\n",
      "Train Epoch: 0 [3840/10000 (38%)]\tLoss: 92.176788\n",
      "Train Epoch: 0 [5120/10000 (51%)]\tLoss: 88.192627\n",
      "Train Epoch: 0 [6400/10000 (63%)]\tLoss: 89.576157\n",
      "Train Epoch: 0 [7680/10000 (76%)]\tLoss: 90.206009\n",
      "Train Epoch: 0 [8960/10000 (89%)]\tLoss: 93.942017\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 86.599884\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 88.712204\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 88.257370\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 93.708893\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 88.692093\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 90.670654\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 87.629257\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 91.321991\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 85.873917\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 89.743683\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 87.142265\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 93.467194\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 87.783752\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 89.164162\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 87.869385\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 93.614006\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 86.619080\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 89.448563\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 88.932449\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 93.055618\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 88.161346\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 90.085106\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 88.223328\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 93.305367\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 86.503502\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 88.423141\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 88.811768\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 91.991577\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 87.741806\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 90.080063\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 87.060417\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 92.465240\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 86.922928\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 88.584778\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 87.774353\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 92.887756\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 87.898010\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 89.174438\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 88.819794\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 93.492996\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 86.980949\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 89.275291\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 87.778824\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 92.727081\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 88.705994\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 90.512360\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 88.571548\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 93.333977\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 86.729462\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 88.798004\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 88.354294\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 92.062607\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 88.059769\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 90.059555\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 87.697098\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 93.124115\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 86.295578\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 88.390961\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 88.504761\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 92.968491\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 88.096848\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 90.472847\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 88.632446\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 92.824371\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 86.623985\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 89.349129\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 88.198006\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 93.481171\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 88.109192\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 89.568077\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 88.782745\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 92.893707\n",
      "====> Test set NLL: 88.0589\n",
      "Running time: 12391.953125 Seconds\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 545.926392\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 294.147095\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 264.264587\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 252.131561\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 256.335815\n",
      "====> Test set loss: 255.1780\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 250.060699\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 256.473969\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 251.214066\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 249.757690\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 249.766083\n",
      "====> Test set loss: 247.6545\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 253.749893\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 249.087280\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 248.450684\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 238.601791\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 237.643066\n",
      "====> Test set loss: 244.7948\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 234.150726\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 238.185593\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 238.568268\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 240.207642\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 239.337708\n",
      "====> Test set loss: 242.8678\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 245.227921\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 240.823944\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 236.121094\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 243.630066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 248.343597\n",
      "====> Test set loss: 241.7536\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 237.660034\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 230.509155\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 234.621887\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 243.906769\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 230.074951\n",
      "====> Test set loss: 240.8195\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 233.305481\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 235.909180\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 230.195312\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 230.701553\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 229.444183\n",
      "====> Test set loss: 240.1794\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 232.436707\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 233.195068\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 251.198105\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 238.274155\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 236.984756\n",
      "====> Test set loss: 239.4000\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 230.123520\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 230.107422\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 243.739899\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 231.210693\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 241.231354\n",
      "====> Test set loss: 238.9185\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 234.317230\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 232.952408\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 234.792099\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 233.512589\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 238.573883\n",
      "====> Test set loss: 238.6249\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 254.060196\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 245.374054\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 244.197998\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 234.824982\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 243.429474\n",
      "====> Test set loss: 238.1385\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 234.199112\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 242.731842\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 226.114471\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 240.029297\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 246.270584\n",
      "====> Test set loss: 238.1029\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 242.581421\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 231.770630\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 236.592712\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 223.441650\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 239.777588\n",
      "====> Test set loss: 237.5199\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 222.352539\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 235.256485\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 241.265808\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 240.552765\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 237.222641\n",
      "====> Test set loss: 237.1843\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 227.557831\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 231.648666\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 243.179306\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 235.894012\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 241.336700\n",
      "====> Test set loss: 237.1974\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 243.482239\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 233.474167\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 236.497253\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 237.120148\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 246.820679\n",
      "====> Test set loss: 236.9504\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 221.339203\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 234.507751\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 234.047974\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 236.575180\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 238.999710\n",
      "====> Test set loss: 236.7278\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 236.141083\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 221.401886\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 242.996490\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 235.105942\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 246.496063\n",
      "====> Test set loss: 236.4683\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 242.064270\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 225.641846\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 233.011017\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 234.332581\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 238.899323\n",
      "====> Test set loss: 236.3842\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 234.461243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 233.196945\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 231.556580\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 236.840240\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 234.842529\n",
      "====> Test set loss: 236.0834\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 238.126602\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 225.255951\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 235.183563\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 238.318451\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 231.925110\n",
      "====> Test set loss: 236.0842\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 231.697525\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 241.479340\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 241.370651\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 230.480713\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 245.627579\n",
      "====> Test set loss: 235.8736\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 217.199738\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 239.724091\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 240.972397\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 234.608032\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 237.277802\n",
      "====> Test set loss: 235.7219\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 227.190781\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 239.879410\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 238.231842\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 228.799805\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 236.852615\n",
      "====> Test set loss: 235.6124\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 230.859680\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 219.256332\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 236.686661\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 240.063324\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 240.422211\n",
      "====> Test set loss: 235.8002\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 239.974487\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 235.088043\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 244.383316\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 237.158020\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 238.191345\n",
      "====> Test set loss: 235.3210\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 234.354431\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 222.047623\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 229.558136\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 241.049194\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 244.081116\n",
      "====> Test set loss: 235.2191\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 250.700409\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 239.981506\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 224.372803\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 222.052429\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 237.903381\n",
      "====> Test set loss: 235.3044\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 237.013840\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 228.846405\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 232.132553\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 234.844757\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 245.424179\n",
      "====> Test set loss: 235.0589\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 233.930847\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 235.796707\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 227.206604\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 237.197784\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 238.760284\n",
      "====> Test set loss: 235.2649\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 238.719574\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 230.684296\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 231.764069\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 228.988983\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 235.825775\n",
      "====> Test set loss: 234.9090\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 222.298233\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 233.738831\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 232.222015\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 224.136459\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 240.271866\n",
      "====> Test set loss: 234.7976\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 237.116394\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 229.442780\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 237.666443\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 231.392395\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 223.901306\n",
      "====> Test set loss: 235.1496\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 233.255035\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 232.419312\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 232.772644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 230.943939\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 228.920273\n",
      "====> Test set loss: 234.8010\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 222.926514\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 235.427551\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 232.455261\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 233.816650\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 233.032776\n",
      "====> Test set loss: 234.8451\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 227.075775\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 236.763031\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 236.198547\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 232.072388\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 239.276810\n",
      "====> Test set loss: 234.7984\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 226.039169\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 220.311371\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 223.523407\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 219.102631\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 235.371826\n",
      "====> Test set loss: 234.6528\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 231.607300\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 234.116608\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 237.561737\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 224.631317\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 236.035339\n",
      "====> Test set loss: 234.7534\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 227.256866\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 229.037476\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 245.325348\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 238.220901\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 220.824890\n",
      "====> Test set loss: 234.4588\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 243.666077\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 236.777054\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 228.878296\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 239.104309\n",
      "tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 234.215607\n",
      "====> Test set loss: 234.2407\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 1022.171692\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 343.535553\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 319.219177\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 289.357330\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 272.617249\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 264.753479\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 258.172302\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 274.721069\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 264.052612\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 262.939453\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 259.849854\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 254.945480\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 245.897522\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 251.091232\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 242.288925\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 261.274536\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 247.563492\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 249.217957\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 252.973328\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 248.362610\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 240.528900\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 242.552032\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 235.307434\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 256.568726\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 242.578201\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 245.647919\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 252.638245\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 244.923721\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 235.434998\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 240.624222\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 233.118378\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 253.174622\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 241.621628\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 245.295944\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 250.500565\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 242.798447\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 236.422668\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 241.860382\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 231.735901\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 251.980377\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 241.066132\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 243.353638\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 249.764130\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 241.696381\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 234.868439\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 238.670654\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 229.084137\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 249.635101\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 236.914764\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 240.520782\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 248.086517\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 239.720337\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 235.563202\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 238.691925\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 230.700684\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 250.723160\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 236.939453\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 241.148010\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 246.915802\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 238.777649\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 234.214645\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 238.187164\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 229.747467\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 251.349945\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 237.526642\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 241.533737\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 244.823303\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 241.175049\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 234.251862\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 235.776077\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 227.328949\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 251.247879\n",
      "Train Epoch: 10 [0/10000 (0%)]\tLoss: 236.381775\n",
      "Train Epoch: 10 [1280/10000 (13%)]\tLoss: 238.766479\n",
      "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 245.085861\n",
      "Train Epoch: 10 [3840/10000 (38%)]\tLoss: 238.492493\n",
      "Train Epoch: 10 [5120/10000 (51%)]\tLoss: 234.498489\n",
      "Train Epoch: 10 [6400/10000 (63%)]\tLoss: 237.825867\n",
      "Train Epoch: 10 [7680/10000 (76%)]\tLoss: 229.875641\n",
      "Train Epoch: 10 [8960/10000 (89%)]\tLoss: 248.267914\n",
      "Train Epoch: 11 [0/10000 (0%)]\tLoss: 236.755447\n",
      "Train Epoch: 11 [1280/10000 (13%)]\tLoss: 239.921448\n",
      "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 244.027328\n",
      "Train Epoch: 11 [3840/10000 (38%)]\tLoss: 237.865341\n",
      "Train Epoch: 11 [5120/10000 (51%)]\tLoss: 233.128723\n",
      "Train Epoch: 11 [6400/10000 (63%)]\tLoss: 237.565796\n",
      "Train Epoch: 11 [7680/10000 (76%)]\tLoss: 229.947174\n",
      "Train Epoch: 11 [8960/10000 (89%)]\tLoss: 249.162231\n",
      "Train Epoch: 12 [0/10000 (0%)]\tLoss: 235.162598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [1280/10000 (13%)]\tLoss: 238.800446\n",
      "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 245.133545\n",
      "Train Epoch: 12 [3840/10000 (38%)]\tLoss: 237.861023\n",
      "Train Epoch: 12 [5120/10000 (51%)]\tLoss: 230.159760\n",
      "Train Epoch: 12 [6400/10000 (63%)]\tLoss: 236.475174\n",
      "Train Epoch: 12 [7680/10000 (76%)]\tLoss: 227.585953\n",
      "Train Epoch: 12 [8960/10000 (89%)]\tLoss: 247.728088\n",
      "Train Epoch: 13 [0/10000 (0%)]\tLoss: 236.680435\n",
      "Train Epoch: 13 [1280/10000 (13%)]\tLoss: 238.892319\n",
      "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 244.721619\n",
      "Train Epoch: 13 [3840/10000 (38%)]\tLoss: 237.365387\n",
      "Train Epoch: 13 [5120/10000 (51%)]\tLoss: 231.734650\n",
      "Train Epoch: 13 [6400/10000 (63%)]\tLoss: 235.092957\n",
      "Train Epoch: 13 [7680/10000 (76%)]\tLoss: 225.936279\n",
      "Train Epoch: 13 [8960/10000 (89%)]\tLoss: 246.762665\n",
      "Train Epoch: 14 [0/10000 (0%)]\tLoss: 236.743103\n",
      "Train Epoch: 14 [1280/10000 (13%)]\tLoss: 239.960754\n",
      "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 246.180817\n",
      "Train Epoch: 14 [3840/10000 (38%)]\tLoss: 237.060074\n",
      "Train Epoch: 14 [5120/10000 (51%)]\tLoss: 231.230438\n",
      "Train Epoch: 14 [6400/10000 (63%)]\tLoss: 237.105423\n",
      "Train Epoch: 14 [7680/10000 (76%)]\tLoss: 229.376190\n",
      "Train Epoch: 14 [8960/10000 (89%)]\tLoss: 248.468872\n",
      "Train Epoch: 15 [0/10000 (0%)]\tLoss: 235.979324\n",
      "Train Epoch: 15 [1280/10000 (13%)]\tLoss: 239.009857\n",
      "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 245.478424\n",
      "Train Epoch: 15 [3840/10000 (38%)]\tLoss: 236.873718\n",
      "Train Epoch: 15 [5120/10000 (51%)]\tLoss: 232.645966\n",
      "Train Epoch: 15 [6400/10000 (63%)]\tLoss: 233.764832\n",
      "Train Epoch: 15 [7680/10000 (76%)]\tLoss: 226.968857\n",
      "Train Epoch: 15 [8960/10000 (89%)]\tLoss: 247.652008\n",
      "Train Epoch: 16 [0/10000 (0%)]\tLoss: 234.439789\n",
      "Train Epoch: 16 [1280/10000 (13%)]\tLoss: 239.142242\n",
      "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 243.349670\n",
      "Train Epoch: 16 [3840/10000 (38%)]\tLoss: 238.860046\n",
      "Train Epoch: 16 [5120/10000 (51%)]\tLoss: 231.164764\n",
      "Train Epoch: 16 [6400/10000 (63%)]\tLoss: 234.637772\n",
      "Train Epoch: 16 [7680/10000 (76%)]\tLoss: 225.989517\n",
      "Train Epoch: 16 [8960/10000 (89%)]\tLoss: 247.457169\n",
      "Train Epoch: 17 [0/10000 (0%)]\tLoss: 231.980438\n",
      "Train Epoch: 17 [1280/10000 (13%)]\tLoss: 238.431213\n",
      "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 245.090164\n",
      "Train Epoch: 17 [3840/10000 (38%)]\tLoss: 237.364899\n",
      "Train Epoch: 17 [5120/10000 (51%)]\tLoss: 230.010468\n",
      "Train Epoch: 17 [6400/10000 (63%)]\tLoss: 235.308319\n",
      "Train Epoch: 17 [7680/10000 (76%)]\tLoss: 226.478821\n",
      "Train Epoch: 17 [8960/10000 (89%)]\tLoss: 246.444519\n",
      "Train Epoch: 18 [0/10000 (0%)]\tLoss: 236.504425\n",
      "Train Epoch: 18 [1280/10000 (13%)]\tLoss: 238.639862\n",
      "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 244.215881\n",
      "Train Epoch: 18 [3840/10000 (38%)]\tLoss: 236.308167\n",
      "Train Epoch: 18 [5120/10000 (51%)]\tLoss: 230.571960\n",
      "Train Epoch: 18 [6400/10000 (63%)]\tLoss: 235.362503\n",
      "Train Epoch: 18 [7680/10000 (76%)]\tLoss: 225.488678\n",
      "Train Epoch: 18 [8960/10000 (89%)]\tLoss: 246.171783\n",
      "Train Epoch: 19 [0/10000 (0%)]\tLoss: 234.030685\n",
      "Train Epoch: 19 [1280/10000 (13%)]\tLoss: 239.163223\n",
      "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 244.250488\n",
      "Train Epoch: 19 [3840/10000 (38%)]\tLoss: 236.545776\n",
      "Train Epoch: 19 [5120/10000 (51%)]\tLoss: 230.888474\n",
      "Train Epoch: 19 [6400/10000 (63%)]\tLoss: 235.822525\n",
      "Train Epoch: 19 [7680/10000 (76%)]\tLoss: 224.843460\n",
      "Train Epoch: 19 [8960/10000 (89%)]\tLoss: 247.785614\n",
      "Train Epoch: 20 [0/10000 (0%)]\tLoss: 233.873581\n",
      "Train Epoch: 20 [1280/10000 (13%)]\tLoss: 239.928162\n",
      "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 245.202972\n",
      "Train Epoch: 20 [3840/10000 (38%)]\tLoss: 236.850998\n",
      "Train Epoch: 20 [5120/10000 (51%)]\tLoss: 231.116577\n",
      "Train Epoch: 20 [6400/10000 (63%)]\tLoss: 234.428864\n",
      "Train Epoch: 20 [7680/10000 (76%)]\tLoss: 227.921326\n",
      "Train Epoch: 20 [8960/10000 (89%)]\tLoss: 247.763733\n",
      "Train Epoch: 21 [0/10000 (0%)]\tLoss: 234.421478\n",
      "Train Epoch: 21 [1280/10000 (13%)]\tLoss: 237.719620\n",
      "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 243.271179\n",
      "Train Epoch: 21 [3840/10000 (38%)]\tLoss: 236.279816\n",
      "Train Epoch: 21 [5120/10000 (51%)]\tLoss: 230.861526\n",
      "Train Epoch: 21 [6400/10000 (63%)]\tLoss: 235.045502\n",
      "Train Epoch: 21 [7680/10000 (76%)]\tLoss: 227.471085\n",
      "Train Epoch: 21 [8960/10000 (89%)]\tLoss: 246.721573\n",
      "Train Epoch: 22 [0/10000 (0%)]\tLoss: 234.934540\n",
      "Train Epoch: 22 [1280/10000 (13%)]\tLoss: 238.500549\n",
      "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 244.547653\n",
      "Train Epoch: 22 [3840/10000 (38%)]\tLoss: 236.419891\n",
      "Train Epoch: 22 [5120/10000 (51%)]\tLoss: 229.992157\n",
      "Train Epoch: 22 [6400/10000 (63%)]\tLoss: 234.055206\n",
      "Train Epoch: 22 [7680/10000 (76%)]\tLoss: 226.689346\n",
      "Train Epoch: 22 [8960/10000 (89%)]\tLoss: 244.224731\n",
      "Train Epoch: 23 [0/10000 (0%)]\tLoss: 233.444580\n",
      "Train Epoch: 23 [1280/10000 (13%)]\tLoss: 237.767319\n",
      "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 243.770721\n",
      "Train Epoch: 23 [3840/10000 (38%)]\tLoss: 236.321655\n",
      "Train Epoch: 23 [5120/10000 (51%)]\tLoss: 230.883484\n",
      "Train Epoch: 23 [6400/10000 (63%)]\tLoss: 234.379364\n",
      "Train Epoch: 23 [7680/10000 (76%)]\tLoss: 226.447266\n",
      "Train Epoch: 23 [8960/10000 (89%)]\tLoss: 247.948700\n",
      "Train Epoch: 24 [0/10000 (0%)]\tLoss: 233.987885\n",
      "Train Epoch: 24 [1280/10000 (13%)]\tLoss: 238.409378\n",
      "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 244.108673\n",
      "Train Epoch: 24 [3840/10000 (38%)]\tLoss: 236.725250\n",
      "Train Epoch: 24 [5120/10000 (51%)]\tLoss: 230.985703\n",
      "Train Epoch: 24 [6400/10000 (63%)]\tLoss: 234.682770\n",
      "Train Epoch: 24 [7680/10000 (76%)]\tLoss: 225.361389\n",
      "Train Epoch: 24 [8960/10000 (89%)]\tLoss: 245.450073\n",
      "Train Epoch: 25 [0/10000 (0%)]\tLoss: 233.678986\n",
      "Train Epoch: 25 [1280/10000 (13%)]\tLoss: 238.286774\n",
      "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 245.247299\n",
      "Train Epoch: 25 [3840/10000 (38%)]\tLoss: 236.101929\n",
      "Train Epoch: 25 [5120/10000 (51%)]\tLoss: 229.416565\n",
      "Train Epoch: 25 [6400/10000 (63%)]\tLoss: 233.491821\n",
      "Train Epoch: 25 [7680/10000 (76%)]\tLoss: 225.604889\n",
      "Train Epoch: 25 [8960/10000 (89%)]\tLoss: 245.588364\n",
      "Train Epoch: 26 [0/10000 (0%)]\tLoss: 234.253540\n",
      "Train Epoch: 26 [1280/10000 (13%)]\tLoss: 236.903687\n",
      "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 244.430878\n",
      "Train Epoch: 26 [3840/10000 (38%)]\tLoss: 236.506561\n",
      "Train Epoch: 26 [5120/10000 (51%)]\tLoss: 229.381058\n",
      "Train Epoch: 26 [6400/10000 (63%)]\tLoss: 233.816010\n",
      "Train Epoch: 26 [7680/10000 (76%)]\tLoss: 224.826691\n",
      "Train Epoch: 26 [8960/10000 (89%)]\tLoss: 244.059113\n",
      "Train Epoch: 27 [0/10000 (0%)]\tLoss: 234.698944\n",
      "Train Epoch: 27 [1280/10000 (13%)]\tLoss: 236.287323\n",
      "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 242.753540\n",
      "Train Epoch: 27 [3840/10000 (38%)]\tLoss: 236.605743\n",
      "Train Epoch: 27 [5120/10000 (51%)]\tLoss: 230.324860\n",
      "Train Epoch: 27 [6400/10000 (63%)]\tLoss: 233.876068\n",
      "Train Epoch: 27 [7680/10000 (76%)]\tLoss: 224.227417\n",
      "Train Epoch: 27 [8960/10000 (89%)]\tLoss: 244.861816\n",
      "Train Epoch: 28 [0/10000 (0%)]\tLoss: 234.045639\n",
      "Train Epoch: 28 [1280/10000 (13%)]\tLoss: 238.386063\n",
      "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 245.054871\n",
      "Train Epoch: 28 [3840/10000 (38%)]\tLoss: 235.089783\n",
      "Train Epoch: 28 [5120/10000 (51%)]\tLoss: 229.434814\n",
      "Train Epoch: 28 [6400/10000 (63%)]\tLoss: 233.311218\n",
      "Train Epoch: 28 [7680/10000 (76%)]\tLoss: 225.599823\n",
      "Train Epoch: 28 [8960/10000 (89%)]\tLoss: 245.724426\n",
      "Train Epoch: 29 [0/10000 (0%)]\tLoss: 233.499451\n",
      "Train Epoch: 29 [1280/10000 (13%)]\tLoss: 237.175690\n",
      "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 244.803162\n",
      "Train Epoch: 29 [3840/10000 (38%)]\tLoss: 236.345535\n",
      "Train Epoch: 29 [5120/10000 (51%)]\tLoss: 231.779633\n",
      "Train Epoch: 29 [6400/10000 (63%)]\tLoss: 231.842560\n",
      "Train Epoch: 29 [7680/10000 (76%)]\tLoss: 224.893066\n",
      "Train Epoch: 29 [8960/10000 (89%)]\tLoss: 247.000046\n",
      "Train Epoch: 30 [0/10000 (0%)]\tLoss: 233.951385\n",
      "Train Epoch: 30 [1280/10000 (13%)]\tLoss: 238.781601\n",
      "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 246.817703\n",
      "Train Epoch: 30 [3840/10000 (38%)]\tLoss: 235.991577\n",
      "Train Epoch: 30 [5120/10000 (51%)]\tLoss: 230.381607\n",
      "Train Epoch: 30 [6400/10000 (63%)]\tLoss: 234.680359\n",
      "Train Epoch: 30 [7680/10000 (76%)]\tLoss: 225.362595\n",
      "Train Epoch: 30 [8960/10000 (89%)]\tLoss: 245.626129\n",
      "Train Epoch: 31 [0/10000 (0%)]\tLoss: 233.276672\n",
      "Train Epoch: 31 [1280/10000 (13%)]\tLoss: 236.878006\n",
      "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 244.489395\n",
      "Train Epoch: 31 [3840/10000 (38%)]\tLoss: 234.830002\n",
      "Train Epoch: 31 [5120/10000 (51%)]\tLoss: 229.560562\n",
      "Train Epoch: 31 [6400/10000 (63%)]\tLoss: 233.243713\n",
      "Train Epoch: 31 [7680/10000 (76%)]\tLoss: 226.011871\n",
      "Train Epoch: 31 [8960/10000 (89%)]\tLoss: 246.676514\n",
      "Train Epoch: 32 [0/10000 (0%)]\tLoss: 235.396790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [1280/10000 (13%)]\tLoss: 237.446442\n",
      "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 243.574738\n",
      "Train Epoch: 32 [3840/10000 (38%)]\tLoss: 236.806061\n",
      "Train Epoch: 32 [5120/10000 (51%)]\tLoss: 229.239731\n",
      "Train Epoch: 32 [6400/10000 (63%)]\tLoss: 233.745758\n",
      "Train Epoch: 32 [7680/10000 (76%)]\tLoss: 226.487976\n",
      "Train Epoch: 32 [8960/10000 (89%)]\tLoss: 245.441925\n",
      "Train Epoch: 33 [0/10000 (0%)]\tLoss: 231.278549\n",
      "Train Epoch: 33 [1280/10000 (13%)]\tLoss: 236.004166\n",
      "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 242.805023\n",
      "Train Epoch: 33 [3840/10000 (38%)]\tLoss: 236.753128\n",
      "Train Epoch: 33 [5120/10000 (51%)]\tLoss: 230.879578\n",
      "Train Epoch: 33 [6400/10000 (63%)]\tLoss: 233.175674\n",
      "Train Epoch: 33 [7680/10000 (76%)]\tLoss: 224.527374\n",
      "Train Epoch: 33 [8960/10000 (89%)]\tLoss: 244.226990\n",
      "Train Epoch: 34 [0/10000 (0%)]\tLoss: 233.179306\n",
      "Train Epoch: 34 [1280/10000 (13%)]\tLoss: 236.097183\n",
      "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 242.229721\n",
      "Train Epoch: 34 [3840/10000 (38%)]\tLoss: 236.333557\n",
      "Train Epoch: 34 [5120/10000 (51%)]\tLoss: 230.906189\n",
      "Train Epoch: 34 [6400/10000 (63%)]\tLoss: 232.016373\n",
      "Train Epoch: 34 [7680/10000 (76%)]\tLoss: 224.886169\n",
      "Train Epoch: 34 [8960/10000 (89%)]\tLoss: 244.549164\n",
      "Train Epoch: 35 [0/10000 (0%)]\tLoss: 233.051270\n",
      "Train Epoch: 35 [1280/10000 (13%)]\tLoss: 236.520569\n",
      "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 244.588715\n",
      "Train Epoch: 35 [3840/10000 (38%)]\tLoss: 234.657532\n",
      "Train Epoch: 35 [5120/10000 (51%)]\tLoss: 229.321808\n",
      "Train Epoch: 35 [6400/10000 (63%)]\tLoss: 233.668320\n",
      "Train Epoch: 35 [7680/10000 (76%)]\tLoss: 226.542877\n",
      "Train Epoch: 35 [8960/10000 (89%)]\tLoss: 246.929413\n",
      "Train Epoch: 36 [0/10000 (0%)]\tLoss: 232.327972\n",
      "Train Epoch: 36 [1280/10000 (13%)]\tLoss: 238.056519\n",
      "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 243.825012\n",
      "Train Epoch: 36 [3840/10000 (38%)]\tLoss: 234.562820\n",
      "Train Epoch: 36 [5120/10000 (51%)]\tLoss: 229.403854\n",
      "Train Epoch: 36 [6400/10000 (63%)]\tLoss: 233.267883\n",
      "Train Epoch: 36 [7680/10000 (76%)]\tLoss: 225.106812\n",
      "Train Epoch: 36 [8960/10000 (89%)]\tLoss: 244.824219\n",
      "Train Epoch: 37 [0/10000 (0%)]\tLoss: 233.182526\n",
      "Train Epoch: 37 [1280/10000 (13%)]\tLoss: 236.783356\n",
      "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 244.407227\n",
      "Train Epoch: 37 [3840/10000 (38%)]\tLoss: 235.810654\n",
      "Train Epoch: 37 [5120/10000 (51%)]\tLoss: 229.456177\n",
      "Train Epoch: 37 [6400/10000 (63%)]\tLoss: 232.174088\n",
      "Train Epoch: 37 [7680/10000 (76%)]\tLoss: 225.054779\n",
      "Train Epoch: 37 [8960/10000 (89%)]\tLoss: 246.441315\n",
      "Train Epoch: 38 [0/10000 (0%)]\tLoss: 232.072525\n",
      "Train Epoch: 38 [1280/10000 (13%)]\tLoss: 236.892990\n",
      "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 241.809662\n",
      "Train Epoch: 38 [3840/10000 (38%)]\tLoss: 234.583664\n",
      "Train Epoch: 38 [5120/10000 (51%)]\tLoss: 230.657806\n",
      "Train Epoch: 38 [6400/10000 (63%)]\tLoss: 232.405426\n",
      "Train Epoch: 38 [7680/10000 (76%)]\tLoss: 225.675690\n",
      "Train Epoch: 38 [8960/10000 (89%)]\tLoss: 244.617798\n",
      "Train Epoch: 39 [0/10000 (0%)]\tLoss: 232.475479\n",
      "Train Epoch: 39 [1280/10000 (13%)]\tLoss: 236.408432\n",
      "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 243.413177\n",
      "Train Epoch: 39 [3840/10000 (38%)]\tLoss: 236.078369\n",
      "Train Epoch: 39 [5120/10000 (51%)]\tLoss: 231.181244\n",
      "Train Epoch: 39 [6400/10000 (63%)]\tLoss: 231.063202\n",
      "Train Epoch: 39 [7680/10000 (76%)]\tLoss: 223.916962\n",
      "Train Epoch: 39 [8960/10000 (89%)]\tLoss: 245.437668\n",
      "Train Epoch: 40 [0/10000 (0%)]\tLoss: 234.373749\n",
      "Train Epoch: 40 [1280/10000 (13%)]\tLoss: 236.344879\n",
      "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 244.141296\n",
      "Train Epoch: 40 [3840/10000 (38%)]\tLoss: 235.928772\n",
      "Train Epoch: 40 [5120/10000 (51%)]\tLoss: 229.641495\n",
      "Train Epoch: 40 [6400/10000 (63%)]\tLoss: 233.439941\n",
      "Train Epoch: 40 [7680/10000 (76%)]\tLoss: 226.400406\n",
      "Train Epoch: 40 [8960/10000 (89%)]\tLoss: 243.662094\n",
      "Train Epoch: 0 [0/10000 (0%)]\tLoss: 228.264664\n",
      "Train Epoch: 0 [1280/10000 (13%)]\tLoss: 230.799927\n",
      "Train Epoch: 0 [2560/10000 (25%)]\tLoss: 239.414612\n",
      "Train Epoch: 0 [3840/10000 (38%)]\tLoss: 231.788025\n",
      "Train Epoch: 0 [5120/10000 (51%)]\tLoss: 226.813232\n",
      "Train Epoch: 0 [6400/10000 (63%)]\tLoss: 228.581421\n",
      "Train Epoch: 0 [7680/10000 (76%)]\tLoss: 221.190201\n",
      "Train Epoch: 0 [8960/10000 (89%)]\tLoss: 241.029633\n",
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 228.479828\n",
      "Train Epoch: 1 [1280/10000 (13%)]\tLoss: 232.232376\n",
      "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 238.703186\n",
      "Train Epoch: 1 [3840/10000 (38%)]\tLoss: 231.567581\n",
      "Train Epoch: 1 [5120/10000 (51%)]\tLoss: 225.998764\n",
      "Train Epoch: 1 [6400/10000 (63%)]\tLoss: 228.518478\n",
      "Train Epoch: 1 [7680/10000 (76%)]\tLoss: 220.766418\n",
      "Train Epoch: 1 [8960/10000 (89%)]\tLoss: 241.722870\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 229.143936\n",
      "Train Epoch: 2 [1280/10000 (13%)]\tLoss: 231.304092\n",
      "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 238.912445\n",
      "Train Epoch: 2 [3840/10000 (38%)]\tLoss: 233.108490\n",
      "Train Epoch: 2 [5120/10000 (51%)]\tLoss: 226.699402\n",
      "Train Epoch: 2 [6400/10000 (63%)]\tLoss: 228.987045\n",
      "Train Epoch: 2 [7680/10000 (76%)]\tLoss: 220.340469\n",
      "Train Epoch: 2 [8960/10000 (89%)]\tLoss: 240.136688\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 229.197968\n",
      "Train Epoch: 3 [1280/10000 (13%)]\tLoss: 231.957657\n",
      "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 239.216248\n",
      "Train Epoch: 3 [3840/10000 (38%)]\tLoss: 231.093994\n",
      "Train Epoch: 3 [5120/10000 (51%)]\tLoss: 225.671219\n",
      "Train Epoch: 3 [6400/10000 (63%)]\tLoss: 227.967361\n",
      "Train Epoch: 3 [7680/10000 (76%)]\tLoss: 220.635895\n",
      "Train Epoch: 3 [8960/10000 (89%)]\tLoss: 241.992020\n",
      "Train Epoch: 4 [0/10000 (0%)]\tLoss: 227.315277\n",
      "Train Epoch: 4 [1280/10000 (13%)]\tLoss: 233.370331\n",
      "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 237.836548\n",
      "Train Epoch: 4 [3840/10000 (38%)]\tLoss: 230.492462\n",
      "Train Epoch: 4 [5120/10000 (51%)]\tLoss: 225.825348\n",
      "Train Epoch: 4 [6400/10000 (63%)]\tLoss: 229.535233\n",
      "Train Epoch: 4 [7680/10000 (76%)]\tLoss: 221.594650\n",
      "Train Epoch: 4 [8960/10000 (89%)]\tLoss: 240.615372\n",
      "Train Epoch: 5 [0/10000 (0%)]\tLoss: 229.074158\n",
      "Train Epoch: 5 [1280/10000 (13%)]\tLoss: 230.321442\n",
      "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 239.219147\n",
      "Train Epoch: 5 [3840/10000 (38%)]\tLoss: 231.535370\n",
      "Train Epoch: 5 [5120/10000 (51%)]\tLoss: 225.428162\n",
      "Train Epoch: 5 [6400/10000 (63%)]\tLoss: 228.076111\n",
      "Train Epoch: 5 [7680/10000 (76%)]\tLoss: 221.177155\n",
      "Train Epoch: 5 [8960/10000 (89%)]\tLoss: 240.851089\n",
      "Train Epoch: 6 [0/10000 (0%)]\tLoss: 227.793579\n",
      "Train Epoch: 6 [1280/10000 (13%)]\tLoss: 231.645203\n",
      "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 239.470169\n",
      "Train Epoch: 6 [3840/10000 (38%)]\tLoss: 230.820908\n",
      "Train Epoch: 6 [5120/10000 (51%)]\tLoss: 225.978607\n",
      "Train Epoch: 6 [6400/10000 (63%)]\tLoss: 227.725586\n",
      "Train Epoch: 6 [7680/10000 (76%)]\tLoss: 220.742737\n",
      "Train Epoch: 6 [8960/10000 (89%)]\tLoss: 240.163330\n",
      "Train Epoch: 7 [0/10000 (0%)]\tLoss: 228.040115\n",
      "Train Epoch: 7 [1280/10000 (13%)]\tLoss: 232.470428\n",
      "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 237.641159\n",
      "Train Epoch: 7 [3840/10000 (38%)]\tLoss: 231.508148\n",
      "Train Epoch: 7 [5120/10000 (51%)]\tLoss: 225.651703\n",
      "Train Epoch: 7 [6400/10000 (63%)]\tLoss: 229.332855\n",
      "Train Epoch: 7 [7680/10000 (76%)]\tLoss: 220.193237\n",
      "Train Epoch: 7 [8960/10000 (89%)]\tLoss: 242.470688\n",
      "Train Epoch: 8 [0/10000 (0%)]\tLoss: 229.938675\n",
      "Train Epoch: 8 [1280/10000 (13%)]\tLoss: 232.649170\n",
      "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 238.841522\n",
      "Train Epoch: 8 [3840/10000 (38%)]\tLoss: 230.517746\n",
      "Train Epoch: 8 [5120/10000 (51%)]\tLoss: 225.996674\n",
      "Train Epoch: 8 [6400/10000 (63%)]\tLoss: 228.464447\n",
      "Train Epoch: 8 [7680/10000 (76%)]\tLoss: 221.312256\n",
      "Train Epoch: 8 [8960/10000 (89%)]\tLoss: 241.546539\n",
      "Train Epoch: 9 [0/10000 (0%)]\tLoss: 229.339020\n",
      "Train Epoch: 9 [1280/10000 (13%)]\tLoss: 232.792358\n",
      "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 238.124649\n",
      "Train Epoch: 9 [3840/10000 (38%)]\tLoss: 232.711761\n",
      "Train Epoch: 9 [5120/10000 (51%)]\tLoss: 225.628983\n",
      "Train Epoch: 9 [6400/10000 (63%)]\tLoss: 228.679871\n",
      "Train Epoch: 9 [7680/10000 (76%)]\tLoss: 221.307159\n",
      "Train Epoch: 9 [8960/10000 (89%)]\tLoss: 241.149384\n",
      "====> Test set NLL: 231.9653\n",
      "Running time: 11725.34375 Seconds\n"
     ]
    }
   ],
   "source": [
    "M = 5\n",
    "for model in ['SimpleVAE', 'RealNVPVAE', 'LangevinVAE', 'SNFVAE']:\n",
    "    for data_file in ['mnist_data', 'fashionmnist_data']:\n",
    "        train(model, data_file, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feec39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'SNF'",
   "language": "python",
   "name": "snf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
